{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_new/bin/pip\n"
     ]
    }
   ],
   "source": [
    "! which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (1.2.4)\n",
      "Collecting bokeh\n",
      "  Downloading bokeh-2.3.1.tar.gz (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML>=3.10\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 74.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (1.20.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (8.2.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (20.9)\n",
      "Requirement already satisfied: tornado>=5.1 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (6.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from bokeh) (3.7.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from packaging>=16.8->bokeh) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from python-dateutil>=2.1->bokeh) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.3.1-py3-none-any.whl size=11299678 sha256=95cadd9cb516a880306a31435cead47a94805125beeb6e3c312607c355e75ad3\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/d1/a4/b53575bc2fa65fa5f52a29aafd6ed7b05f2ee5c11aa5a908ad\n",
      "Successfully built bokeh\n",
      "Installing collected packages: PyYAML, bokeh\n",
      "Successfully installed PyYAML-5.4.1 bokeh-2.3.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas bokeh blessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.2-cp38-cp38-manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from transformers) (1.20.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.4.4-cp38-cp38-manylinux2014_x86_64.whl (733 kB)\n",
      "\u001b[K     |████████████████████████████████| 733 kB 33.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from transformers) (4.44.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 34.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex, joblib, click, tokenizers, sacremoses, filelock, transformers\n",
      "Successfully installed click-7.1.2 filelock-3.0.12 joblib-1.0.1 regex-2021.4.4 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "! pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm==4.44.1 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (4.44.1)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm==4.44.1 termcolor==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import io\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "prefix = '/Users/adivekar/workplace/coursework/nlp-qa-finalproj/results/'\n",
    "\n",
    "def get_file_str(file_path) -> str:\n",
    "    file_str: str = None\n",
    "    try:\n",
    "        with io.open(file_path, 'r') as inp:\n",
    "            file_str = inp.read()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    return file_str\n",
    "results = []\n",
    "\n",
    "for file_path in sorted(glob.glob(prefix+'*')):\n",
    "    file_txt = get_file_str(file_path)\n",
    "    result = json.loads(file_txt[file_txt.find('AVERAGE') + len('AVERAGE:'):file_txt.find('MIN')].strip())\n",
    "    result['EM'] = round(result['EM'], 1)\n",
    "    result['F1'] = round(result['F1'], 1)\n",
    "    result['file'] = file_path.replace(prefix, '')\n",
    "    result['params'] = '-'.join(result['file'].split('-')[2:])\n",
    "    result['dataset'] = result['file'].split('_')[0].capitalize()\n",
    "    for col in ['train_dataset.size', 'train_dataset.num_paraphrased_questions', 'dev_dataset.size', 'dev_dataset.num_paraphrased_questions']:\n",
    "        result[col] = int(result[col])\n",
    "    if result['params'] == '' and result['train_dataset.size'] == result['train_dataset.num_paraphrased_questions']:\n",
    "        result['train_dataset.num_paraphrased_questions'] = 0\n",
    "    if result['params'] == '' and result['dev_dataset.size'] == result['dev_dataset.num_paraphrased_questions']:\n",
    "        result['dev_dataset.num_paraphrased_questions'] = 0\n",
    "    result['train_paraphrase_%'] = str(round(100 * result['train_dataset.num_paraphrased_questions'] / result['train_dataset.size'], 1)) + '%'\n",
    "    results.append(result)\n",
    "results = pd.DataFrame(results)[\n",
    "    ['dataset', 'params', 'EM', 'F1', 'train_paraphrase_%',\n",
    "    'train_dataset.num_paraphrased_questions', 'train_dataset.size', 'dev_dataset.num_paraphrased_questions', 'dev_dataset.size', 'file']\n",
    "].rename(columns={\n",
    "    'train_dataset.size':'train_size',\n",
    "    'train_dataset.num_paraphrased_questions': 'train_num_paraphrased',\n",
    "    'dev_dataset.size':'dev_size',\n",
    "    'dev_dataset.num_paraphrased_questions': 'dev_num_paraphrased',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n",
      "True\n",
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 75 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 &\n",
      "    \n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 75 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 &\n",
      "    \n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 75 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 &\n",
      "    \n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 75 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 &\n",
      "    \n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 &\n",
      "    \n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 &\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for i, model_params in enumerate([\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 75',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 75',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 75',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 75',\n",
    "    '--architecture fairseq --num_beams 20',\n",
    "    '--architecture fairseq --MT_sampling --num_beams 20',\n",
    "    ]):\n",
    "    cmd = f\"\"\"\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/bioasq_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device {i} &\n",
    "    \"\"\"\n",
    "    print(cmd, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30 --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
      "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question --architecture fairseq --MT_sampling --num_beams 20 --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
      "    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_params in [\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\" --num_beams 30',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-xsum\" --num_beams 30',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-large\" --num_beams 30',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\" --num_beams 30',\n",
    "    '--architecture fairseq --num_beams 20',\n",
    "    '--architecture fairseq --MT_sampling --num_beams 20',\n",
    "    ]:\n",
    "    cmd = f\"\"\"\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
    "    \"\"\"\n",
    "    print(cmd, end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    }
   ],
   "source": [
    "import gzip, json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "elems = None\n",
    "# path = 'datasets/squad_dev.jsonl.gz'\n",
    "# path = 'datasets/bioasq.jsonl.gz'\n",
    "# path = 'datasets/bioasq_train.jsonl.gz'\n",
    "# path = 'datasets/bioasq_dev.jsonl.gz'\n",
    "# path = 'datasets/newsqa_train.jsonl.gz'\n",
    "# path = 'datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz'\n",
    "# path = 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th1.2-ngram1.jsonl.gz'\n",
    "# path = 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th1.2-ngram1-11420.jsonl.gz'\n",
    "path = \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5.jsonl.gz\"\n",
    "# path = \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\"\n",
    "with gzip.open(path, 'rb') as f:\n",
    "    elems = [\n",
    "        json.loads(l.rstrip())\n",
    "        for l in tqdm(f, desc=f'loading \\'{path}\\'', leave=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elems2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AbstractParaphraser import AbstractParaphraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===QA1===\n",
      "question_tokens_original: ['Which', 'is', 'the', 'major', 'RNA', 'editing', 'enzyme', 'in', 'Drosophila', 'melanogaster', '?']\n",
      "question_tokens: ['Which', 'is', 'the', 'major', 'RNA', 'editing', 'enzyme', 'in', 'Drosophila', 'melanogaster']\n",
      "0.909\n",
      "========\n",
      "===QA2===\n",
      "question_tokens_original: ['Which', 'is', 'the', 'major', 'RNA', 'editing', 'enzyme', 'in', 'Drosophila', 'melanogaster', '?']\n",
      "question_tokens: ['What', 'does', 'RNA', 'editing', 'enzyme', 'do', '?', 'What', 'is', 'the', 'difference', 'between']\n",
      "1.375\n"
     ]
    }
   ],
   "source": [
    "num_paraphrased_questions = 0\n",
    "for elem, elem2 in zip(elems[1:], elems2[1:]):\n",
    "    for qa, qa2 in zip(elem['qas'], elem2['qas']):\n",
    "        print('===QA1===')\n",
    "#         print(qa['question_tokens'])\n",
    "#         print(qa['question_tokens_original'])\n",
    "        question_tokens_original = [x[0] for x in qa['question_tokens_original']]\n",
    "        question_tokens = [x[0] for x in qa['question_tokens']]\n",
    "        print(f'question_tokens_original: {question_tokens_original}')\n",
    "        print(f'question_tokens: {question_tokens}')\n",
    "        paraphrase_score: float = AbstractParaphraser._calculate_paraphrase_score(\n",
    "            question_tokens_original,\n",
    "            question_tokens,\n",
    "            1,\n",
    "        )\n",
    "        print(paraphrase_score)\n",
    "        \n",
    "        print('========')\n",
    "        print('===QA2===')\n",
    "#         print(qa2['question_tokens'])\n",
    "#         print(qa2['question_tokens_original'])\n",
    "        question_tokens_original = [x[0] for x in qa2['question_tokens_original']]\n",
    "        question_tokens = [x[0] for x in qa2['question_tokens']]\n",
    "        print(f'question_tokens_original: {question_tokens_original}')\n",
    "        print(f'question_tokens: {question_tokens}')\n",
    "        paraphrase_score: float = AbstractParaphraser._calculate_paraphrase_score(\n",
    "            question_tokens_original,\n",
    "            question_tokens,\n",
    "            1,\n",
    "        )\n",
    "        print(paraphrase_score)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsqa_paraphrased_full[:10000] == elems[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsqa_paraphrased_full = elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11429"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsqa_paraphrased_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_params in [\n",
    "    '--architecture fairseq',\n",
    "    '--architecture fairseq --MT_sampling --num_beams 20',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-cnn_dailymail\"',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-xsum\"',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-large\"',\n",
    "    '--architecture pegasus --pretrained_model_name \"google/pegasus-multi_news\"',\n",
    "    ]:\n",
    "    cmd = f\"\"\"\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 0 --examples_range 1:1500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 1 --examples_range 1501:3000 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 2 --examples_range 3001:4500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 3 --examples_range 4501:6000 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 4 --examples_range 6001:7500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 5 --examples_range 7501:9000 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 6 --examples_range 9001:10500 &\n",
    "python3 paraphrase.py --use_scoring_function --score_threshold 0.0 --input_path \"datasets/newsqa_train.jsonl.gz\" --paraphrase question {model_params} --num_checkpoints 0 --batch_size 1 --use_gpu --device 7 --examples_range 10501:12000 &\n",
    "    \"\"\"\n",
    "print(cmd, end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Which is the major RNA editing enzyme in Drosophila melanogaster?'\n",
    "tokens_idxs_orig = [['Which', 0],\n",
    "    ['is', 6],\n",
    "    ['the', 9],\n",
    "    ['major', 13],\n",
    "    ['RNA', 19],\n",
    "    ['editing', 23],\n",
    "    ['enzyme', 31],\n",
    "    ['in', 38],\n",
    "    ['Drosophila', 41],\n",
    "    ['melanogaster', 52],\n",
    "    ['?', 64]]\n",
    "tokens = [x[0] for x in tokens_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "def get_token_idxs(string: str, tokens: List[str]) -> List[List]:\n",
    "    tokens_idxs = []\n",
    "    prev_token_idx = 0\n",
    "    for token in tokens:\n",
    "        idx = string.find(token, prev_token_idx)\n",
    "        if idx == -1:\n",
    "            idx = prev_token_idx\n",
    "        tokens_idxs.append([token, idx])\n",
    "        prev_token_idx = idx + 1\n",
    "    assert len(tokens_idxs) == len(tokens)\n",
    "    return tokens_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['``', 0],\n",
       " ['What', 2],\n",
       " ['does', 7],\n",
       " ['RNA', 12],\n",
       " ['editing', 16],\n",
       " ['enzyme', 24],\n",
       " ['do', 31],\n",
       " ['?', 33],\n",
       " ['``', 34],\n",
       " ['What', 36],\n",
       " ['is', 41],\n",
       " ['the', 44],\n",
       " ['difference', 48],\n",
       " ['between', 59]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_idxs('\" What does RNA editing enzyme do? \"What is the difference between', [\n",
    "    '``', \n",
    "    'What',\n",
    "    'does',\n",
    "    'RNA',\n",
    "    'editing',\n",
    "    'enzyme',\n",
    "    'do',\n",
    "    '?',\n",
    "    '``',\n",
    "    'What',\n",
    "    'is',\n",
    "    'the',\n",
    "    'difference',\n",
    "    'between'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [['What', 0],\n",
    "#  ['does', 5],\n",
    "#  ['RNA', 10],\n",
    "#  ['editing', 14],\n",
    "#  ['enzyme', 22],\n",
    "#  ['do', 29],\n",
    "#  ['?', 31],\n",
    "#  ['What', 33],\n",
    "#  ['is', 38],\n",
    "#  ['the', 41],\n",
    "#  ['difference', 45],\n",
    "#  ['between', 56]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['``', 0],\n",
       " ['What', 1],\n",
       " ['does', 6],\n",
       " ['RNA', 11],\n",
       " ['editing', 15],\n",
       " ['enzyme', 23],\n",
       " ['do', 30],\n",
       " ['?', 32],\n",
       " ['``', 33],\n",
       " ['What', 35],\n",
       " ['is', 40],\n",
       " ['the', 43],\n",
       " ['difference', 47],\n",
       " ['between', 58]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.find('W', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"Drosophila melanogaster has a single Adar gene encoding a protein related to mammalian ADAR2 that edits transcripts encoding glutamate receptor subunits. We describe the structure of the Drosophila Adar locus and use ModENCODE information to supplement published data on Adar gene transcription, and splicing. We discuss the roles of ADAR in Drosophila in terms of the two main types of RNA molecules edited and roles of ADARs as RNA-binding proteins. Site-specific RNA editing events in transcripts encoding ion channel subunits were initially found serendipitously and subsequent directed searches for editing sites and transcriptome sequencing have now led to 972 edited sites being identified in 597 transcripts. Four percent of D. melanogaster transcripts are site-specifically edited and these encode a wide range of largely membrane-associated proteins expressed particularly in CNS. Electrophysiological studies on the effects of specific RNA editing events on ion channel subunits do not suggest that loss of RNA editing events in ion channels consistently produce a particular outcome such as making Adar mutant neurons more excitable. This possibility would have been consistent with neurodegeneration seen in Adar mutant fly brains. A further set of ADAR targets are dsRNA intermediates in siRNA generation, derived from transposons and from structured RNA loci. Transcripts with convergent overlapping 3' ends are also edited and the first discovered instance of RNA editing in Drosophila, in the Rnp4F transcript, is an example. There is no evidence yet to show that Adar antagonizes RNA interference in Drosophila. Evidence has been obtained that catalytically inactive ADAR proteins exert effects on microRNA generation and RNA interference. Whether all effects of inactive ADARs are due to RNA-binding or to even further roles of these proteins remains to be determined.\",\n",
       " 'qas': [{'question': 'What does RNA editing enzyme do? What is the difference between',\n",
       "   'answers': ['ADAR', 'adenosine deaminase, RNA-specific'],\n",
       "   'qid': '9bb16ae9ce384988b2c0a173f93c5be4',\n",
       "   'question_tokens': [['What', 0],\n",
       "    ['does', 5],\n",
       "    ['RNA', 10],\n",
       "    ['editing', 14],\n",
       "    ['enzyme', 22],\n",
       "    ['do', 29],\n",
       "    ['?', 31],\n",
       "    ['What', 33],\n",
       "    ['is', 38],\n",
       "    ['the', 41],\n",
       "    ['difference', 45],\n",
       "    ['between', 56]],\n",
       "   'detected_answers': [{'text': 'ADAR',\n",
       "     'token_spans': [[272, 272],\n",
       "      [29, 29],\n",
       "      [5, 5],\n",
       "      [202, 202],\n",
       "      [52, 52],\n",
       "      [40, 40],\n",
       "      [258, 258],\n",
       "      [193, 193],\n",
       "      [177, 177]],\n",
       "     'char_spans': [[1685, 1688],\n",
       "      [198, 201],\n",
       "      [37, 40],\n",
       "      [1262, 1265],\n",
       "      [334, 337],\n",
       "      [271, 274],\n",
       "      [1581, 1584],\n",
       "      [1221, 1224],\n",
       "      [1110, 1113]]}],\n",
       "   'question_original': 'Which is the major RNA editing enzyme in Drosophila melanogaster?',\n",
       "   'question_tokens_original': [['Which', 0],\n",
       "    ['is', 6],\n",
       "    ['the', 9],\n",
       "    ['major', 13],\n",
       "    ['RNA', 19],\n",
       "    ['editing', 23],\n",
       "    ['enzyme', 31],\n",
       "    ['in', 38],\n",
       "    ['Drosophila', 41],\n",
       "    ['melanogaster', 52],\n",
       "    ['?', 64]],\n",
       "   'question_is_paraphrased': True}],\n",
       " 'context_tokens': [['Drosophila', 0],\n",
       "  ['melanogaster', 11],\n",
       "  ['has', 24],\n",
       "  ['a', 28],\n",
       "  ['single', 30],\n",
       "  ['Adar', 37],\n",
       "  ['gene', 42],\n",
       "  ['encoding', 47],\n",
       "  ['a', 56],\n",
       "  ['protein', 58],\n",
       "  ['related', 66],\n",
       "  ['to', 74],\n",
       "  ['mammalian', 77],\n",
       "  ['ADAR2', 87],\n",
       "  ['that', 93],\n",
       "  ['edits', 98],\n",
       "  ['transcripts', 104],\n",
       "  ['encoding', 116],\n",
       "  ['glutamate', 125],\n",
       "  ['receptor', 135],\n",
       "  ['subunits', 144],\n",
       "  ['.', 152],\n",
       "  ['We', 154],\n",
       "  ['describe', 157],\n",
       "  ['the', 166],\n",
       "  ['structure', 170],\n",
       "  ['of', 180],\n",
       "  ['the', 183],\n",
       "  ['Drosophila', 187],\n",
       "  ['Adar', 198],\n",
       "  ['locus', 203],\n",
       "  ['and', 209],\n",
       "  ['use', 213],\n",
       "  ['ModENCODE', 217],\n",
       "  ['information', 227],\n",
       "  ['to', 239],\n",
       "  ['supplement', 242],\n",
       "  ['published', 253],\n",
       "  ['data', 263],\n",
       "  ['on', 268],\n",
       "  ['Adar', 271],\n",
       "  ['gene', 276],\n",
       "  ['transcription', 281],\n",
       "  [',', 294],\n",
       "  ['and', 296],\n",
       "  ['splicing', 300],\n",
       "  ['.', 308],\n",
       "  ['We', 310],\n",
       "  ['discuss', 313],\n",
       "  ['the', 321],\n",
       "  ['roles', 325],\n",
       "  ['of', 331],\n",
       "  ['ADAR', 334],\n",
       "  ['in', 339],\n",
       "  ['Drosophila', 342],\n",
       "  ['in', 353],\n",
       "  ['terms', 356],\n",
       "  ['of', 362],\n",
       "  ['the', 365],\n",
       "  ['two', 369],\n",
       "  ['main', 373],\n",
       "  ['types', 378],\n",
       "  ['of', 384],\n",
       "  ['RNA', 387],\n",
       "  ['molecules', 391],\n",
       "  ['edited', 401],\n",
       "  ['and', 408],\n",
       "  ['roles', 412],\n",
       "  ['of', 418],\n",
       "  ['ADARs', 421],\n",
       "  ['as', 427],\n",
       "  ['RNA', 430],\n",
       "  ['-', 433],\n",
       "  ['binding', 434],\n",
       "  ['proteins', 442],\n",
       "  ['.', 450],\n",
       "  ['Site', 452],\n",
       "  ['-', 456],\n",
       "  ['specific', 457],\n",
       "  ['RNA', 466],\n",
       "  ['editing', 470],\n",
       "  ['events', 478],\n",
       "  ['in', 485],\n",
       "  ['transcripts', 488],\n",
       "  ['encoding', 500],\n",
       "  ['ion', 509],\n",
       "  ['channel', 513],\n",
       "  ['subunits', 521],\n",
       "  ['were', 530],\n",
       "  ['initially', 535],\n",
       "  ['found', 545],\n",
       "  ['serendipitously', 551],\n",
       "  ['and', 567],\n",
       "  ['subsequent', 571],\n",
       "  ['directed', 582],\n",
       "  ['searches', 591],\n",
       "  ['for', 600],\n",
       "  ['editing', 604],\n",
       "  ['sites', 612],\n",
       "  ['and', 618],\n",
       "  ['transcriptome', 622],\n",
       "  ['sequencing', 636],\n",
       "  ['have', 647],\n",
       "  ['now', 652],\n",
       "  ['led', 656],\n",
       "  ['to', 660],\n",
       "  ['972', 663],\n",
       "  ['edited', 667],\n",
       "  ['sites', 674],\n",
       "  ['being', 680],\n",
       "  ['identified', 686],\n",
       "  ['in', 697],\n",
       "  ['597', 700],\n",
       "  ['transcripts', 704],\n",
       "  ['.', 715],\n",
       "  ['Four', 717],\n",
       "  ['percent', 722],\n",
       "  ['of', 730],\n",
       "  ['D.', 733],\n",
       "  ['melanogaster', 736],\n",
       "  ['transcripts', 749],\n",
       "  ['are', 761],\n",
       "  ['site', 765],\n",
       "  ['-', 769],\n",
       "  ['specifically', 770],\n",
       "  ['edited', 783],\n",
       "  ['and', 790],\n",
       "  ['these', 794],\n",
       "  ['encode', 800],\n",
       "  ['a', 807],\n",
       "  ['wide', 809],\n",
       "  ['range', 814],\n",
       "  ['of', 820],\n",
       "  ['largely', 823],\n",
       "  ['membrane', 831],\n",
       "  ['-', 839],\n",
       "  ['associated', 840],\n",
       "  ['proteins', 851],\n",
       "  ['expressed', 860],\n",
       "  ['particularly', 870],\n",
       "  ['in', 883],\n",
       "  ['CNS', 886],\n",
       "  ['.', 889],\n",
       "  ['Electrophysiological', 891],\n",
       "  ['studies', 912],\n",
       "  ['on', 920],\n",
       "  ['the', 923],\n",
       "  ['effects', 927],\n",
       "  ['of', 935],\n",
       "  ['specific', 938],\n",
       "  ['RNA', 947],\n",
       "  ['editing', 951],\n",
       "  ['events', 959],\n",
       "  ['on', 966],\n",
       "  ['ion', 969],\n",
       "  ['channel', 973],\n",
       "  ['subunits', 981],\n",
       "  ['do', 990],\n",
       "  ['not', 993],\n",
       "  ['suggest', 997],\n",
       "  ['that', 1005],\n",
       "  ['loss', 1010],\n",
       "  ['of', 1015],\n",
       "  ['RNA', 1018],\n",
       "  ['editing', 1022],\n",
       "  ['events', 1030],\n",
       "  ['in', 1037],\n",
       "  ['ion', 1040],\n",
       "  ['channels', 1044],\n",
       "  ['consistently', 1053],\n",
       "  ['produce', 1066],\n",
       "  ['a', 1074],\n",
       "  ['particular', 1076],\n",
       "  ['outcome', 1087],\n",
       "  ['such', 1095],\n",
       "  ['as', 1100],\n",
       "  ['making', 1103],\n",
       "  ['Adar', 1110],\n",
       "  ['mutant', 1115],\n",
       "  ['neurons', 1122],\n",
       "  ['more', 1130],\n",
       "  ['excitable', 1135],\n",
       "  ['.', 1144],\n",
       "  ['This', 1146],\n",
       "  ['possibility', 1151],\n",
       "  ['would', 1163],\n",
       "  ['have', 1169],\n",
       "  ['been', 1174],\n",
       "  ['consistent', 1179],\n",
       "  ['with', 1190],\n",
       "  ['neurodegeneration', 1195],\n",
       "  ['seen', 1213],\n",
       "  ['in', 1218],\n",
       "  ['Adar', 1221],\n",
       "  ['mutant', 1226],\n",
       "  ['fly', 1233],\n",
       "  ['brains', 1237],\n",
       "  ['.', 1243],\n",
       "  ['A', 1245],\n",
       "  ['further', 1247],\n",
       "  ['set', 1255],\n",
       "  ['of', 1259],\n",
       "  ['ADAR', 1262],\n",
       "  ['targets', 1267],\n",
       "  ['are', 1275],\n",
       "  ['dsRNA', 1279],\n",
       "  ['intermediates', 1285],\n",
       "  ['in', 1299],\n",
       "  ['siRNA', 1302],\n",
       "  ['generation', 1308],\n",
       "  [',', 1318],\n",
       "  ['derived', 1320],\n",
       "  ['from', 1328],\n",
       "  ['transposons', 1333],\n",
       "  ['and', 1345],\n",
       "  ['from', 1349],\n",
       "  ['structured', 1354],\n",
       "  ['RNA', 1365],\n",
       "  ['loci', 1369],\n",
       "  ['.', 1373],\n",
       "  ['Transcripts', 1375],\n",
       "  ['with', 1387],\n",
       "  ['convergent', 1392],\n",
       "  ['overlapping', 1403],\n",
       "  ['3', 1415],\n",
       "  [\"'\", 1416],\n",
       "  ['ends', 1418],\n",
       "  ['are', 1423],\n",
       "  ['also', 1427],\n",
       "  ['edited', 1432],\n",
       "  ['and', 1439],\n",
       "  ['the', 1443],\n",
       "  ['first', 1447],\n",
       "  ['discovered', 1453],\n",
       "  ['instance', 1464],\n",
       "  ['of', 1473],\n",
       "  ['RNA', 1476],\n",
       "  ['editing', 1480],\n",
       "  ['in', 1488],\n",
       "  ['Drosophila', 1491],\n",
       "  [',', 1501],\n",
       "  ['in', 1503],\n",
       "  ['the', 1506],\n",
       "  ['Rnp4F', 1510],\n",
       "  ['transcript', 1516],\n",
       "  [',', 1526],\n",
       "  ['is', 1528],\n",
       "  ['an', 1531],\n",
       "  ['example', 1534],\n",
       "  ['.', 1541],\n",
       "  ['There', 1543],\n",
       "  ['is', 1549],\n",
       "  ['no', 1552],\n",
       "  ['evidence', 1555],\n",
       "  ['yet', 1564],\n",
       "  ['to', 1568],\n",
       "  ['show', 1571],\n",
       "  ['that', 1576],\n",
       "  ['Adar', 1581],\n",
       "  ['antagonizes', 1586],\n",
       "  ['RNA', 1598],\n",
       "  ['interference', 1602],\n",
       "  ['in', 1615],\n",
       "  ['Drosophila', 1618],\n",
       "  ['.', 1628],\n",
       "  ['Evidence', 1630],\n",
       "  ['has', 1639],\n",
       "  ['been', 1643],\n",
       "  ['obtained', 1648],\n",
       "  ['that', 1657],\n",
       "  ['catalytically', 1662],\n",
       "  ['inactive', 1676],\n",
       "  ['ADAR', 1685],\n",
       "  ['proteins', 1690],\n",
       "  ['exert', 1699],\n",
       "  ['effects', 1705],\n",
       "  ['on', 1713],\n",
       "  ['microRNA', 1716],\n",
       "  ['generation', 1725],\n",
       "  ['and', 1736],\n",
       "  ['RNA', 1740],\n",
       "  ['interference', 1744],\n",
       "  ['.', 1756],\n",
       "  ['Whether', 1758],\n",
       "  ['all', 1766],\n",
       "  ['effects', 1770],\n",
       "  ['of', 1778],\n",
       "  ['inactive', 1781],\n",
       "  ['ADARs', 1790],\n",
       "  ['are', 1796],\n",
       "  ['due', 1800],\n",
       "  ['to', 1804],\n",
       "  ['RNA', 1807],\n",
       "  ['-', 1810],\n",
       "  ['binding', 1811],\n",
       "  ['or', 1819],\n",
       "  ['to', 1822],\n",
       "  ['even', 1825],\n",
       "  ['further', 1830],\n",
       "  ['roles', 1838],\n",
       "  ['of', 1844],\n",
       "  ['these', 1847],\n",
       "  ['proteins', 1853],\n",
       "  ['remains', 1862],\n",
       "  ['to', 1870],\n",
       "  ['be', 1873],\n",
       "  ['determined', 1876],\n",
       "  ['.', 1886]]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([np.random.randint(0,4) for _ in range(1000)]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 3\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 3\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 3\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 2\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 2\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-large-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 2\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 3\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 2\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 3\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 3\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 0\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device 1\n"
     ]
    }
   ],
   "source": [
    "for train_file in [\n",
    "    'BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-large-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-multi_news-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram2.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.5-ngram1.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5.jsonl.gz',\n",
    "    'BioASQ_train-question-pegasus-xsum-chk20-mul2.0-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "    'NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th1.2-ngram1.jsonl.gz',\n",
    "]:\n",
    "    print(f'''python3 main.py --do_train_test_eval --model \"baseline\" --train_path \"datasets/{train_file}\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --use_gpu --device {np.random.randint(0,4)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_tokenize(elem['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LONDON',\n",
       " ',',\n",
       " 'England',\n",
       " '(',\n",
       " 'CNN',\n",
       " ')',\n",
       " '--',\n",
       " 'After',\n",
       " 'a',\n",
       " 'week',\n",
       " 'when',\n",
       " 'he',\n",
       " 'could',\n",
       " 'not',\n",
       " 'be',\n",
       " 'traced',\n",
       " ',',\n",
       " 'Egyptian',\n",
       " 'striker',\n",
       " 'Amir',\n",
       " 'Zaki',\n",
       " 'is',\n",
       " 'back',\n",
       " 'at',\n",
       " 'his',\n",
       " 'Premier',\n",
       " 'League',\n",
       " 'club',\n",
       " 'side',\n",
       " 'Wigan',\n",
       " 'Athletic',\n",
       " 'in',\n",
       " 'northern',\n",
       " 'England',\n",
       " '.',\n",
       " 'Wigan',\n",
       " 'and',\n",
       " 'Egypt',\n",
       " 'striker',\n",
       " 'Amir',\n",
       " 'Zaki',\n",
       " 'has',\n",
       " 'mended',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'his',\n",
       " 'club',\n",
       " 'manager',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'Wigan',\n",
       " 'manager',\n",
       " 'Steve',\n",
       " 'Bruce',\n",
       " 'the',\n",
       " 'two',\n",
       " 'have',\n",
       " 'patched',\n",
       " 'up',\n",
       " 'their',\n",
       " 'differences',\n",
       " 'after',\n",
       " 'he',\n",
       " 'launched',\n",
       " 'a',\n",
       " 'verbal',\n",
       " 'tirade',\n",
       " 'against',\n",
       " 'the',\n",
       " '26-year',\n",
       " '-',\n",
       " 'old',\n",
       " 'striker',\n",
       " '.',\n",
       " 'Zaki',\n",
       " 'told',\n",
       " 'Al',\n",
       " '-',\n",
       " 'Hayat',\n",
       " 'TV',\n",
       " 'that',\n",
       " 'the',\n",
       " 'pair',\n",
       " '\"',\n",
       " 'ended',\n",
       " 'up',\n",
       " 'laughing',\n",
       " '\"',\n",
       " 'about',\n",
       " 'his',\n",
       " 'absence',\n",
       " '--',\n",
       " 'when',\n",
       " 'he',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'return',\n",
       " 'from',\n",
       " 'international',\n",
       " 'duty',\n",
       " 'and',\n",
       " 'had',\n",
       " 'a',\n",
       " 'hamstring',\n",
       " 'strain',\n",
       " 'which',\n",
       " 'no',\n",
       " 'one',\n",
       " 'knew',\n",
       " 'the',\n",
       " 'seriousness',\n",
       " 'of',\n",
       " '.',\n",
       " 'But',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'all',\n",
       " 'laughs',\n",
       " 'a',\n",
       " 'week',\n",
       " 'ago',\n",
       " '.',\n",
       " 'On',\n",
       " 'Wigan',\n",
       " \"'s\",\n",
       " 'club',\n",
       " 'Web',\n",
       " 'site',\n",
       " ',',\n",
       " 'Bruce',\n",
       " 'had',\n",
       " 'said',\n",
       " 'of',\n",
       " 'Zaki',\n",
       " ':',\n",
       " '\"',\n",
       " 'I',\n",
       " 'just',\n",
       " 'feel',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'time',\n",
       " 'that',\n",
       " 'we',\n",
       " 'went',\n",
       " 'public',\n",
       " 'on',\n",
       " 'just',\n",
       " 'what',\n",
       " 'a',\n",
       " 'nightmare',\n",
       " 'he',\n",
       " 'has',\n",
       " 'been',\n",
       " 'to',\n",
       " 'deal',\n",
       " 'with',\n",
       " '.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'honestly',\n",
       " 'say',\n",
       " 'that',\n",
       " 'in',\n",
       " 'all',\n",
       " 'my',\n",
       " 'time',\n",
       " 'in',\n",
       " 'football',\n",
       " 'I',\n",
       " 'have',\n",
       " 'never',\n",
       " 'worked',\n",
       " 'with',\n",
       " 'someone',\n",
       " 'as',\n",
       " 'unprofessional',\n",
       " '.',\n",
       " '\"',\n",
       " 'I',\n",
       " 'have',\n",
       " 'already',\n",
       " 'fined',\n",
       " 'him',\n",
       " 'the',\n",
       " 'maximum',\n",
       " 'allowed',\n",
       " 'but',\n",
       " 'this',\n",
       " 'just',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'have',\n",
       " 'no',\n",
       " 'effect',\n",
       " ',',\n",
       " '\"',\n",
       " 'Bruce',\n",
       " 'said',\n",
       " '.',\n",
       " 'After',\n",
       " 'giving',\n",
       " 'Zaki',\n",
       " 'a',\n",
       " 'fine',\n",
       " 'for',\n",
       " 'his',\n",
       " 'misdemeanor',\n",
       " 'the',\n",
       " 'Wigan',\n",
       " 'manager',\n",
       " 'also',\n",
       " 'revealed',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'fourth',\n",
       " 'time',\n",
       " 'he',\n",
       " 'had',\n",
       " 'gone',\n",
       " 'AWOL',\n",
       " 'after',\n",
       " 'international',\n",
       " 'duty',\n",
       " '.',\n",
       " 'Are',\n",
       " 'players',\n",
       " 'selling',\n",
       " 'their',\n",
       " 'fans',\n",
       " 'and',\n",
       " 'clubs',\n",
       " 'short',\n",
       " 'when',\n",
       " 'they',\n",
       " 'go',\n",
       " 'AWOL',\n",
       " '?',\n",
       " 'How',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'should',\n",
       " 'they',\n",
       " 'be',\n",
       " 'punished',\n",
       " 'by',\n",
       " 'clubs',\n",
       " '?',\n",
       " 'Zaki',\n",
       " \"'s\",\n",
       " 'case',\n",
       " 'certainly',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'the',\n",
       " 'first',\n",
       " 'high',\n",
       " 'profile',\n",
       " 'instance',\n",
       " 'of',\n",
       " 'a',\n",
       " 'player',\n",
       " 'going',\n",
       " 'missing',\n",
       " '.',\n",
       " 'Inter',\n",
       " 'Milan',\n",
       " 'striker',\n",
       " 'Adriano',\n",
       " 'sparked',\n",
       " 'kidnap',\n",
       " 'fears',\n",
       " 'after',\n",
       " 'failing',\n",
       " 'to',\n",
       " 'return',\n",
       " 'earlier',\n",
       " 'this',\n",
       " 'month',\n",
       " ',',\n",
       " 'following',\n",
       " 'a',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'qualifier',\n",
       " 'in',\n",
       " 'South',\n",
       " 'America',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'the',\n",
       " 'Brazilian',\n",
       " 'had',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'report',\n",
       " 'back',\n",
       " 'to',\n",
       " 'his',\n",
       " 'club',\n",
       " 'following',\n",
       " 'international',\n",
       " 'duty',\n",
       " '.',\n",
       " 'After',\n",
       " 'a',\n",
       " 'two',\n",
       " '-',\n",
       " 'week',\n",
       " 'absence',\n",
       " ',',\n",
       " 'Adriano',\n",
       " 'later',\n",
       " 'announced',\n",
       " 'he',\n",
       " 'was',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'break',\n",
       " 'from',\n",
       " 'professional',\n",
       " 'football',\n",
       " 'at',\n",
       " 'a',\n",
       " 'news',\n",
       " 'conference',\n",
       " 'in',\n",
       " 'Brazil',\n",
       " '.',\n",
       " 'He',\n",
       " 'told',\n",
       " 'reporters',\n",
       " ':',\n",
       " '\"',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'lost',\n",
       " 'the',\n",
       " 'happiness',\n",
       " 'of',\n",
       " 'playing',\n",
       " '.',\n",
       " 'I',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'like',\n",
       " 'to',\n",
       " 'go',\n",
       " 'back',\n",
       " 'to',\n",
       " 'Italy',\n",
       " ',',\n",
       " 'I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'live',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'here',\n",
       " 'in',\n",
       " 'Brazil',\n",
       " '.',\n",
       " '\"',\n",
       " 'I',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'if',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'stay',\n",
       " 'for',\n",
       " 'one',\n",
       " ',',\n",
       " 'two',\n",
       " 'or',\n",
       " 'three',\n",
       " 'months',\n",
       " 'without',\n",
       " 'playing',\n",
       " '.',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'rethink',\n",
       " 'my',\n",
       " 'career',\n",
       " '.',\n",
       " '\"',\n",
       " 'Other',\n",
       " 'notable',\n",
       " 'cases',\n",
       " 'include',\n",
       " 'Nigerian',\n",
       " 'forward',\n",
       " 'Ayegbeni',\n",
       " 'Yakubu',\n",
       " ',',\n",
       " 'who',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'return',\n",
       " 'to',\n",
       " 'club',\n",
       " 'duty',\n",
       " 'at',\n",
       " 'Premier',\n",
       " 'League',\n",
       " 'side',\n",
       " 'Everton',\n",
       " 'after',\n",
       " 'the',\n",
       " 'African',\n",
       " 'Cup',\n",
       " 'of',\n",
       " 'Nations',\n",
       " 'last',\n",
       " 'year',\n",
       " '.',\n",
       " 'When',\n",
       " 'he',\n",
       " 'returned',\n",
       " 'to',\n",
       " 'Everton',\n",
       " ',',\n",
       " 'Yakubu',\n",
       " 'was',\n",
       " 'hit',\n",
       " 'with',\n",
       " 'a',\n",
       " 'maximum',\n",
       " '£',\n",
       " '80,000',\n",
       " 'fine',\n",
       " '.',\n",
       " 'Manager',\n",
       " 'David',\n",
       " 'Moyes',\n",
       " 'said',\n",
       " 'at',\n",
       " 'a',\n",
       " 'news',\n",
       " 'conference',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " ':',\n",
       " \"'\",\n",
       " 'Yakubu',\n",
       " \"'s\",\n",
       " 'back',\n",
       " 'in',\n",
       " 'it',\n",
       " 'now',\n",
       " '.',\n",
       " 'That',\n",
       " 'episode',\n",
       " 'has',\n",
       " 'ended',\n",
       " '.',\n",
       " 'He',\n",
       " 'let',\n",
       " 'us',\n",
       " 'down',\n",
       " 'by',\n",
       " 'not',\n",
       " 'coming',\n",
       " 'back',\n",
       " '.',\n",
       " 'But',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'over',\n",
       " 'and',\n",
       " 'we',\n",
       " \"'ve\",\n",
       " 'moved',\n",
       " 'on',\n",
       " '.',\n",
       " '\"',\n",
       " 'German',\n",
       " 'club',\n",
       " 'Schalke',\n",
       " 'fined',\n",
       " 'defender',\n",
       " 'Rafinha',\n",
       " 'a',\n",
       " 'record',\n",
       " '$',\n",
       " '1million',\n",
       " 'for',\n",
       " 'making',\n",
       " 'an',\n",
       " 'unauthorized',\n",
       " 'trip',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Beijing',\n",
       " 'Olympic',\n",
       " 'Games',\n",
       " 'and',\n",
       " 'spending',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " '35',\n",
       " 'days',\n",
       " 'away',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'bizarre',\n",
       " 'examples',\n",
       " 'was',\n",
       " 'that',\n",
       " 'of',\n",
       " 'Moroccan',\n",
       " 'defender',\n",
       " 'Youssef',\n",
       " 'Rossi',\n",
       " ',',\n",
       " 'who',\n",
       " 'surprised',\n",
       " 'everyone',\n",
       " 'when',\n",
       " 'he',\n",
       " 'returned',\n",
       " 'to',\n",
       " 'training',\n",
       " 'at',\n",
       " 'Dunfermline',\n",
       " 'Athletic',\n",
       " 'a',\n",
       " 'year',\n",
       " 'after',\n",
       " 'having',\n",
       " 'his',\n",
       " 'wages',\n",
       " 'stopped',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Scottish',\n",
       " 'club',\n",
       " '.',\n",
       " 'Rossi',\n",
       " 'had',\n",
       " 'previously',\n",
       " 'gone',\n",
       " 'AWOL',\n",
       " 'from',\n",
       " 'the',\n",
       " 'club',\n",
       " 'and',\n",
       " 'returned',\n",
       " 'to',\n",
       " 'training',\n",
       " 'with',\n",
       " 'Raja',\n",
       " 'Casablanca',\n",
       " 'back',\n",
       " 'in',\n",
       " 'his',\n",
       " 'homeland',\n",
       " '.']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem = elems[2]\n",
    "[x[0] for x in elem['context_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz': 206it [00:00, 2050.44it/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11429\n",
      "{'header': {'dataset': 'NewsQA', 'split': 'train'}}\n",
      "{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'qas': [{'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#0', 'question': 'Do we have such a large number of the murdered children?', 'answers': ['19'], 'qid': 'da0e6b66e04d439fa1ba23c32de07e50', 'question_tokens': [['Do', 0], ['we', 0], ['have', 0], ['such', 0], ['a', 0], ['large', 0], ['number', 0], ['of', 0], ['the', 0], ['murdered', 0], ['children', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'What was the amount of children murdered?', 'question_tokens_original': [['What', 0], ['was', 5], ['the', 9], ['amount', 13], ['of', 20], ['children', 23], ['murdered', 32], ['?', 40]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#1', 'question': 'How long before he is sentenced To Deportation.', 'answers': ['February.'], 'qid': '724f6eb9a2814e4fb2d7d8e4de846073', 'question_tokens': [['How', 0], ['long', 0], ['before', 0], ['he', 0], ['is', 0], ['sentenced', 0], ['To', 0], ['Deportation', 0], ['.', 0]], 'detected_answers': [{'text': 'February.', 'char_spans': [[261, 269]], 'token_spans': [[53, 54]]}], 'question_original': 'When was Pandher sentenced to death?', 'question_tokens_original': [['When', 0], ['was', 5], ['Pandher', 9], ['sentenced', 17], ['to', 27], ['death', 30], ['?', 35]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#2', 'question': 'Which crime did Mrs Moninder Singh Pandher escape with acquit from that court?', 'answers': ['rape and murder'], 'qid': 'd64cbb90e5134081acfa83d3e702408c', 'question_tokens': [['Which', 0], ['crime', 0], ['did', 0], ['Mrs', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0], ['escape', 0], ['with', 0], ['acquit', 0], ['from', 0], ['that', 0], ['court', 0], ['?', 0]], 'detected_answers': [{'text': 'rape and murder', 'char_spans': [[624, 638]], 'token_spans': [[119, 121]]}], 'question_original': 'The court aquitted Moninder Singh Pandher of what crime?', 'question_tokens_original': [['The', 0], ['court', 4], ['aquitted', 10], ['Moninder', 19], ['Singh', 28], ['Pandher', 34], ['of', 42], ['what', 45], ['crime', 50], ['?', 55]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#3', 'question': 'He has been acquitted.', 'answers': ['Moninder Singh Pandher'], 'qid': 'fd7177ee6f1f4d62becd983a0305f503', 'question_tokens': [['He', 0], ['has', 0], ['been', 0], ['acquitted', 0], ['.', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was acquitted', 'question_tokens_original': [['who', 0], ['was', 4], ['acquitted', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#4', 'question': 'The Convicted Man.', 'answers': ['Moninder Singh Pandher'], 'qid': 'cd25c69f631349748ccdeccaace66463', 'question_tokens': [['The', 0], ['Convicted', 0], ['Man', 0], ['.', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was sentenced', 'question_tokens_original': [['who', 0], ['was', 4], ['sentenced', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#5', 'question': 'Why Was Moninder Singh Pandher Acquitted As a Trialmate?', 'answers': ['the killing of a teen'], 'qid': 'b434021eb85d4c1b9fffcfa26dc71b97', 'question_tokens': [['Why', 0], ['Was', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0], ['Acquitted', 0], ['As', 0], ['a', 0], ['Trialmate', 0], ['?', 0]], 'detected_answers': [{'text': 'the killing of a teen', 'char_spans': [[129, 149]], 'token_spans': [[25, 29]]}], 'question_original': 'What was Moninder Singh Pandher acquitted for?', 'question_tokens_original': [['What', 0], ['was', 5], ['Moninder', 9], ['Singh', 18], ['Pandher', 24], ['acquitted', 32], ['for', 42], ['?', 45]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#6', 'question': 'In February, Who Was Sentenced to Death?', 'answers': ['Moninder Singh Pandher'], 'qid': '5b2631c1d21044a9bb1b2c22d118ad97', 'question_tokens': [['In', 0], ['February', 0], [',', 0], ['Who', 0], ['Was', 0], ['Sentenced', 0], ['to', 0], ['Death', 0], ['?', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'Who was sentenced to death in February?', 'question_tokens_original': [['Who', 0], ['was', 4], ['sentenced', 8], ['to', 18], ['death', 21], ['in', 27], ['February', 30], ['?', 38]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#7', 'question': 'How many people have died', 'answers': ['19'], 'qid': '79e3ef1435f34886888ebf84b12364c7', 'question_tokens': [['How', 0], ['many', 0], ['people', 0], ['have', 0], ['died', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'how many people died', 'question_tokens_original': [['how', 0], ['many', 4], ['people', 9], ['died', 16]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#8', 'question': 'How Number of Children and Young Women Murdered??', 'answers': ['19'], 'qid': 'fd571dcf979c4b9aa3d5da73c7668e38', 'question_tokens': [['How', 0], ['Number', 0], ['of', 0], ['Children', 0], ['and', 0], ['Young', 0], ['Women', 0], ['Murdered', 0], ['?', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'How many children and young women were murdered?', 'question_tokens_original': [['How', 0], ['many', 4], ['children', 9], ['and', 18], ['young', 22], ['women', 28], ['were', 34], ['murdered', 39], ['?', 47]], 'question_is_paraphrased': True}], 'context_tokens': [['NEW', 0], ['DELHI', 4], [',', 9], ['India', 11], ['(', 17], ['CNN', 18], [')', 21], ['--', 23], ['A', 26], ['high', 28], ['court', 33], ['in', 39], ['northern', 42], ['India', 51], ['on', 57], ['Friday', 60], ['acquitted', 67], ['a', 77], ['wealthy', 79], ['businessman', 87], ['facing', 99], ['the', 106], ['death', 110], ['sentence', 116], ['for', 125], ['the', 129], ['killing', 133], ['of', 141], ['a', 144], ['teen', 146], ['in', 151], ['a', 154], ['case', 156], ['dubbed', 161], ['\"', 168], ['the', 169], ['house', 173], ['of', 179], ['horrors', 182], ['.', 189], ['\"', 190], ['Moninder', 195], ['Singh', 204], ['Pandher', 210], ['was', 218], ['sentenced', 222], ['to', 232], ['death', 235], ['by', 241], ['a', 244], ['lower', 246], ['court', 252], ['in', 258], ['February', 261], ['.', 269], ['The', 274], ['teen', 278], ['was', 283], ['one', 287], ['of', 291], ['19', 294], ['victims', 297], ['--', 305], ['children', 308], ['and', 317], ['young', 321], ['women', 327], ['--', 333], ['in', 336], ['one', 339], ['of', 343], ['the', 346], ['most', 350], ['gruesome', 355], ['serial', 364], ['killings', 371], ['in', 380], ['India', 383], ['in', 389], ['recent', 392], ['years', 399], ['.', 404], ['The', 409], ['Allahabad', 413], ['high', 423], ['court', 428], ['has', 434], ['acquitted', 438], ['Moninder', 448], ['Singh', 457], ['Pandher', 463], [',', 470], ['his', 472], ['lawyer', 476], ['Sikandar', 483], ['B.', 492], ['Kochar', 495], ['told', 502], ['CNN', 507], ['.', 510], ['Pandher', 515], ['and', 523], ['his', 527], ['domestic', 531], ['employee', 540], ['Surinder', 549], ['Koli', 558], ['were', 563], ['sentenced', 568], ['to', 578], ['death', 581], ['in', 587], ['February', 590], ['by', 599], ['a', 602], ['lower', 604], ['court', 610], ['for', 616], ['the', 620], ['rape', 624], ['and', 629], ['murder', 633], ['of', 640], ['the', 643], ['14-year', 647], ['-', 654], ['old', 655], ['.', 658], ['The', 663], ['high', 667], ['court', 672], ['upheld', 678], ['Koli', 685], [\"'s\", 689], ['death', 692], ['sentence', 698], [',', 706], ['Kochar', 708], ['said', 715], ['.', 719], ['The', 724], ['two', 728], ['were', 732], ['arrested', 737], ['two', 746], ['years', 750], ['ago', 756], ['after', 760], ['body', 766], ['parts', 771], ['packed', 777], ['in', 784], ['plastic', 787], ['bags', 795], ['were', 800], ['found', 805], ['near', 811], ['their', 816], ['home', 822], ['in', 827], ['Noida', 830], [',', 835], ['a', 837], ['New', 839], ['Delhi', 843], ['suburb', 849], ['.', 855], ['Their', 857], ['home', 863], ['was', 868], ['later', 872], ['dubbed', 878], ['a', 885], ['\"', 887], ['house', 888], ['of', 894], ['horrors', 897], ['\"', 904], ['by', 906], ['the', 909], ['Indian', 913], ['media', 920], ['.', 925], ['Pandher', 930], ['was', 938], ['not', 942], ['named', 946], ['a', 952], ['main', 954], ['suspect', 959], ['by', 967], ['investigators', 970], ['initially', 984], [',', 993], ['but', 995], ['was', 999], ['summoned', 1003], ['as', 1012], ['co', 1015], ['-', 1017], ['accused', 1018], ['during', 1026], ['the', 1033], ['trial', 1037], [',', 1042], ['Kochar', 1044], ['said', 1051], ['.', 1055], ['Kochar', 1060], ['said', 1067], ['his', 1072], ['client', 1076], ['was', 1083], ['in', 1087], ['Australia', 1090], ['when', 1100], ['the', 1105], ['teen', 1109], ['was', 1114], ['raped', 1118], ['and', 1124], ['killed', 1128], ['.', 1134], ['Pandher', 1139], ['faces', 1147], ['trial', 1153], ['in', 1159], ['the', 1162], ['remaining', 1166], ['18', 1176], ['killings', 1179], ['and', 1188], ['could', 1192], ['remain', 1198], ['in', 1205], ['custody', 1208], [',', 1215], ['the', 1217], ['attorney', 1221], ['said', 1230], ['.', 1234]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz': 209it [00:00, 2083.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11429\n",
      "{'header': {'dataset': 'NewsQA', 'split': 'train'}}\n",
      "{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'qas': [{'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#0', 'question': 'How many murdered children were there?', 'answers': ['19'], 'qid': 'da0e6b66e04d439fa1ba23c32de07e50', 'question_tokens': [['How', 0], ['many', 0], ['murdered', 0], ['children', 0], ['were', 0], ['there', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'What was the amount of children murdered?', 'question_tokens_original': [['What', 0], ['was', 5], ['the', 9], ['amount', 13], ['of', 20], ['children', 23], ['murdered', 32], ['?', 40]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#1', 'question': 'When Was Pandher Sentenced to Death', 'answers': ['February.'], 'qid': '724f6eb9a2814e4fb2d7d8e4de846073', 'question_tokens': [['When', 0], ['Was', 0], ['Pandher', 0], ['Sentenced', 0], ['to', 0], ['Death', 0]], 'detected_answers': [{'text': 'February.', 'char_spans': [[261, 269]], 'token_spans': [[53, 54]]}], 'question_original': 'When was Pandher sentenced to death?', 'question_tokens_original': [['When', 0], ['was', 5], ['Pandher', 9], ['sentenced', 17], ['to', 27], ['death', 30], ['?', 35]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#2', 'question': 'What crime did the Court acquit Moninder Singh Pandher?', 'answers': ['rape and murder'], 'qid': 'd64cbb90e5134081acfa83d3e702408c', 'question_tokens': [['What', 0], ['crime', 0], ['did', 0], ['the', 0], ['Court', 0], ['acquit', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0], ['?', 0]], 'detected_answers': [{'text': 'rape and murder', 'char_spans': [[624, 638]], 'token_spans': [[119, 121]]}], 'question_original': 'The court aquitted Moninder Singh Pandher of what crime?', 'question_tokens_original': [['The', 0], ['court', 4], ['aquitted', 10], ['Moninder', 19], ['Singh', 28], ['Pandher', 34], ['of', 42], ['what', 45], ['crime', 50], ['?', 55]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#3', 'question': 'Acquitted', 'answers': ['Moninder Singh Pandher'], 'qid': 'fd7177ee6f1f4d62becd983a0305f503', 'question_tokens': [['Acquitted', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was acquitted', 'question_tokens_original': [['who', 0], ['was', 4], ['acquitted', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#4', 'question': 'Sentenced', 'answers': ['Moninder Singh Pandher'], 'qid': 'cd25c69f631349748ccdeccaace66463', 'question_tokens': [['Sentenced', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was sentenced', 'question_tokens_original': [['who', 0], ['was', 4], ['sentenced', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#5', 'question': 'Why has Moninder Singh Pandher been acquitted?', 'answers': ['the killing of a teen'], 'qid': 'b434021eb85d4c1b9fffcfa26dc71b97', 'question_tokens': [['Why', 0], ['has', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0], ['been', 0], ['acquitted', 0], ['?', 0]], 'detected_answers': [{'text': 'the killing of a teen', 'char_spans': [[129, 149]], 'token_spans': [[25, 29]]}], 'question_original': 'What was Moninder Singh Pandher acquitted for?', 'question_tokens_original': [['What', 0], ['was', 5], ['Moninder', 9], ['Singh', 18], ['Pandher', 24], ['acquitted', 32], ['for', 42], ['?', 45]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#6', 'question': 'Who Was Sentenced to Death on Feb.', 'answers': ['Moninder Singh Pandher'], 'qid': '5b2631c1d21044a9bb1b2c22d118ad97', 'question_tokens': [['Who', 0], ['Was', 0], ['Sentenced', 0], ['to', 0], ['Death', 0], ['on', 0], ['Feb', 0], ['.', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'Who was sentenced to death in February?', 'question_tokens_original': [['Who', 0], ['was', 4], ['sentenced', 8], ['to', 18], ['death', 21], ['in', 27], ['February', 30], ['?', 38]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#7', 'question': 'How Many People Died', 'answers': ['19'], 'qid': '79e3ef1435f34886888ebf84b12364c7', 'question_tokens': [['How', 0], ['Many', 0], ['People', 0], ['Died', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'how many people died', 'question_tokens_original': [['how', 0], ['many', 4], ['people', 9], ['died', 16]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#8', 'question': 'How Many Children and Young Women Was Murdered?', 'answers': ['19'], 'qid': 'fd571dcf979c4b9aa3d5da73c7668e38', 'question_tokens': [['How', 0], ['Many', 0], ['Children', 0], ['and', 0], ['Young', 0], ['Women', 0], ['Was', 0], ['Murdered', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'How many children and young women were murdered?', 'question_tokens_original': [['How', 0], ['many', 4], ['children', 9], ['and', 18], ['young', 22], ['women', 28], ['were', 34], ['murdered', 39], ['?', 47]], 'question_is_paraphrased': True}], 'context_tokens': [['NEW', 0], ['DELHI', 4], [',', 9], ['India', 11], ['(', 17], ['CNN', 18], [')', 21], ['--', 23], ['A', 26], ['high', 28], ['court', 33], ['in', 39], ['northern', 42], ['India', 51], ['on', 57], ['Friday', 60], ['acquitted', 67], ['a', 77], ['wealthy', 79], ['businessman', 87], ['facing', 99], ['the', 106], ['death', 110], ['sentence', 116], ['for', 125], ['the', 129], ['killing', 133], ['of', 141], ['a', 144], ['teen', 146], ['in', 151], ['a', 154], ['case', 156], ['dubbed', 161], ['\"', 168], ['the', 169], ['house', 173], ['of', 179], ['horrors', 182], ['.', 189], ['\"', 190], ['Moninder', 195], ['Singh', 204], ['Pandher', 210], ['was', 218], ['sentenced', 222], ['to', 232], ['death', 235], ['by', 241], ['a', 244], ['lower', 246], ['court', 252], ['in', 258], ['February', 261], ['.', 269], ['The', 274], ['teen', 278], ['was', 283], ['one', 287], ['of', 291], ['19', 294], ['victims', 297], ['--', 305], ['children', 308], ['and', 317], ['young', 321], ['women', 327], ['--', 333], ['in', 336], ['one', 339], ['of', 343], ['the', 346], ['most', 350], ['gruesome', 355], ['serial', 364], ['killings', 371], ['in', 380], ['India', 383], ['in', 389], ['recent', 392], ['years', 399], ['.', 404], ['The', 409], ['Allahabad', 413], ['high', 423], ['court', 428], ['has', 434], ['acquitted', 438], ['Moninder', 448], ['Singh', 457], ['Pandher', 463], [',', 470], ['his', 472], ['lawyer', 476], ['Sikandar', 483], ['B.', 492], ['Kochar', 495], ['told', 502], ['CNN', 507], ['.', 510], ['Pandher', 515], ['and', 523], ['his', 527], ['domestic', 531], ['employee', 540], ['Surinder', 549], ['Koli', 558], ['were', 563], ['sentenced', 568], ['to', 578], ['death', 581], ['in', 587], ['February', 590], ['by', 599], ['a', 602], ['lower', 604], ['court', 610], ['for', 616], ['the', 620], ['rape', 624], ['and', 629], ['murder', 633], ['of', 640], ['the', 643], ['14-year', 647], ['-', 654], ['old', 655], ['.', 658], ['The', 663], ['high', 667], ['court', 672], ['upheld', 678], ['Koli', 685], [\"'s\", 689], ['death', 692], ['sentence', 698], [',', 706], ['Kochar', 708], ['said', 715], ['.', 719], ['The', 724], ['two', 728], ['were', 732], ['arrested', 737], ['two', 746], ['years', 750], ['ago', 756], ['after', 760], ['body', 766], ['parts', 771], ['packed', 777], ['in', 784], ['plastic', 787], ['bags', 795], ['were', 800], ['found', 805], ['near', 811], ['their', 816], ['home', 822], ['in', 827], ['Noida', 830], [',', 835], ['a', 837], ['New', 839], ['Delhi', 843], ['suburb', 849], ['.', 855], ['Their', 857], ['home', 863], ['was', 868], ['later', 872], ['dubbed', 878], ['a', 885], ['\"', 887], ['house', 888], ['of', 894], ['horrors', 897], ['\"', 904], ['by', 906], ['the', 909], ['Indian', 913], ['media', 920], ['.', 925], ['Pandher', 930], ['was', 938], ['not', 942], ['named', 946], ['a', 952], ['main', 954], ['suspect', 959], ['by', 967], ['investigators', 970], ['initially', 984], [',', 993], ['but', 995], ['was', 999], ['summoned', 1003], ['as', 1012], ['co', 1015], ['-', 1017], ['accused', 1018], ['during', 1026], ['the', 1033], ['trial', 1037], [',', 1042], ['Kochar', 1044], ['said', 1051], ['.', 1055], ['Kochar', 1060], ['said', 1067], ['his', 1072], ['client', 1076], ['was', 1083], ['in', 1087], ['Australia', 1090], ['when', 1100], ['the', 1105], ['teen', 1109], ['was', 1114], ['raped', 1118], ['and', 1124], ['killed', 1128], ['.', 1134], ['Pandher', 1139], ['faces', 1147], ['trial', 1153], ['in', 1159], ['the', 1162], ['remaining', 1166], ['18', 1176], ['killings', 1179], ['and', 1188], ['could', 1192], ['remain', 1198], ['in', 1205], ['custody', 1208], [',', 1215], ['the', 1217], ['attorney', 1221], ['said', 1230], ['.', 1234]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz': 209it [00:00, 2088.22it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11429\n",
      "{'header': {'dataset': 'NewsQA', 'split': 'train'}}\n",
      "{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'qas': [{'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#0', 'question': 'How many children were murdered? What', 'answers': ['19'], 'qid': 'da0e6b66e04d439fa1ba23c32de07e50', 'question_tokens': [['How', 0], ['many', 0], ['children', 0], ['were', 0], ['murdered', 0], ['?', 0], ['What', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'What was the amount of children murdered?', 'question_tokens_original': [['What', 0], ['was', 5], ['the', 9], ['amount', 13], ['of', 20], ['children', 23], ['murdered', 32], ['?', 40]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#1', 'question': 'Pandher was sentenced to death', 'answers': ['February.'], 'qid': '724f6eb9a2814e4fb2d7d8e4de846073', 'question_tokens': [['Pandher', 0], ['was', 0], ['sentenced', 0], ['to', 0], ['death', 0]], 'detected_answers': [{'text': 'February.', 'char_spans': [[261, 269]], 'token_spans': [[53, 54]]}], 'question_original': 'When was Pandher sentenced to death?', 'question_tokens_original': [['When', 0], ['was', 5], ['Pandher', 9], ['sentenced', 17], ['to', 27], ['death', 30], ['?', 35]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#2', 'question': 'What do you think? Share your thoughts in the comments below', 'answers': ['rape and murder'], 'qid': 'd64cbb90e5134081acfa83d3e702408c', 'question_tokens': [['What', 0], ['do', 0], ['you', 0], ['think', 0], ['?', 0], ['Share', 0], ['your', 0], ['thoughts', 0], ['in', 0], ['the', 0], ['comments', 0], ['below', 0]], 'detected_answers': [{'text': 'rape and murder', 'char_spans': [[624, 638]], 'token_spans': [[119, 121]]}], 'question_original': 'The court aquitted Moninder Singh Pandher of what crime?', 'question_tokens_original': [['The', 0], ['court', 4], ['aquitted', 10], ['Moninder', 19], ['Singh', 28], ['Pandher', 34], ['of', 42], ['what', 45], ['crime', 50], ['?', 55]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#3', 'question': 'In the', 'answers': ['Moninder Singh Pandher'], 'qid': 'fd7177ee6f1f4d62becd983a0305f503', 'question_tokens': [['In', 0], ['the', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was acquitted', 'question_tokens_original': [['who', 0], ['was', 4], ['acquitted', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#4', 'question': 'In the', 'answers': ['Moninder Singh Pandher'], 'qid': 'cd25c69f631349748ccdeccaace66463', 'question_tokens': [['In', 0], ['the', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was sentenced', 'question_tokens_original': [['who', 0], ['was', 4], ['sentenced', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#5', 'question': 'Moninder Singh Pandher acquitted in', 'answers': ['the killing of a teen'], 'qid': 'b434021eb85d4c1b9fffcfa26dc71b97', 'question_tokens': [['Moninder', 0], ['Singh', 0], ['Pandher', 0], ['acquitted', 0], ['in', 0]], 'detected_answers': [{'text': 'the killing of a teen', 'char_spans': [[129, 149]], 'token_spans': [[25, 29]]}], 'question_original': 'What was Moninder Singh Pandher acquitted for?', 'question_tokens_original': [['What', 0], ['was', 5], ['Moninder', 9], ['Singh', 18], ['Pandher', 24], ['acquitted', 32], ['for', 42], ['?', 45]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#6', 'question': 'What does the death penalty mean to you', 'answers': ['Moninder Singh Pandher'], 'qid': '5b2631c1d21044a9bb1b2c22d118ad97', 'question_tokens': [['What', 0], ['does', 0], ['the', 0], ['death', 0], ['penalty', 0], ['mean', 0], ['to', 0], ['you', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'Who was sentenced to death in February?', 'question_tokens_original': [['Who', 0], ['was', 4], ['sentenced', 8], ['to', 18], ['death', 21], ['in', 27], ['February', 30], ['?', 38]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#7', 'question': 'How many people died', 'answers': ['19'], 'qid': '79e3ef1435f34886888ebf84b12364c7', 'question_tokens': [['How', 0], ['many', 0], ['people', 0], ['died', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'how many people died', 'question_tokens_original': [['how', 0], ['many', 4], ['people', 9], ['died', 16]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#8', 'question': 'How many children and young women have been murdered?', 'answers': ['19'], 'qid': 'fd571dcf979c4b9aa3d5da73c7668e38', 'question_tokens': [['How', 0], ['many', 0], ['children', 0], ['and', 0], ['young', 0], ['women', 0], ['have', 0], ['been', 0], ['murdered', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'How many children and young women were murdered?', 'question_tokens_original': [['How', 0], ['many', 4], ['children', 9], ['and', 18], ['young', 22], ['women', 28], ['were', 34], ['murdered', 39], ['?', 47]], 'question_is_paraphrased': True}], 'context_tokens': [['NEW', 0], ['DELHI', 4], [',', 9], ['India', 11], ['(', 17], ['CNN', 18], [')', 21], ['--', 23], ['A', 26], ['high', 28], ['court', 33], ['in', 39], ['northern', 42], ['India', 51], ['on', 57], ['Friday', 60], ['acquitted', 67], ['a', 77], ['wealthy', 79], ['businessman', 87], ['facing', 99], ['the', 106], ['death', 110], ['sentence', 116], ['for', 125], ['the', 129], ['killing', 133], ['of', 141], ['a', 144], ['teen', 146], ['in', 151], ['a', 154], ['case', 156], ['dubbed', 161], ['\"', 168], ['the', 169], ['house', 173], ['of', 179], ['horrors', 182], ['.', 189], ['\"', 190], ['Moninder', 195], ['Singh', 204], ['Pandher', 210], ['was', 218], ['sentenced', 222], ['to', 232], ['death', 235], ['by', 241], ['a', 244], ['lower', 246], ['court', 252], ['in', 258], ['February', 261], ['.', 269], ['The', 274], ['teen', 278], ['was', 283], ['one', 287], ['of', 291], ['19', 294], ['victims', 297], ['--', 305], ['children', 308], ['and', 317], ['young', 321], ['women', 327], ['--', 333], ['in', 336], ['one', 339], ['of', 343], ['the', 346], ['most', 350], ['gruesome', 355], ['serial', 364], ['killings', 371], ['in', 380], ['India', 383], ['in', 389], ['recent', 392], ['years', 399], ['.', 404], ['The', 409], ['Allahabad', 413], ['high', 423], ['court', 428], ['has', 434], ['acquitted', 438], ['Moninder', 448], ['Singh', 457], ['Pandher', 463], [',', 470], ['his', 472], ['lawyer', 476], ['Sikandar', 483], ['B.', 492], ['Kochar', 495], ['told', 502], ['CNN', 507], ['.', 510], ['Pandher', 515], ['and', 523], ['his', 527], ['domestic', 531], ['employee', 540], ['Surinder', 549], ['Koli', 558], ['were', 563], ['sentenced', 568], ['to', 578], ['death', 581], ['in', 587], ['February', 590], ['by', 599], ['a', 602], ['lower', 604], ['court', 610], ['for', 616], ['the', 620], ['rape', 624], ['and', 629], ['murder', 633], ['of', 640], ['the', 643], ['14-year', 647], ['-', 654], ['old', 655], ['.', 658], ['The', 663], ['high', 667], ['court', 672], ['upheld', 678], ['Koli', 685], [\"'s\", 689], ['death', 692], ['sentence', 698], [',', 706], ['Kochar', 708], ['said', 715], ['.', 719], ['The', 724], ['two', 728], ['were', 732], ['arrested', 737], ['two', 746], ['years', 750], ['ago', 756], ['after', 760], ['body', 766], ['parts', 771], ['packed', 777], ['in', 784], ['plastic', 787], ['bags', 795], ['were', 800], ['found', 805], ['near', 811], ['their', 816], ['home', 822], ['in', 827], ['Noida', 830], [',', 835], ['a', 837], ['New', 839], ['Delhi', 843], ['suburb', 849], ['.', 855], ['Their', 857], ['home', 863], ['was', 868], ['later', 872], ['dubbed', 878], ['a', 885], ['\"', 887], ['house', 888], ['of', 894], ['horrors', 897], ['\"', 904], ['by', 906], ['the', 909], ['Indian', 913], ['media', 920], ['.', 925], ['Pandher', 930], ['was', 938], ['not', 942], ['named', 946], ['a', 952], ['main', 954], ['suspect', 959], ['by', 967], ['investigators', 970], ['initially', 984], [',', 993], ['but', 995], ['was', 999], ['summoned', 1003], ['as', 1012], ['co', 1015], ['-', 1017], ['accused', 1018], ['during', 1026], ['the', 1033], ['trial', 1037], [',', 1042], ['Kochar', 1044], ['said', 1051], ['.', 1055], ['Kochar', 1060], ['said', 1067], ['his', 1072], ['client', 1076], ['was', 1083], ['in', 1087], ['Australia', 1090], ['when', 1100], ['the', 1105], ['teen', 1109], ['was', 1114], ['raped', 1118], ['and', 1124], ['killed', 1128], ['.', 1134], ['Pandher', 1139], ['faces', 1147], ['trial', 1153], ['in', 1159], ['the', 1162], ['remaining', 1166], ['18', 1176], ['killings', 1179], ['and', 1188], ['could', 1192], ['remain', 1198], ['in', 1205], ['custody', 1208], [',', 1215], ['the', 1217], ['attorney', 1221], ['said', 1230], ['.', 1234]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz': 211it [00:00, 2104.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11429\n",
      "{'header': {'dataset': 'NewsQA', 'split': 'train'}}\n",
      "{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'qas': [{'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#0', 'question': 'what was the amount of children murdered?', 'answers': ['19'], 'qid': 'da0e6b66e04d439fa1ba23c32de07e50', 'question_tokens': [['what', 0], ['was', 0], ['the', 0], ['amount', 0], ['of', 0], ['children', 0], ['murdered', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'What was the amount of children murdered?', 'question_tokens_original': [['What', 0], ['was', 5], ['the', 9], ['amount', 13], ['of', 20], ['children', 23], ['murdered', 32], ['?', 40]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#1', 'question': 'And when was Pandher sentenced', 'answers': ['February.'], 'qid': '724f6eb9a2814e4fb2d7d8e4de846073', 'question_tokens': [['And', 0], ['when', 0], ['was', 0], ['Pandher', 0], ['sentenced', 0]], 'detected_answers': [{'text': 'February.', 'char_spans': [[261, 269]], 'token_spans': [[53, 54]]}], 'question_original': 'When was Pandher sentenced to death?', 'question_tokens_original': [['When', 0], ['was', 5], ['Pandher', 9], ['sentenced', 17], ['to', 27], ['death', 30], ['?', 35]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#2', 'question': 'What the court aquitted Moninder Singh Pandher', 'answers': ['rape and murder'], 'qid': 'd64cbb90e5134081acfa83d3e702408c', 'question_tokens': [['What', 0], ['the', 0], ['court', 0], ['aquitted', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0]], 'detected_answers': [{'text': 'rape and murder', 'char_spans': [[624, 638]], 'token_spans': [[119, 121]]}], 'question_original': 'The court aquitted Moninder Singh Pandher of what crime?', 'question_tokens_original': [['The', 0], ['court', 4], ['aquitted', 10], ['Moninder', 19], ['Singh', 28], ['Pandher', 34], ['of', 42], ['what', 45], ['crime', 50], ['?', 55]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#3', 'question': 'of being', 'answers': ['Moninder Singh Pandher'], 'qid': 'fd7177ee6f1f4d62becd983a0305f503', 'question_tokens': [['of', 0], ['being', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was acquitted', 'question_tokens_original': [['who', 0], ['was', 4], ['acquitted', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#4', 'question': 'of being', 'answers': ['Moninder Singh Pandher'], 'qid': 'cd25c69f631349748ccdeccaace66463', 'question_tokens': [['of', 0], ['being', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was sentenced', 'question_tokens_original': [['who', 0], ['was', 4], ['sentenced', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#5', 'question': 'what was Moninder Singh Pandher', 'answers': ['the killing of a teen'], 'qid': 'b434021eb85d4c1b9fffcfa26dc71b97', 'question_tokens': [['what', 0], ['was', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0]], 'detected_answers': [{'text': 'the killing of a teen', 'char_spans': [[129, 149]], 'token_spans': [[25, 29]]}], 'question_original': 'What was Moninder Singh Pandher acquitted for?', 'question_tokens_original': [['What', 0], ['was', 5], ['Moninder', 9], ['Singh', 18], ['Pandher', 24], ['acquitted', 32], ['for', 42], ['?', 45]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#6', 'question': 'What was sentenced to death in February?', 'answers': ['Moninder Singh Pandher'], 'qid': '5b2631c1d21044a9bb1b2c22d118ad97', 'question_tokens': [['What', 0], ['was', 0], ['sentenced', 0], ['to', 0], ['death', 0], ['in', 0], ['February', 0], ['?', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'Who was sentenced to death in February?', 'question_tokens_original': [['Who', 0], ['was', 4], ['sentenced', 8], ['to', 18], ['death', 21], ['in', 27], ['February', 30], ['?', 38]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#7', 'question': 'what many people died', 'answers': ['19'], 'qid': '79e3ef1435f34886888ebf84b12364c7', 'question_tokens': [['what', 0], ['many', 0], ['people', 0], ['died', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'how many people died', 'question_tokens_original': [['how', 0], ['many', 4], ['people', 9], ['died', 16]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#8', 'question': 'How many children and young women have been murdered?', 'answers': ['19'], 'qid': 'fd571dcf979c4b9aa3d5da73c7668e38', 'question_tokens': [['How', 0], ['many', 0], ['children', 0], ['and', 0], ['young', 0], ['women', 0], ['have', 0], ['been', 0], ['murdered', 0], ['?', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'How many children and young women were murdered?', 'question_tokens_original': [['How', 0], ['many', 4], ['children', 9], ['and', 18], ['young', 22], ['women', 28], ['were', 34], ['murdered', 39], ['?', 47]], 'question_is_paraphrased': True}], 'context_tokens': [['NEW', 0], ['DELHI', 4], [',', 9], ['India', 11], ['(', 17], ['CNN', 18], [')', 21], ['--', 23], ['A', 26], ['high', 28], ['court', 33], ['in', 39], ['northern', 42], ['India', 51], ['on', 57], ['Friday', 60], ['acquitted', 67], ['a', 77], ['wealthy', 79], ['businessman', 87], ['facing', 99], ['the', 106], ['death', 110], ['sentence', 116], ['for', 125], ['the', 129], ['killing', 133], ['of', 141], ['a', 144], ['teen', 146], ['in', 151], ['a', 154], ['case', 156], ['dubbed', 161], ['\"', 168], ['the', 169], ['house', 173], ['of', 179], ['horrors', 182], ['.', 189], ['\"', 190], ['Moninder', 195], ['Singh', 204], ['Pandher', 210], ['was', 218], ['sentenced', 222], ['to', 232], ['death', 235], ['by', 241], ['a', 244], ['lower', 246], ['court', 252], ['in', 258], ['February', 261], ['.', 269], ['The', 274], ['teen', 278], ['was', 283], ['one', 287], ['of', 291], ['19', 294], ['victims', 297], ['--', 305], ['children', 308], ['and', 317], ['young', 321], ['women', 327], ['--', 333], ['in', 336], ['one', 339], ['of', 343], ['the', 346], ['most', 350], ['gruesome', 355], ['serial', 364], ['killings', 371], ['in', 380], ['India', 383], ['in', 389], ['recent', 392], ['years', 399], ['.', 404], ['The', 409], ['Allahabad', 413], ['high', 423], ['court', 428], ['has', 434], ['acquitted', 438], ['Moninder', 448], ['Singh', 457], ['Pandher', 463], [',', 470], ['his', 472], ['lawyer', 476], ['Sikandar', 483], ['B.', 492], ['Kochar', 495], ['told', 502], ['CNN', 507], ['.', 510], ['Pandher', 515], ['and', 523], ['his', 527], ['domestic', 531], ['employee', 540], ['Surinder', 549], ['Koli', 558], ['were', 563], ['sentenced', 568], ['to', 578], ['death', 581], ['in', 587], ['February', 590], ['by', 599], ['a', 602], ['lower', 604], ['court', 610], ['for', 616], ['the', 620], ['rape', 624], ['and', 629], ['murder', 633], ['of', 640], ['the', 643], ['14-year', 647], ['-', 654], ['old', 655], ['.', 658], ['The', 663], ['high', 667], ['court', 672], ['upheld', 678], ['Koli', 685], [\"'s\", 689], ['death', 692], ['sentence', 698], [',', 706], ['Kochar', 708], ['said', 715], ['.', 719], ['The', 724], ['two', 728], ['were', 732], ['arrested', 737], ['two', 746], ['years', 750], ['ago', 756], ['after', 760], ['body', 766], ['parts', 771], ['packed', 777], ['in', 784], ['plastic', 787], ['bags', 795], ['were', 800], ['found', 805], ['near', 811], ['their', 816], ['home', 822], ['in', 827], ['Noida', 830], [',', 835], ['a', 837], ['New', 839], ['Delhi', 843], ['suburb', 849], ['.', 855], ['Their', 857], ['home', 863], ['was', 868], ['later', 872], ['dubbed', 878], ['a', 885], ['\"', 887], ['house', 888], ['of', 894], ['horrors', 897], ['\"', 904], ['by', 906], ['the', 909], ['Indian', 913], ['media', 920], ['.', 925], ['Pandher', 930], ['was', 938], ['not', 942], ['named', 946], ['a', 952], ['main', 954], ['suspect', 959], ['by', 967], ['investigators', 970], ['initially', 984], [',', 993], ['but', 995], ['was', 999], ['summoned', 1003], ['as', 1012], ['co', 1015], ['-', 1017], ['accused', 1018], ['during', 1026], ['the', 1033], ['trial', 1037], [',', 1042], ['Kochar', 1044], ['said', 1051], ['.', 1055], ['Kochar', 1060], ['said', 1067], ['his', 1072], ['client', 1076], ['was', 1083], ['in', 1087], ['Australia', 1090], ['when', 1100], ['the', 1105], ['teen', 1109], ['was', 1114], ['raped', 1118], ['and', 1124], ['killed', 1128], ['.', 1134], ['Pandher', 1139], ['faces', 1147], ['trial', 1153], ['in', 1159], ['the', 1162], ['remaining', 1166], ['18', 1176], ['killings', 1179], ['and', 1188], ['could', 1192], ['remain', 1198], ['in', 1205], ['custody', 1208], [',', 1215], ['the', 1217], ['attorney', 1221], ['said', 1230], ['.', 1234]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz': 205it [00:00, 2044.13it/s]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11429\n",
      "{'header': {'dataset': 'NewsQA', 'split': 'train'}}\n",
      "{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'qas': [{'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#0', 'question': '– The Washington Post is out with a', 'answers': ['19'], 'qid': 'da0e6b66e04d439fa1ba23c32de07e50', 'question_tokens': [['–', 0], ['The', 0], ['Washington', 0], ['Post', 0], ['is', 0], ['out', 0], ['with', 0], ['a', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'What was the amount of children murdered?', 'question_tokens_original': [['What', 0], ['was', 5], ['the', 9], ['amount', 13], ['of', 20], ['children', 23], ['murdered', 32], ['?', 40]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#1', 'question': '– A man has been sentenced to', 'answers': ['February.'], 'qid': '724f6eb9a2814e4fb2d7d8e4de846073', 'question_tokens': [['–', 0], ['A', 0], ['man', 0], ['has', 0], ['been', 0], ['sentenced', 0], ['to', 0]], 'detected_answers': [{'text': 'February.', 'char_spans': [[261, 269]], 'token_spans': [[53, 54]]}], 'question_original': 'When was Pandher sentenced to death?', 'question_tokens_original': [['When', 0], ['was', 5], ['Pandher', 9], ['sentenced', 17], ['to', 27], ['death', 30], ['?', 35]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#2', 'question': '– A man has been arrested and charged with murder in the', 'answers': ['rape and murder'], 'qid': 'd64cbb90e5134081acfa83d3e702408c', 'question_tokens': [['–', 0], ['A', 0], ['man', 0], ['has', 0], ['been', 0], ['arrested', 0], ['and', 0], ['charged', 0], ['with', 0], ['murder', 0], ['in', 0], ['the', 0]], 'detected_answers': [{'text': 'rape and murder', 'char_spans': [[624, 638]], 'token_spans': [[119, 121]]}], 'question_original': 'The court aquitted Moninder Singh Pandher of what crime?', 'question_tokens_original': [['The', 0], ['court', 4], ['aquitted', 10], ['Moninder', 19], ['Singh', 28], ['Pandher', 34], ['of', 42], ['what', 45], ['crime', 50], ['?', 55]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#3', 'question': '– A', 'answers': ['Moninder Singh Pandher'], 'qid': 'fd7177ee6f1f4d62becd983a0305f503', 'question_tokens': [['–', 0], ['A', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was acquitted', 'question_tokens_original': [['who', 0], ['was', 4], ['acquitted', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#4', 'question': '– A', 'answers': ['Moninder Singh Pandher'], 'qid': 'cd25c69f631349748ccdeccaace66463', 'question_tokens': [['–', 0], ['A', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was sentenced', 'question_tokens_original': [['who', 0], ['was', 4], ['sentenced', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#5', 'question': '– Moninder Singh Pandher was', 'answers': ['the killing of a teen'], 'qid': 'b434021eb85d4c1b9fffcfa26dc71b97', 'question_tokens': [['–', 0], ['Moninder', 0], ['Singh', 0], ['Pandher', 0], ['was', 0]], 'detected_answers': [{'text': 'the killing of a teen', 'char_spans': [[129, 149]], 'token_spans': [[25, 29]]}], 'question_original': 'What was Moninder Singh Pandher acquitted for?', 'question_tokens_original': [['What', 0], ['was', 5], ['Moninder', 9], ['Singh', 18], ['Pandher', 24], ['acquitted', 32], ['for', 42], ['?', 45]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#6', 'question': \"– It's been more than a\", 'answers': ['Moninder Singh Pandher'], 'qid': '5b2631c1d21044a9bb1b2c22d118ad97', 'question_tokens': [['–', 0], ['It', 0], [\"'s\", 0], ['been', 0], ['more', 0], ['than', 0], ['a', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'Who was sentenced to death in February?', 'question_tokens_original': [['Who', 0], ['was', 4], ['sentenced', 8], ['to', 18], ['death', 21], ['in', 27], ['February', 30], ['?', 38]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#7', 'question': '– In what is', 'answers': ['19'], 'qid': '79e3ef1435f34886888ebf84b12364c7', 'question_tokens': [['–', 0], ['In', 0], ['what', 0], ['is', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'how many people died', 'question_tokens_original': [['how', 0], ['many', 4], ['people', 9], ['died', 16]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#8', 'question': '– In what is believed to be the first such', 'answers': ['19'], 'qid': 'fd571dcf979c4b9aa3d5da73c7668e38', 'question_tokens': [['–', 0], ['In', 0], ['what', 0], ['is', 0], ['believed', 0], ['to', 0], ['be', 0], ['the', 0], ['first', 0], ['such', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'How many children and young women were murdered?', 'question_tokens_original': [['How', 0], ['many', 4], ['children', 9], ['and', 18], ['young', 22], ['women', 28], ['were', 34], ['murdered', 39], ['?', 47]], 'question_is_paraphrased': True}], 'context_tokens': [['NEW', 0], ['DELHI', 4], [',', 9], ['India', 11], ['(', 17], ['CNN', 18], [')', 21], ['--', 23], ['A', 26], ['high', 28], ['court', 33], ['in', 39], ['northern', 42], ['India', 51], ['on', 57], ['Friday', 60], ['acquitted', 67], ['a', 77], ['wealthy', 79], ['businessman', 87], ['facing', 99], ['the', 106], ['death', 110], ['sentence', 116], ['for', 125], ['the', 129], ['killing', 133], ['of', 141], ['a', 144], ['teen', 146], ['in', 151], ['a', 154], ['case', 156], ['dubbed', 161], ['\"', 168], ['the', 169], ['house', 173], ['of', 179], ['horrors', 182], ['.', 189], ['\"', 190], ['Moninder', 195], ['Singh', 204], ['Pandher', 210], ['was', 218], ['sentenced', 222], ['to', 232], ['death', 235], ['by', 241], ['a', 244], ['lower', 246], ['court', 252], ['in', 258], ['February', 261], ['.', 269], ['The', 274], ['teen', 278], ['was', 283], ['one', 287], ['of', 291], ['19', 294], ['victims', 297], ['--', 305], ['children', 308], ['and', 317], ['young', 321], ['women', 327], ['--', 333], ['in', 336], ['one', 339], ['of', 343], ['the', 346], ['most', 350], ['gruesome', 355], ['serial', 364], ['killings', 371], ['in', 380], ['India', 383], ['in', 389], ['recent', 392], ['years', 399], ['.', 404], ['The', 409], ['Allahabad', 413], ['high', 423], ['court', 428], ['has', 434], ['acquitted', 438], ['Moninder', 448], ['Singh', 457], ['Pandher', 463], [',', 470], ['his', 472], ['lawyer', 476], ['Sikandar', 483], ['B.', 492], ['Kochar', 495], ['told', 502], ['CNN', 507], ['.', 510], ['Pandher', 515], ['and', 523], ['his', 527], ['domestic', 531], ['employee', 540], ['Surinder', 549], ['Koli', 558], ['were', 563], ['sentenced', 568], ['to', 578], ['death', 581], ['in', 587], ['February', 590], ['by', 599], ['a', 602], ['lower', 604], ['court', 610], ['for', 616], ['the', 620], ['rape', 624], ['and', 629], ['murder', 633], ['of', 640], ['the', 643], ['14-year', 647], ['-', 654], ['old', 655], ['.', 658], ['The', 663], ['high', 667], ['court', 672], ['upheld', 678], ['Koli', 685], [\"'s\", 689], ['death', 692], ['sentence', 698], [',', 706], ['Kochar', 708], ['said', 715], ['.', 719], ['The', 724], ['two', 728], ['were', 732], ['arrested', 737], ['two', 746], ['years', 750], ['ago', 756], ['after', 760], ['body', 766], ['parts', 771], ['packed', 777], ['in', 784], ['plastic', 787], ['bags', 795], ['were', 800], ['found', 805], ['near', 811], ['their', 816], ['home', 822], ['in', 827], ['Noida', 830], [',', 835], ['a', 837], ['New', 839], ['Delhi', 843], ['suburb', 849], ['.', 855], ['Their', 857], ['home', 863], ['was', 868], ['later', 872], ['dubbed', 878], ['a', 885], ['\"', 887], ['house', 888], ['of', 894], ['horrors', 897], ['\"', 904], ['by', 906], ['the', 909], ['Indian', 913], ['media', 920], ['.', 925], ['Pandher', 930], ['was', 938], ['not', 942], ['named', 946], ['a', 952], ['main', 954], ['suspect', 959], ['by', 967], ['investigators', 970], ['initially', 984], [',', 993], ['but', 995], ['was', 999], ['summoned', 1003], ['as', 1012], ['co', 1015], ['-', 1017], ['accused', 1018], ['during', 1026], ['the', 1033], ['trial', 1037], [',', 1042], ['Kochar', 1044], ['said', 1051], ['.', 1055], ['Kochar', 1060], ['said', 1067], ['his', 1072], ['client', 1076], ['was', 1083], ['in', 1087], ['Australia', 1090], ['when', 1100], ['the', 1105], ['teen', 1109], ['was', 1114], ['raped', 1118], ['and', 1124], ['killed', 1128], ['.', 1134], ['Pandher', 1139], ['faces', 1147], ['trial', 1153], ['in', 1159], ['the', 1162], ['remaining', 1166], ['18', 1176], ['killings', 1179], ['and', 1188], ['could', 1192], ['remain', 1198], ['in', 1205], ['custody', 1208], [',', 1215], ['the', 1217], ['attorney', 1221], ['said', 1230], ['.', 1234]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11429\n",
      "{'header': {'dataset': 'NewsQA', 'split': 'train'}}\n",
      "{'context': 'NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\\n\\n\\n\\nMoninder Singh Pandher was sentenced to death by a lower court in February.\\n\\n\\n\\nThe teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\\n\\n\\n\\nThe Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\\n\\n\\n\\nPandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\\n\\n\\n\\nThe high court upheld Koli\\'s death sentence, Kochar said.\\n\\n\\n\\nThe two were arrested two years ago after body parts packed in plastic bags were found near their home in Noida, a New Delhi suburb. Their home was later dubbed a \"house of horrors\" by the Indian media.\\n\\n\\n\\nPandher was not named a main suspect by investigators initially, but was summoned as co-accused during the trial, Kochar said.\\n\\n\\n\\nKochar said his client was in Australia when the teen was raped and killed.\\n\\n\\n\\nPandher faces trial in the remaining 18 killings and could remain in custody, the attorney said.', 'qas': [{'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#0', 'question': 'Take a look back at some of the', 'answers': ['19'], 'qid': 'da0e6b66e04d439fa1ba23c32de07e50', 'question_tokens': [['Take', 0], ['a', 0], ['look', 0], ['back', 0], ['at', 0], ['some', 0], ['of', 0], ['the', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'What was the amount of children murdered?', 'question_tokens_original': [['What', 0], ['was', 5], ['the', 9], ['amount', 13], ['of', 20], ['children', 23], ['murdered', 32], ['?', 40]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#1', 'question': 'The death sentence has been handed down', 'answers': ['February.'], 'qid': '724f6eb9a2814e4fb2d7d8e4de846073', 'question_tokens': [['The', 0], ['death', 0], ['sentence', 0], ['has', 0], ['been', 0], ['handed', 0], ['down', 0]], 'detected_answers': [{'text': 'February.', 'char_spans': [[261, 269]], 'token_spans': [[53, 54]]}], 'question_original': 'When was Pandher sentenced to death?', 'question_tokens_original': [['When', 0], ['was', 5], ['Pandher', 9], ['sentenced', 17], ['to', 27], ['death', 30], ['?', 35]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#2', 'question': 'A man has been acquitted by a court in connection with the', 'answers': ['rape and murder'], 'qid': 'd64cbb90e5134081acfa83d3e702408c', 'question_tokens': [['A', 0], ['man', 0], ['has', 0], ['been', 0], ['acquitted', 0], ['by', 0], ['a', 0], ['court', 0], ['in', 0], ['connection', 0], ['with', 0], ['the', 0]], 'detected_answers': [{'text': 'rape and murder', 'char_spans': [[624, 638]], 'token_spans': [[119, 121]]}], 'question_original': 'The court aquitted Moninder Singh Pandher of what crime?', 'question_tokens_original': [['The', 0], ['court', 4], ['aquitted', 10], ['Moninder', 19], ['Singh', 28], ['Pandher', 34], ['of', 42], ['what', 45], ['crime', 50], ['?', 55]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#3', 'question': 'More than', 'answers': ['Moninder Singh Pandher'], 'qid': 'fd7177ee6f1f4d62becd983a0305f503', 'question_tokens': [['More', 0], ['than', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was acquitted', 'question_tokens_original': [['who', 0], ['was', 4], ['acquitted', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#4', 'question': 'More than', 'answers': ['Moninder Singh Pandher'], 'qid': 'cd25c69f631349748ccdeccaace66463', 'question_tokens': [['More', 0], ['than', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'who was sentenced', 'question_tokens_original': [['who', 0], ['was', 4], ['sentenced', 8]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#5', 'question': 'A man has been acquitted of murdering his', 'answers': ['the killing of a teen'], 'qid': 'b434021eb85d4c1b9fffcfa26dc71b97', 'question_tokens': [['A', 0], ['man', 0], ['has', 0], ['been', 0], ['acquitted', 0], ['of', 0], ['murdering', 0], ['his', 0]], 'detected_answers': [{'text': 'the killing of a teen', 'char_spans': [[129, 149]], 'token_spans': [[25, 29]]}], 'question_original': 'What was Moninder Singh Pandher acquitted for?', 'question_tokens_original': [['What', 0], ['was', 5], ['Moninder', 9], ['Singh', 18], ['Pandher', 24], ['acquitted', 32], ['for', 42], ['?', 45]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#6', 'question': 'What is the death penalty and what is', 'answers': ['Moninder Singh Pandher'], 'qid': '5b2631c1d21044a9bb1b2c22d118ad97', 'question_tokens': [['What', 0], ['is', 0], ['the', 0], ['death', 0], ['penalty', 0], ['and', 0], ['what', 0], ['is', 0]], 'detected_answers': [{'text': 'Moninder Singh Pandher', 'char_spans': [[195, 216]], 'token_spans': [[41, 43]]}], 'question_original': 'Who was sentenced to death in February?', 'question_tokens_original': [['Who', 0], ['was', 4], ['sentenced', 8], ['to', 18], ['death', 21], ['in', 27], ['February', 30], ['?', 38]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#7', 'question': 'A man has been', 'answers': ['19'], 'qid': '79e3ef1435f34886888ebf84b12364c7', 'question_tokens': [['A', 0], ['man', 0], ['has', 0], ['been', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'how many people died', 'question_tokens_original': [['how', 0], ['many', 4], ['people', 9], ['died', 16]], 'question_is_paraphrased': True}, {'id': './cnn/stories/42d01e187213e86f5fe617fe32e716ff7fa3afc4.story#8', 'question': 'How many children and young women have been murdered in', 'answers': ['19'], 'qid': 'fd571dcf979c4b9aa3d5da73c7668e38', 'question_tokens': [['How', 0], ['many', 0], ['children', 0], ['and', 0], ['young', 0], ['women', 0], ['have', 0], ['been', 0], ['murdered', 0], ['in', 0]], 'detected_answers': [{'text': '19', 'char_spans': [[294, 295]], 'token_spans': [[60, 60]]}], 'question_original': 'How many children and young women were murdered?', 'question_tokens_original': [['How', 0], ['many', 4], ['children', 9], ['and', 18], ['young', 22], ['women', 28], ['were', 34], ['murdered', 39], ['?', 47]], 'question_is_paraphrased': True}], 'context_tokens': [['NEW', 0], ['DELHI', 4], [',', 9], ['India', 11], ['(', 17], ['CNN', 18], [')', 21], ['--', 23], ['A', 26], ['high', 28], ['court', 33], ['in', 39], ['northern', 42], ['India', 51], ['on', 57], ['Friday', 60], ['acquitted', 67], ['a', 77], ['wealthy', 79], ['businessman', 87], ['facing', 99], ['the', 106], ['death', 110], ['sentence', 116], ['for', 125], ['the', 129], ['killing', 133], ['of', 141], ['a', 144], ['teen', 146], ['in', 151], ['a', 154], ['case', 156], ['dubbed', 161], ['\"', 168], ['the', 169], ['house', 173], ['of', 179], ['horrors', 182], ['.', 189], ['\"', 190], ['Moninder', 195], ['Singh', 204], ['Pandher', 210], ['was', 218], ['sentenced', 222], ['to', 232], ['death', 235], ['by', 241], ['a', 244], ['lower', 246], ['court', 252], ['in', 258], ['February', 261], ['.', 269], ['The', 274], ['teen', 278], ['was', 283], ['one', 287], ['of', 291], ['19', 294], ['victims', 297], ['--', 305], ['children', 308], ['and', 317], ['young', 321], ['women', 327], ['--', 333], ['in', 336], ['one', 339], ['of', 343], ['the', 346], ['most', 350], ['gruesome', 355], ['serial', 364], ['killings', 371], ['in', 380], ['India', 383], ['in', 389], ['recent', 392], ['years', 399], ['.', 404], ['The', 409], ['Allahabad', 413], ['high', 423], ['court', 428], ['has', 434], ['acquitted', 438], ['Moninder', 448], ['Singh', 457], ['Pandher', 463], [',', 470], ['his', 472], ['lawyer', 476], ['Sikandar', 483], ['B.', 492], ['Kochar', 495], ['told', 502], ['CNN', 507], ['.', 510], ['Pandher', 515], ['and', 523], ['his', 527], ['domestic', 531], ['employee', 540], ['Surinder', 549], ['Koli', 558], ['were', 563], ['sentenced', 568], ['to', 578], ['death', 581], ['in', 587], ['February', 590], ['by', 599], ['a', 602], ['lower', 604], ['court', 610], ['for', 616], ['the', 620], ['rape', 624], ['and', 629], ['murder', 633], ['of', 640], ['the', 643], ['14-year', 647], ['-', 654], ['old', 655], ['.', 658], ['The', 663], ['high', 667], ['court', 672], ['upheld', 678], ['Koli', 685], [\"'s\", 689], ['death', 692], ['sentence', 698], [',', 706], ['Kochar', 708], ['said', 715], ['.', 719], ['The', 724], ['two', 728], ['were', 732], ['arrested', 737], ['two', 746], ['years', 750], ['ago', 756], ['after', 760], ['body', 766], ['parts', 771], ['packed', 777], ['in', 784], ['plastic', 787], ['bags', 795], ['were', 800], ['found', 805], ['near', 811], ['their', 816], ['home', 822], ['in', 827], ['Noida', 830], [',', 835], ['a', 837], ['New', 839], ['Delhi', 843], ['suburb', 849], ['.', 855], ['Their', 857], ['home', 863], ['was', 868], ['later', 872], ['dubbed', 878], ['a', 885], ['\"', 887], ['house', 888], ['of', 894], ['horrors', 897], ['\"', 904], ['by', 906], ['the', 909], ['Indian', 913], ['media', 920], ['.', 925], ['Pandher', 930], ['was', 938], ['not', 942], ['named', 946], ['a', 952], ['main', 954], ['suspect', 959], ['by', 967], ['investigators', 970], ['initially', 984], [',', 993], ['but', 995], ['was', 999], ['summoned', 1003], ['as', 1012], ['co', 1015], ['-', 1017], ['accused', 1018], ['during', 1026], ['the', 1033], ['trial', 1037], [',', 1042], ['Kochar', 1044], ['said', 1051], ['.', 1055], ['Kochar', 1060], ['said', 1067], ['his', 1072], ['client', 1076], ['was', 1083], ['in', 1087], ['Australia', 1090], ['when', 1100], ['the', 1105], ['teen', 1109], ['was', 1114], ['raped', 1118], ['and', 1124], ['killed', 1128], ['.', 1134], ['Pandher', 1139], ['faces', 1147], ['trial', 1153], ['in', 1159], ['the', 1162], ['remaining', 1166], ['18', 1176], ['killings', 1179], ['and', 1188], ['could', 1192], ['remain', 1198], ['in', 1205], ['custody', 1208], [',', 1215], ['the', 1217], ['attorney', 1221], ['said', 1230], ['.', 1234]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for dataset_path in [\n",
    "    'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz',\n",
    "    'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "    'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "    'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "    'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "    'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "]:\n",
    "    with gzip.open(dataset_path, 'rb') as f:\n",
    "        elems = [\n",
    "            json.loads(l.rstrip())\n",
    "            for l in tqdm(f, desc=f'loading \\'{dataset_path}\\'', leave=False)\n",
    "        ]\n",
    "        print(len(elems))\n",
    "        print(elems[0])\n",
    "        print(elems[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_write(prefix):\n",
    "    sorted_ranges = []\n",
    "    for file_path in FileSystemUtil.list_files_in_dir('datasets/', file_glob=f'{prefix}*.jsonl.gz'):\n",
    "        sorted_ranges.append(\n",
    "            [int(x) for x in file_path.replace('datasets/', '').replace(prefix, '').replace('.jsonl.gz', '').split('_')]\n",
    "        )\n",
    "    sorted_ranges = sorted(sorted_ranges, key=lambda x: x[0])\n",
    "    elems = []\n",
    "    header = None\n",
    "    for sorted_range in sorted_ranges:\n",
    "        path = f'datasets/{prefix}{sorted_range[0]}_{sorted_range[1]}.jsonl.gz'\n",
    "        print(path)\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            vals = [\n",
    "                json.loads(l.rstrip())\n",
    "                for l in tqdm(f, desc=f'loading \\'{path}\\'', leave=False)\n",
    "            ]\n",
    "            header = vals[0]\n",
    "            header['header'].pop('examples_range', None)\n",
    "            elems.extend(vals[1:])\n",
    "    file_name = prefix.replace('-range_', '')\n",
    "    out_file_path = f'datasets/{file_name}.jsonl.gz'\n",
    "    print(f'\\nWriting {len(elems)} elements to:\\n{out_file_path}')\n",
    "    with gzip.open(out_file_path, 'wb') as out:\n",
    "        for ex in [header] + elems:\n",
    "            ## Ref: https://stackoverflow.com/a/39451012\n",
    "            out.write((json.dumps(ex) + '\\n').encode('utf-8'))\n",
    "    print('...done\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz': 183it [00:00, 1824.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz': 186it [00:00, 1850.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz': 181it [00:00, 1806.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz': 184it [00:00, 1837.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz': 180it [00:00, 1793.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz': 188it [00:00, 1876.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz': 180it [00:00, 1792.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz': 193it [00:00, 1927.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 11428 elements to:\n",
      "datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz': 199it [00:00, 1981.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done\n",
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz': 187it [00:00, 1859.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz': 181it [00:00, 1808.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz': 186it [00:00, 1855.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz': 181it [00:00, 1807.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz': 189it [00:00, 1882.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz': 184it [00:00, 1822.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz': 194it [00:00, 1934.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 11428 elements to:\n",
      "datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz': 209it [00:00, 2088.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done\n",
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz': 188it [00:00, 1870.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz': 183it [00:00, 1824.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz': 186it [00:00, 1858.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz': 182it [00:00, 1813.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz': 190it [00:00, 1898.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz': 184it [00:00, 1832.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz': 195it [00:00, 1944.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 11428 elements to:\n",
      "datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz': 208it [00:00, 2072.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done\n",
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz': 186it [00:00, 1854.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz': 181it [00:00, 1800.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz': 184it [00:00, 1834.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz': 180it [00:00, 1793.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz': 188it [00:00, 1875.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz': 181it [00:00, 1808.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz': 193it [00:00, 1924.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 11428 elements to:\n",
      "datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz': 208it [00:00, 2075.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done\n",
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_1_1500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz': 187it [00:00, 1855.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_1501_3000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz': 182it [00:00, 1814.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_3001_4500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz': 186it [00:00, 1855.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_4501_6000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz': 181it [00:00, 1804.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_6001_7500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz': 189it [00:00, 1888.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_7501_9000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz': 182it [00:00, 1816.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_9001_10500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz': 194it [00:00, 1937.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_10501_11428.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 11428 elements to:\n",
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_1_1500.jsonl.gz': 202it [00:00, 2012.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done\n",
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_1_1500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_1501_3000.jsonl.gz': 0it [00:00, ?it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_1501_3000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_3001_4500.jsonl.gz': 178it [00:00, 1770.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_3001_4500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_4501_6000.jsonl.gz': 182it [00:00, 1805.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_4501_6000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_6001_7500.jsonl.gz': 176it [00:00, 1758.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_6001_7500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_7501_9000.jsonl.gz': 185it [00:00, 1846.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_7501_9000.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_9001_10500.jsonl.gz': 178it [00:00, 1768.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_9001_10500.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading 'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_10501_11428.jsonl.gz': 190it [00:00, 1892.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_10501_11428.jsonl.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 11428 elements to:\n",
      "datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\n",
      "...done\n"
     ]
    }
   ],
   "source": [
    "for prefix in [\n",
    "    'NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_',\n",
    "    'NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_',\n",
    "    'NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_',\n",
    "    'NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1-range_',\n",
    "    'NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1-range_',\n",
    "    'NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1-range_',\n",
    "]:\n",
    "    merge_write(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/newsqa_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_path = '\"datasets/newsqa_dev.jsonl.gz\"'\n",
    "\n",
    "device_i = 0\n",
    "total = 0\n",
    "for (paraphrase_score_n_gram, paraphrase_score_thresh) in [\n",
    "    (1, 0.0), \n",
    "    (1, 1.0), (1, 1.2), (1, 1.5),   \n",
    "    (2, 1.0), (2, 1.2), (2, 1.5),\n",
    "    (3, 1.0), (3, 1.2), (3, 1.5),\n",
    "]:\n",
    "    for train_path in [\n",
    "        'datasets/NewsQA_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/NewsQA_train-question-pegasus-xsum-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/NewsQA_train-question-pegasus-large-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/NewsQA_train-question-pegasus-multi_news-chk20-mul1.5-beam30-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/NewsQA_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz',\n",
    "    ]:\n",
    "        cmd = f'''python3 main.py --do_train_test_eval --model \"baseline\" --train_path {train_path} --dev_path {dev_path} --hidden_dim 128 --bidirectional --paraphrase_score_thresh {paraphrase_score_thresh} --paraphrase_score_n_gram {paraphrase_score_n_gram} --use_gpu --device {device_i} &'''\n",
    "        print(cmd, end='\\n\\n')\n",
    "        device_i = (device_i + 1) % 8\n",
    "        total += 1\n",
    "        if total % 16 == 0:\n",
    "            print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --model \"baseline\" --train_path datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_path = '\"datasets/bioasq_dev.jsonl.gz\"'\n",
    "\n",
    "device_i = 0\n",
    "total = 0\n",
    "for (paraphrase_score_n_gram, paraphrase_score_thresh) in [\n",
    "    (1, 0.0), \n",
    "    (1, 1.0), (1, 1.2), (1, 1.5),   \n",
    "    (2, 1.0), (2, 1.2), (2, 1.5),\n",
    "    (3, 1.0), (3, 1.2), (3, 1.5),\n",
    "]:\n",
    "    for train_path in [\n",
    "        'datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz',\n",
    "    ]:\n",
    "        cmd = f'''python3 main.py --do_train_test_eval --model \"baseline\" --train_path {train_path} --dev_path {dev_path} --hidden_dim 128 --bidirectional --paraphrase_score_thresh {paraphrase_score_thresh} --paraphrase_score_n_gram {paraphrase_score_n_gram} --use_gpu --device {device_i} &'''\n",
    "        print(cmd, end='\\n\\n')\n",
    "        device_i = (device_i + 1) % 8\n",
    "        total += 1\n",
    "        if total % 24 == 0:\n",
    "            print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 0.0 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 1 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 1 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 2 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 2 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 2 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.0 --paraphrase_score_n_gram 3 --use_gpu --device 7 &\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 4 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.2 --paraphrase_score_n_gram 3 --use_gpu --device 5 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 6 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 7 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 0 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 1 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 2 &\n",
      "\n",
      "python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz\" --dev_path \"datasets/bioasq_dev.jsonl.gz\" --hidden_dim 128 --bidirectional --paraphrase_score_thresh 1.5 --paraphrase_score_n_gram 3 --use_gpu --device 3 &\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dev_path = '\"datasets/bioasq_dev.jsonl.gz\"'\n",
    "\n",
    "device_i = 0\n",
    "total = 0\n",
    "for (paraphrase_score_n_gram, paraphrase_score_thresh) in [\n",
    "    (1, 0.0), \n",
    "    (1, 1.0), (1, 1.2), (1, 1.5),   \n",
    "    (2, 1.0), (2, 1.2), (2, 1.5),\n",
    "    (3, 1.0), (3, 1.2), (3, 1.5),\n",
    "]:\n",
    "    for train_path in [\n",
    "        'datasets/BioASQ_train-question-pegasus-cnn_dailymail-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-pegasus-xsum-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-pegasus-large-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-pegasus-multi_news-chk20-mul1.5-beam75-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-score-th0.0-ngram1.jsonl.gz',\n",
    "        'datasets/BioASQ_train-question-fairseq-chk20-mul1.5-beam20-temp1.5-MT_sampling_k50-score-th0.0-ngram1.jsonl.gz',\n",
    "    ]:\n",
    "        cmd = f'''python3 main.py --do_train_test_eval --shuffle_examples --model \"baseline\" --train_path \"datasets/bioasq_train.jsonl.gz\" \"{train_path}\" --dev_path {dev_path} --hidden_dim 128 --bidirectional --paraphrase_score_thresh {paraphrase_score_thresh} --paraphrase_score_n_gram {paraphrase_score_n_gram} --use_gpu --device {device_i} &'''\n",
    "        print(cmd, end='\\n\\n')\n",
    "        device_i = (device_i + 1) % 8\n",
    "        total += 1\n",
    "        if total % 24 == 0:\n",
    "            print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(elems[0:-1], elems[1:])):\n",
    "    if x == y:\n",
    "        print(i)\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"A collection of utilities to augment the Python language:\"\"\"\n",
    "from typing import Any, Optional, Type\n",
    "from pandas.core.frame import Series as PandasSeries, DataFrame as PandasDataFrame\n",
    "import numpy as np\n",
    "\n",
    "get_default = lambda x, default, default_2=None: (default if x is None else x) if default_2 is None \\\n",
    "    else (default if x is None else default_2)\n",
    "if_else = lambda cond, x, y: (x if cond is True else y)\n",
    "is_series = lambda x: isinstance(x, PandasSeries)\n",
    "is_df = lambda x: isinstance(x, PandasDataFrame)\n",
    "is_int_in_floats_clothing = lambda x: isinstance(x, float) and int(x) == x\n",
    "\n",
    "\n",
    "def are_any_none(*args):\n",
    "    for x in args:\n",
    "        if x is None:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def are_all_not_none(*args):\n",
    "    return not are_any_none(*args)\n",
    "\n",
    "\n",
    "def are_all_none(*args):\n",
    "    for x in args:\n",
    "        if x is not None:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def are_any_not_none(*args):\n",
    "    return not are_all_none(*args)\n",
    "\n",
    "\n",
    "def check_isinstance_or_none(x, y, err=True):\n",
    "    if x is None:\n",
    "        return True\n",
    "    return check_isinstance(x, y, err=err)\n",
    "\n",
    "\n",
    "def check_isinstance(x, y, err=True):\n",
    "    if x is None and y is type(None):\n",
    "        return True\n",
    "    assert isinstance(y, type) or (isinstance(y, list) and np.all([isinstance(z, type) for z in y]))\n",
    "    if (isinstance(y, type) and isinstance(x, y)) or (isinstance(y, list) and np.any([isinstance(x, z) for z in y])):\n",
    "        return True\n",
    "    if err:\n",
    "        raise TypeError(\n",
    "            f'Input parameter must be of type `{y.__name__}`; found type `{type(x).__name__}` with value:\\n{x}')\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_issubclass_or_none(x, y, err=True):\n",
    "    if x is None:\n",
    "        return True\n",
    "    return check_issubclass(x, y, err=err)\n",
    "\n",
    "\n",
    "def check_issubclass(x, y, err=True):\n",
    "    if x is None:\n",
    "        return False\n",
    "    assert isinstance(x, type)\n",
    "    assert isinstance(y, type) or (isinstance(y, list) and np.all([isinstance(z, type) for z in y]))\n",
    "    if (isinstance(y, type) and issubclass(x, y)) or (isinstance(y, list) and np.any([issubclass(x, z) for z in y])):\n",
    "        return True\n",
    "    if err:\n",
    "        raise TypeError(f'Input parameter must be a subclass of type {str(y)}; found type {type(x)} with value {x}')\n",
    "    return False\n",
    "\n",
    "\n",
    "## Ref: https://stackoverflow.com/a/13624858/4900327\n",
    "class classproperty(property):\n",
    "    def __get__(self, obj, objtype=None):\n",
    "        return super(classproperty, self).__get__(objtype)\n",
    "\n",
    "    def __set__(self, obj, value):\n",
    "        super(classproperty, self).__set__(type(obj), value)\n",
    "\n",
    "    def __delete__(self, obj):\n",
    "        super(classproperty, self).__delete__(type(obj))\n",
    "\n",
    "\n",
    "## Ref: https://stackoverflow.com/q/6760685/4900327, Method 2 base class.\n",
    "## The metaclass method in the above link did not work well with multiple inheritance.\n",
    "class Singleton:\n",
    "    __instance = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not isinstance(cls.__instance, cls):\n",
    "            cls.__instance = super(Singleton, cls).__new__(cls)\n",
    "        return cls.__instance\n",
    "\n",
    "    @classproperty\n",
    "    def instance(cls):\n",
    "        return cls.__instance\n",
    "\n",
    "\n",
    "class Registry:\n",
    "    _registry = {}\n",
    "\n",
    "    def __init_subclass__(cls, **kwargs):\n",
    "        \"\"\"\n",
    "        Register any sub class with the base class. a child class is registered as long as it is imported into environment\n",
    "        \"\"\"\n",
    "        super().__init_subclass__(**kwargs)\n",
    "        if cls in Registry.__subclasses__():\n",
    "            ## The current class is a direct subclass of Registry; it is a base class.\n",
    "            cls._registry = {}\n",
    "        else:\n",
    "            ## The current class is a subclass of a subclass of Registry: register this class as a subclass\n",
    "            cls._register_subclass()\n",
    "\n",
    "    @classmethod\n",
    "    def _register_subclass(cls):\n",
    "        cls._registry[cls._get_subclass_registration_key()] = cls\n",
    "\n",
    "    @classmethod\n",
    "    def _get_subclass_registration_key(cls) -> Any:\n",
    "        return str(cls.__name__)\n",
    "\n",
    "    @classmethod\n",
    "    def get_subclass(cls, key: Any) -> Optional[Type]:\n",
    "        return cls._registry.get(key)\n",
    "\n",
    "from typing import Dict, List\n",
    "from enum import Enum, auto\n",
    "# from eps_data_transformation_lib.util.StringUtils import StringUtils\n",
    "\n",
    "\n",
    "class AutoEnum(str, Enum):\n",
    "    '''\n",
    "    Utility class which can be subclassed to create enums using auto().\n",
    "    Also provides utility methods for common enum operations.\n",
    "    '''\n",
    "\n",
    "    def _generate_next_value_(name, start, count, last_values):\n",
    "        return name\n",
    "\n",
    "    @property\n",
    "    def str(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__class__.__name__ + self.name)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self is other\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return self is not other\n",
    "\n",
    "    def matches(self, enum_value: str) -> bool:\n",
    "        return self is self.from_str(enum_value, raise_error=False)\n",
    "\n",
    "    @classmethod\n",
    "    def matches_any(cls, enum_value: str) -> bool:\n",
    "        return cls.from_str(enum_value, raise_error=False) is not None\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, enum_value: str, raise_error: bool=True):\n",
    "        '''\n",
    "        Performs a case-insensitive lookup of the enum value string among the members of the current AutoEnum subclass.\n",
    "        :param enum_value: enum value string\n",
    "        :param raise_error: whether to raise an error if the string is not found in the enum\n",
    "        :return: an enum value which matches the string\n",
    "        :raises: ValueError if raise_error is True and no enum value matches the string\n",
    "        '''\n",
    "        if isinstance(enum_value, cls):\n",
    "            return enum_value\n",
    "        enum_value = StringUtils.assert_not_empty_and_strip(enum_value)\n",
    "        enum_values_map: Dict = {e.value.lower(): e for e in list(cls)}\n",
    "        enum_obj: cls = enum_values_map.get(enum_value.lower())\n",
    "        if enum_obj is None and raise_error:\n",
    "            raise ValueError(f'Could not find enum with value {enum_value}.')\n",
    "        return enum_obj\n",
    "\n",
    "    @classmethod\n",
    "    def convert_dict_keys_to_enum(cls, d: Dict) -> Dict:\n",
    "        '''\n",
    "        Converts string dict keys to the matching members of the current AutoEnum subclass.\n",
    "        Leaves non-string keys untouched.\n",
    "        :param d: dict to transform\n",
    "        :return: dict with matching string keys transformed to enum values\n",
    "        '''\n",
    "        out_dict = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(k, str) and cls.from_str(k, raise_error=False) is not None:\n",
    "                out_dict[cls.from_str(k, raise_error=False)] = v\n",
    "            else:\n",
    "                out_dict[k] = v\n",
    "        return out_dict\n",
    "\n",
    "    @classmethod\n",
    "    def convert_dict_keys_to_str(cls, d: Dict) -> Dict:\n",
    "        '''\n",
    "        Converts dict keys of the current AutoEnum subclass to the matching string key.\n",
    "        Leaves other keys untouched.\n",
    "        :param d: dict to transform\n",
    "        :return: dict with matching keys of the current AutoEnum transformed to strings.\n",
    "        '''\n",
    "        out_dict = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(k, cls):\n",
    "                out_dict[str(k)] = v\n",
    "            else:\n",
    "                out_dict[k] = v\n",
    "        return out_dict\n",
    "\n",
    "    @classmethod\n",
    "    def convert_dict_values_to_enum(cls, d: Dict) -> Dict:\n",
    "        '''\n",
    "        Converts string dict values to the matching members of the current AutoEnum subclass.\n",
    "        Leaves non-string values untouched.\n",
    "        :param d: dict to transform\n",
    "        :return: dict with matching string values transformed to enum values\n",
    "        '''\n",
    "        out_dict = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, str) and cls.from_str(v, raise_error=False) is not None:\n",
    "                out_dict[k] = cls.from_str(v, raise_error=False)\n",
    "            else:\n",
    "                out_dict[k] = v\n",
    "        return out_dict\n",
    "\n",
    "    @classmethod\n",
    "    def convert_dict_values_to_str(cls, d: Dict) -> Dict:\n",
    "        '''\n",
    "        Converts dict values of the current AutoEnum subclass to the matching string value.\n",
    "        Leaves other values untouched.\n",
    "        :param d: dict to transform\n",
    "        :return: dict with matching values of the current AutoEnum transformed to strings.\n",
    "        '''\n",
    "        out_dict = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, cls):\n",
    "                out_dict[k] = str(v)\n",
    "            else:\n",
    "                out_dict[k] = v\n",
    "        return out_dict\n",
    "\n",
    "    @classmethod\n",
    "    def convert_list_to_enum(cls, l: List) -> List:\n",
    "        '''\n",
    "        Converts string list itmes to the matching members of the current AutoEnum subclass.\n",
    "        Leaves non-string items untouched.\n",
    "        :param l: list to transform\n",
    "        :return: list with matching string items transformed to enum values\n",
    "        '''\n",
    "        out_list = []\n",
    "        for item in l:\n",
    "            if isinstance(item, str) and cls.from_str(item, raise_error=False) is not None:\n",
    "                out_list.append(cls.from_str(item, raise_error=False))\n",
    "            else:\n",
    "                out_list.append(item)\n",
    "        return out_list\n",
    "\n",
    "from typing import Union, List, Set, Dict, Any, Optional, Type\n",
    "from abc import abstractmethod, ABC\n",
    "import sys, random, numpy as np, re\n",
    "from math import log10, inf\n",
    "from numpy import sign\n",
    "# from eps_data_transformation_lib.util.StringUtils import StringUtils\n",
    "# from eps_data_transformation_lib.util.LanguageUtil import is_int_in_floats_clothing, check_isinstance_or_none, \\\n",
    "#     check_isinstance, check_issubclass, get_default, if_else\n",
    "# from eps_data_transformation_lib.util.AutoEnum import AutoEnum\n",
    "\n",
    "\n",
    "def convert_dict_to_parameters(Class, d):\n",
    "    from eps_data_transformation_lib.util.Parameters import Parameters\n",
    "    if Class is None:\n",
    "        return d\n",
    "    if d is None:\n",
    "        return None\n",
    "    if isinstance(d, Class):\n",
    "        return d\n",
    "    if isinstance(d, dict) and issubclass(Class, Parameters):\n",
    "        return Class(d)\n",
    "    return d\n",
    "\n",
    "\n",
    "class ParameterRange(ABC):\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(default={str(self.default())})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    @classmethod\n",
    "    def get_class_name(cls) -> str:\n",
    "        return str(cls.__name__)  ## Will return the child class name.\n",
    "\n",
    "    def check_is_valid(self, val, name=None):\n",
    "        if not self.is_valid(val):\n",
    "            raise ValueError(\n",
    "                f'{get_default(val, \"`None`\")} is not a valid value'\n",
    "                f'{if_else(StringUtils.is_not_empty(name), f\" for parameter `{name}`\", \"\")}. '\n",
    "                f'{self.help_msg()}.'\n",
    "            )\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_valid(self, val) -> bool:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def default(self) -> Any:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def help_msg(self) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SampleableParameterRange(ParameterRange, ABC):\n",
    "    @abstractmethod\n",
    "    def sample_value(self) -> Any:\n",
    "        pass\n",
    "\n",
    "\n",
    "class ParseableParameterRange(ParameterRange, ABC):\n",
    "    @abstractmethod\n",
    "    def expected_type(self) -> Type:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def parse_str(self, str_val) -> Any:\n",
    "        pass\n",
    "\n",
    "\n",
    "class IntegerRange(SampleableParameterRange, ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            low: Union[int, float],\n",
    "            high: Union[int, float],\n",
    "            default: Optional[Union[int, float]] = None,\n",
    "            blocked_vals: List = None,\n",
    "            log_sampling: bool = False,\n",
    "            allow_none: bool = False,\n",
    "    ):\n",
    "        assert isinstance(low, int) or low == -inf or is_int_in_floats_clothing(low)\n",
    "        low = int(low) if low != -inf else low\n",
    "        assert isinstance(high, int) or high == inf or is_int_in_floats_clothing(high)\n",
    "        high = int(high) if high != inf else high\n",
    "        assert low <= high, f'Lower limit of {self.get_class_name()} ({low}) must be <= upper limit ({high})'\n",
    "        assert isinstance(default, int) or is_int_in_floats_clothing(default) or default is None\n",
    "        blocked_vals = get_default(blocked_vals, [])\n",
    "        check_isinstance(blocked_vals, list)\n",
    "        check_isinstance(log_sampling, bool)\n",
    "        if log_sampling is True:\n",
    "            assert low > 0, f'Lower limit of {self.get_class_name()} ({low}) must be greater than zero when using log_sampling'\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._low = low\n",
    "        self._high = high\n",
    "        self._default = int(default) if default is not None else None\n",
    "        self._log_sampling = log_sampling\n",
    "        self._blocked_vals = blocked_vals\n",
    "        self._allow_none = allow_none\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'low={self._low}, ' \\\n",
    "               f'high={self._high}, ' \\\n",
    "               f'log_sampling={self._log_sampling}, ' \\\n",
    "               f'blocked_vals={self._blocked_vals}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return int\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[int]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = StringUtils.convert_str_to_type(str_val, int)\n",
    "        self.check_is_valid(out_val)\n",
    "        return out_val\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        return isinstance(val, int) and self._low <= val <= self._high and val not in self._blocked_vals\n",
    "\n",
    "    def default(self) -> Optional[int]:\n",
    "        return self._default\n",
    "\n",
    "    def sample_value(self) -> Any:\n",
    "        sampled_val = None\n",
    "        ## Since numpy cannot sample with -inf and inf, we sample with the max word size,\n",
    "        ## e.g. (-2^63 - 1) and (2^63 - 1). Ref: https://stackoverflow.com/a/7604981\n",
    "        high = min(self._high, sys.maxsize)\n",
    "        low = max(self._low, -sys.maxsize - 1)\n",
    "        while sampled_val is None or sampled_val in self._blocked_vals:\n",
    "            if not self._log_sampling:\n",
    "                ## Samples in the interval [low, high].\n",
    "                sampled_val = round(np.random.uniform(low, high))\n",
    "            else:\n",
    "                ## Samples exponentially in the interval [low, high]:\n",
    "                sampled_val = int(round(10 ** np.random.uniform(log10(low), log10(high))))\n",
    "        return sampled_val\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be {self.expected_type()} ' \\\n",
    "               f'between {self._low} and {self._high} (inclusive). ' \\\n",
    "               f'The default value is: {str(self.default())}. ' \\\n",
    "               f'{if_else(len(self._blocked_vals) > 0, f\"Values {self._blocked_vals} are not allowed. \", \"\")}' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value. ' \\\n",
    "               f'\\nSome example values are: ' \\\n",
    "               f'{\", \".join([str(self.sample_value()) for _ in range(min(3, self._high - self._low))])}.'\n",
    "\n",
    "\n",
    "class FloatRange(SampleableParameterRange, ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            low: Union[int, float],\n",
    "            high: Union[int, float],\n",
    "            default: Optional[Union[int, float]] = None,\n",
    "            blocked_vals: List = None,\n",
    "            log_sampling: bool = False,\n",
    "            allow_none: bool = False,\n",
    "    ):\n",
    "        check_isinstance(low, [int, float])\n",
    "        low = float(low)\n",
    "        check_isinstance(high, [int, float])\n",
    "        high = float(high)\n",
    "        assert low <= high, f'Lower limit of {self.get_class_name()} ({low}) must be <= upper limit ({high})'\n",
    "        check_isinstance_or_none(default, [int, float])\n",
    "        blocked_vals = get_default(blocked_vals, [])\n",
    "        check_isinstance(blocked_vals, list)\n",
    "        check_isinstance(log_sampling, bool)\n",
    "        if log_sampling is True:\n",
    "            assert low > 0, f'Lower limit of {self.get_class_name()} ({low}) must be greater than zero when using log_sampling'\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._low = low\n",
    "        self._high = high\n",
    "        self._default = float(default) if default is not None else None\n",
    "        self._log_sampling = log_sampling\n",
    "        self._blocked_vals = blocked_vals\n",
    "        self._allow_none = allow_none\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'low={self._low}, ' \\\n",
    "               f'high={self._high}, ' \\\n",
    "               f'log_sampling={self._log_sampling}, ' \\\n",
    "               f'blocked_vals={self._blocked_vals}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return float\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[float]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = StringUtils.convert_str_to_type(str_val, float)\n",
    "        self.check_is_valid(out_val)\n",
    "        return out_val\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        return type(val) in [float, int] and self._low <= val <= self._high and val not in self._blocked_vals\n",
    "\n",
    "    def default(self) -> Optional[float]:\n",
    "        return self._default\n",
    "\n",
    "    def sample_value(self) -> Any:\n",
    "        sampled_val = None\n",
    "        ## Since numpy cannot sample with -inf and inf, we sample with the max word size,\n",
    "        ## e.g. (-2^63 - 1) and (2^63 - 1). Ref: https://stackoverflow.com/a/7604981\n",
    "        high = min(self._high, sys.maxsize)\n",
    "        low = max(self._low, -sys.maxsize - 1)\n",
    "        while sampled_val is None or sampled_val in self._blocked_vals:\n",
    "            if not self._log_sampling:\n",
    "                ## Samples in the interval [low, high]:\n",
    "                sampled_val = np.random.uniform(low, high)\n",
    "            else:\n",
    "                ## Samples exponentially in the interval [low, high]:\n",
    "                sampled_val = 10 ** np.random.uniform(log10(low), log10(high))\n",
    "        return sampled_val\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be {self.expected_type()} ' \\\n",
    "               f'between {self._low} and {self._high} (inclusive). ' \\\n",
    "               f'\\nThe default value is: {str(self.default())}. ' \\\n",
    "               f'{if_else(len(self._blocked_vals) > 0, f\"Values {self._blocked_vals} are not allowed. \", \"\")}' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value. ' \\\n",
    "               f'\\nSome example values are: {\", \".join([str(self.sample_value()) for _ in range(3)])}.'\n",
    "\n",
    "\n",
    "class CategoricalRange(SampleableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            categories: Union[List, Set],\n",
    "            default: Optional[Any] = None,\n",
    "            fuzzy_match: bool = False,\n",
    "            allow_none: bool = False\n",
    "    ):\n",
    "        assert type(categories) in [list, set] and len(categories) > 0\n",
    "        assert default in categories or default is None\n",
    "        check_isinstance(fuzzy_match, bool)\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._categories = list(categories)\n",
    "        self._categories_str_uncased = [str(category).strip().lower() for category in self._categories]\n",
    "        self._default = default\n",
    "        self._fuzzy_match = fuzzy_match\n",
    "        self._allow_none = allow_none\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'categories={self._categories}, ' \\\n",
    "               f'default={self._default}, ' \\\n",
    "               f'fuzzy_match={self._fuzzy_match}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        if not self._fuzzy_match:\n",
    "            return val in self._categories\n",
    "        else:\n",
    "            return str(val).strip().lower() in self._categories_str_uncased\n",
    "\n",
    "    def default(self) -> Any:\n",
    "        return self._default\n",
    "\n",
    "    def sample_value(self) -> Any:\n",
    "        return np.random.choice(self._categories)\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be one of {self._categories} ' \\\n",
    "               f'{if_else(self._fuzzy_match, f\"(matched fuzzily) \", \"\")}' \\\n",
    "               f'\\nThe default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value. ' \\\n",
    "               f'\\nSome example values are: {\", \".join([str(self.sample_value()) for _ in range(3)])}.'\n",
    "\n",
    "\n",
    "class BoolRange(CategoricalRange, ParseableParameterRange):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__([True, False, 0, 1], *args, **kwargs)\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return bool\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[bool]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = StringUtils.convert_str_to_type(str_val, bool)\n",
    "        self.check_is_valid(out_val)\n",
    "        return out_val\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be {self.expected_type()} ' \\\n",
    "               f'{if_else(self._fuzzy_match, f\"(matched fuzzily). \", \". \")}' \\\n",
    "               f'\\nThe default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value. ' \\\n",
    "               f'\\nSupported values are: {\", \".join(self._categories)}.'\n",
    "\n",
    "\n",
    "class StringRange(SampleableParameterRange, ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            min_len: int,\n",
    "            max_len: [int, float],\n",
    "            default: Optional[str] = None,\n",
    "            blocked_vals: List = None,\n",
    "            allow_none: bool = False,\n",
    "            regex: str = None,\n",
    "            max_sample_length: int = 50,\n",
    "    ):\n",
    "        assert isinstance(min_len, int) and min_len >= 0\n",
    "        assert (isinstance(max_len, int) or max_len == inf) and max_len >= 1\n",
    "        assert isinstance(max_sample_length, int) and max_sample_length >= 0\n",
    "        max_sample_length = if_else(max_sample_length > max_len, max_len, max_sample_length)\n",
    "        check_isinstance_or_none(default, str)\n",
    "        check_isinstance_or_none(blocked_vals, list)\n",
    "        check_isinstance(allow_none, bool)\n",
    "        blocked_vals = get_default(blocked_vals, [])\n",
    "        check_isinstance_or_none(regex, str)\n",
    "        regex: str = get_default(regex, StringUtils.MATCH_ALL_REGEX_SINGLE_LINE)\n",
    "        self._min_len = min_len\n",
    "        self._max_len = max_len\n",
    "        self._max_sample_length = max_sample_length\n",
    "        self._default = default\n",
    "        self._blocked_vals = blocked_vals\n",
    "        self._regex = regex\n",
    "        self._allow_none = allow_none\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'min_len={self._min_len}, ' \\\n",
    "               f'max_len={self._max_len}, ' \\\n",
    "               f'max_sample_length={self._max_sample_length}, ' \\\n",
    "               f'blocked_vals={self._blocked_vals}, ' \\\n",
    "               f'regex={self._regex}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return str\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[str]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = StringUtils.convert_str_to_type(str_val, str)\n",
    "        self.check_is_valid(out_val)\n",
    "        return out_val\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        if not isinstance(val, str):\n",
    "            return False\n",
    "        if not (self._min_len <= len(val) <= self._max_len):\n",
    "            return False\n",
    "        if val in self._blocked_vals:\n",
    "            return False\n",
    "        if re.compile(self._regex).match(val) is None:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def default(self) -> str:\n",
    "        return self._default\n",
    "\n",
    "    def sample_value(self) -> Any:\n",
    "        min_len = self._min_len\n",
    "        max_len = self._max_sample_length\n",
    "        sampled_val = None\n",
    "        while sampled_val is None or sampled_val in self._blocked_vals:\n",
    "            sampled_val = StringUtils.generate_random_strings(min_num_chars=min_len, max_num_chars=max_len)\n",
    "        return sampled_val\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be {self.expected_type()} ' \\\n",
    "               f'between {self._min_len} and {self._max_len} characters (inclusive). ' \\\n",
    "               f'It should match regex: {self._regex}' \\\n",
    "               f'\\nThe default value is: {str(self.default())}. ' \\\n",
    "               f'{if_else(len(self._blocked_vals) > 0, f\"Values {self._blocked_vals} are not allowed. \", \"\")}' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value. ' \\\n",
    "               f'\\nSome example values are:\\n' + \"\\n\".join([f'{i + 1}. {str(self.sample_value())}' for i in range(3)])\n",
    "\n",
    "\n",
    "class AutoEnumValue(SampleableParameterRange, ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            ParamEnum: AutoEnum.__class__,\n",
    "            default: Optional[AutoEnum] = None,\n",
    "            allow_none: bool = False,\n",
    "    ):\n",
    "        check_isinstance(ParamEnum, AutoEnum.__class__)\n",
    "        check_isinstance_or_none(default, [str, ParamEnum])\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._ParamEnum: AutoEnum.__class__ = ParamEnum\n",
    "        if default is None:\n",
    "            self._default: AutoEnum = None\n",
    "        else:\n",
    "            self._default: AutoEnum = ParamEnum.from_str(default, raise_error=False)\n",
    "        self._allow_none: bool = allow_none\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return self._ParamEnum\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[AutoEnum]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = self._ParamEnum.from_str(str_val)\n",
    "        self.check_is_valid(out_val)\n",
    "        return out_val\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'ParamEnum=`{self._ParamEnum.__name__}`, ' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        try:\n",
    "            return isinstance(self._ParamEnum.from_str(val, raise_error=False), self._ParamEnum)\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def default(self) -> str:\n",
    "        return self._default\n",
    "\n",
    "    def sample_value(self) -> AutoEnum:\n",
    "        return list(self._ParamEnum)[np.random.choice(np.arange(0, len(list(self._ParamEnum))))]\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be {str(self.expected_type())} ' \\\n",
    "               f'or a string in {[str(e.name) for e in list(self._ParamEnum)]} (not case-sensitive). ' \\\n",
    "               f'\\nThe default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value. ' \\\n",
    "               f'\\nSome example values are: ' \\\n",
    "               f'{\", \".join([str(self.sample_value().name) for _ in range(min(3, len(list(self._ParamEnum))))])}.'\n",
    "\n",
    "\n",
    "class FixedValue(ParameterRange):\n",
    "    def __init__(self, val: Optional[Any]):\n",
    "        self._val = val\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        return self._val == val\n",
    "\n",
    "    def default(self) -> Any:\n",
    "        return self._val\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The only valid value is {self._val}'\n",
    "\n",
    "\n",
    "class InstanceOf(ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Classes: Union[Type, List[Type]],\n",
    "            default: Optional[Type] = None,\n",
    "            allow_none: bool = False,\n",
    "            convert_params_dict: bool = True\n",
    "    ):\n",
    "        assert isinstance(Classes, type) or \\\n",
    "               (isinstance(Classes, list) and np.all([isinstance(x, type) for x in Classes]))\n",
    "        self._Classes = if_else(isinstance(Classes, type), [Classes], Classes)\n",
    "        check_isinstance(self._Classes, list)\n",
    "        for class_ in self._Classes:\n",
    "            check_isinstance(class_, type)\n",
    "        check_isinstance_or_none(default, self._Classes)\n",
    "        self._default = default\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._allow_none: bool = allow_none\n",
    "        check_isinstance(convert_params_dict, bool)\n",
    "        self._convert_params_dict: bool = convert_params_dict\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'classes=[{\", \".join([f\"`{c.__name__}`\" for c in self._Classes])}], ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        return check_isinstance(val, self._Classes, err=False)\n",
    "\n",
    "    def default(self) -> Any:\n",
    "        return self._default\n",
    "\n",
    "    def expected_type(self) -> List[Type]:\n",
    "        return self._Classes\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[Union[Dict, 'Parameters']]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        if len(self._Classes) == 1 and self._convert_params_dict:\n",
    "            str_val = convert_dict_to_parameters(self._Classes[0], str_val)\n",
    "        elif len(self._Classes) == 1 and issubclass(self._Classes[0], AutoEnum):\n",
    "            str_val = self._Classes[0].from_str(str_val)\n",
    "        return str_val\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        if len(self._Classes) == 1:\n",
    "            classes_str = f'`{self._Classes[0].__name__}`'\n",
    "        else:\n",
    "            classes_str = f'one of the following: [{\", \".join([f\"`{c.__name__}`\" for c in self._Classes])}]'\n",
    "        return f'The parameter value should be an instance of {classes_str}. ' \\\n",
    "               f'The default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value.'\n",
    "\n",
    "\n",
    "class SubclassOf(ParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Classes: Union[Type, List[Type]],\n",
    "            default: Optional[List] = None,\n",
    "            allow_none: bool = False\n",
    "    ):\n",
    "        assert isinstance(Classes, type) or \\\n",
    "               (isinstance(Classes, list) and np.all([isinstance(x, type) for x in Classes]))\n",
    "        self._Classes = if_else(isinstance(Classes, type), [Classes], Classes)\n",
    "        check_isinstance(self._Classes, list)\n",
    "        for class_ in self._Classes:\n",
    "            check_isinstance(class_, type)\n",
    "        check_isinstance_or_none(default, self._Classes)\n",
    "        self._default = default\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._allow_none: bool = allow_none\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'classes=[{\", \".join([f\"`{c.__name__}`\" for c in self._Classes])}], ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        return check_issubclass(val, self._Classes, err=False)\n",
    "\n",
    "    def default(self) -> Any:\n",
    "        return self._default\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be a subclass of one of [{\", \".join([f\"`{c.__name__}`\" for c in self._Classes])}]. ' \\\n",
    "               f'The default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value.'\n",
    "\n",
    "\n",
    "class CollectionOf(ParameterRange, ABC):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ListOf(CollectionOf, ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            Class: Optional[Type] = None,\n",
    "            min_length: int = 0,\n",
    "            max_length: Union[int, float] = inf,\n",
    "            default: Optional[List] = None,\n",
    "            allow_none: bool = False,\n",
    "            convert_params_dict: bool = True\n",
    "    ):\n",
    "        check_isinstance_or_none(Class, type)\n",
    "        check_isinstance(min_length, int)\n",
    "        assert isinstance(max_length, int) or max_length == inf\n",
    "        check_isinstance_or_none(default, list)\n",
    "        check_isinstance(allow_none, bool)\n",
    "        self._Class = Class\n",
    "        if self._Class is not None and default is not None:\n",
    "            assert np.all([check_isinstance(x, self._Class) for x in default])\n",
    "        self._min_length: int = min_length\n",
    "        self._max_length: Union[int, float] = max_length\n",
    "        self._default = default\n",
    "        self._allow_none: bool = allow_none\n",
    "        check_isinstance(convert_params_dict, bool)\n",
    "        self._convert_params_dict: bool = convert_params_dict\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'min_length={self._min_length}, ' \\\n",
    "               f'max_length={self._max_length}, ' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'class={f\"`{self._Class.__name__}`\" if self._Class is not None else None}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return list\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[List]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = StringUtils.convert_str_to_type(str_val, list)\n",
    "        if check_issubclass(self._Class, AutoEnum, err=False):\n",
    "            out_val = self._Class.convert_list_to_enum(out_val)\n",
    "        if self._convert_params_dict:\n",
    "            out_val = [convert_dict_to_parameters(self._Class, v) for v in out_val]\n",
    "        return out_val\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        return isinstance(val, list) and (self._Class is None or np.all([isinstance(x, self._Class) for x in val]))\n",
    "\n",
    "    def default(self) -> Any:\n",
    "        return self._default\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        return f'The parameter value should be {self.expected_type()}' \\\n",
    "               f'{f\" where each element has type `{self._Class.__name__}`. \" if self._Class is not None else \". \"}' \\\n",
    "               f'The length should be between {self._min_length} and {self._max_length} (inclusive). ' \\\n",
    "               f'The default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value.'\n",
    "\n",
    "\n",
    "class DictOf(CollectionOf, ParseableParameterRange):\n",
    "    def __init__(\n",
    "            self,\n",
    "            key_class: Optional[Type] = None,\n",
    "            value_class: Optional[Type] = None,\n",
    "            default: Optional[Dict] = None,\n",
    "            allow_none: bool = False,\n",
    "            convert_params_dict: bool = True\n",
    "    ):\n",
    "        check_isinstance_or_none(key_class, type)\n",
    "        check_isinstance_or_none(value_class, type)\n",
    "        check_isinstance_or_none(default, dict)\n",
    "        check_isinstance(allow_none, bool)\n",
    "        check_isinstance(convert_params_dict, bool)\n",
    "        self._key_class = key_class\n",
    "        self._value_class = value_class\n",
    "        if self._key_class is not None and default is not None:\n",
    "            assert np.all([check_isinstance(k, self._key_class) for k in default.keys()])\n",
    "        if self._value_class is not None and default is not None:\n",
    "            assert np.all([check_isinstance(v, self._value_class) for v in default.values()])\n",
    "        self._default = default\n",
    "        self._allow_none: bool = allow_none\n",
    "        self._convert_params_dict = convert_params_dict\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.get_class_name()}(' \\\n",
    "               f'default={self.default()}, ' \\\n",
    "               f'key_class={f\"`{self._key_class.__name__}`\" if self._key_class is not None else None}, ' \\\n",
    "               f'value_class={f\"`{self._value_class.__name__}`\" if self._value_class is not None else None}, ' \\\n",
    "               f'allow_none={self._allow_none})'\n",
    "\n",
    "    def expected_type(self) -> Type:\n",
    "        return dict\n",
    "\n",
    "    def parse_str(self, str_val) -> Optional[Dict]:\n",
    "        if str_val is None:\n",
    "            if not self._allow_none:\n",
    "                raise ValueError(f'Cannot parse None value')\n",
    "            return None\n",
    "        out_val = StringUtils.convert_str_to_type(str_val, dict)\n",
    "        if check_issubclass(self._key_class, AutoEnum, err=False):\n",
    "            out_val = self._key_class.convert_dict_keys_to_enum(out_val)\n",
    "        if check_issubclass(self._value_class, AutoEnum, err=False):\n",
    "            out_val = self._value_class.convert_dict_values_to_enum(out_val)\n",
    "        if self._convert_params_dict:\n",
    "            out_val = {k: convert_dict_to_parameters(self._value_class, v) for k, v in out_val.items()}\n",
    "        return out_val\n",
    "\n",
    "    def is_valid(self, val) -> bool:\n",
    "        if val is None:\n",
    "            return self._allow_none\n",
    "        return isinstance(val, dict) and \\\n",
    "               (self._key_class is None or np.all([isinstance(k, self._key_class) for k in val.keys()])) and \\\n",
    "               (self._value_class is None or np.all([isinstance(k, self._value_class) for k in val.values()]))\n",
    "\n",
    "    def default(self) -> Any:\n",
    "        return self._default\n",
    "\n",
    "    def help_msg(self) -> str:\n",
    "        key_msg = if_else(self._key_class is not None, f', key has type {self._key_class}', '')\n",
    "        value_msg = if_else(self._value_class is not None, f', value has type {self._value_class}', '')\n",
    "        entry_msg = if_else(\n",
    "            self._key_class is not None or self._value_class is not None,\n",
    "            f' where, for each entry{key_msg}{value_msg}',\n",
    "            ''\n",
    "        )\n",
    "        return f'The parameter value should be {self.expected_type()}' \\\n",
    "               f'{entry_msg}. ' \\\n",
    "               f'The default value is: {str(self.default())}. ' \\\n",
    "               f'`None` {if_else(self._allow_none, \"can\", \"cannot\")} be passed as an input value.'\n",
    "\n",
    "\n",
    "PARAM_RANGES_DICT = DictOf(key_class=AutoEnum, value_class=ParameterRange)\n",
    "LIST_OF_STRINGS = ListOf(str)\n",
    "\n",
    "from typing import Dict, Any, List, Union, Tuple, Set\n",
    "import re, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.core.frame import Series as PandasSeries, DataFrame as PandasDataFrame\n",
    "# from eps_data_transformation_lib.util.LanguageUtil import get_default\n",
    "# from eps_data_transformation_lib.util.AutoEnum import AutoEnum\n",
    "# from eps_data_transformation_lib.util.ParameterRange import ParameterRange, PARAM_RANGES_DICT\n",
    "# from eps_data_transformation_lib.util.ParameterRange import LIST_OF_STRINGS\n",
    "from ast import literal_eval\n",
    "\n",
    "ListOrTuple = Union[List, Tuple]\n",
    "DataFrameOrSeries = Union[PandasSeries, PandasDataFrame]\n",
    "SeriesOrArray1D = Union[PandasSeries, List, Tuple, np.ndarray]\n",
    "DataFrameOrArray2D = Union[PandasSeries, PandasDataFrame, List, List[List], np.ndarray]\n",
    "SeriesOrArray1DOrDataFrameOrArray2D = Union[SeriesOrArray1D, DataFrameOrArray2D]\n",
    "\n",
    "\n",
    "class CollectionsUtils:\n",
    "    \"\"\"Utility class with static methods to process various Python collections (List, Set, Dict, etc)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        raise TypeError(\"Cannot create 'CollectionsUtils' instances.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def transform_keys_case(d: Dict, case='lower'):\n",
    "        \"\"\"\n",
    "        Converts string dict keys to either uppercase or lowercase. Leaves non-string keys untouched.\n",
    "        :param d: dict to transform\n",
    "        :param case: desired case, either 'lower' or 'upper'\n",
    "        :return: dict with case-transformed keys\n",
    "        \"\"\"\n",
    "        assert isinstance(case, str)\n",
    "        case = case.lower()\n",
    "        if case not in ['lower', 'upper']:\n",
    "            raise AttributeError(f'Unknown case {case}')\n",
    "        out = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(k, str):\n",
    "                if case == 'lower':\n",
    "                    out[k.lower()] = v\n",
    "                elif case == 'upper':\n",
    "                    out[k.upper()] = v\n",
    "            else:\n",
    "                out[k] = v\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def transform_values_case(d: Dict, case='lower'):\n",
    "        \"\"\"\n",
    "        Converts string dict values to either uppercase or lowercase. Leaves non-string values untouched.\n",
    "        :param d: dict to transform\n",
    "        :param case: desired case, either 'lower' or 'upper'\n",
    "        :return: dict with case-transformed values\n",
    "        \"\"\"\n",
    "        assert isinstance(case, str)\n",
    "        case = case.lower()\n",
    "        if case not in ['lower', 'upper']:\n",
    "            raise AttributeError(f'Unknown case {case}')\n",
    "        out = {}\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, str):\n",
    "                if case == 'lower':\n",
    "                    out[k] = v.lower()\n",
    "                elif case == 'upper':\n",
    "                    out[k] = v.upper()\n",
    "            else:\n",
    "                out[k] = v\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_convert_keys_to_enum(\n",
    "            d: Dict,\n",
    "            EnumClass: AutoEnum.__class__,\n",
    "            nested_EnumClass_mapping: Dict[AutoEnum, AutoEnum.__class__] = None,\n",
    "            err: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Recursively, converts string dict keys to the matching enum values of the AutoEnum class passed.\n",
    "        Leaves non-string keys untouched.\n",
    "        :param d: dict to transform\n",
    "        :param EnumClass: the AutoEnum class from which string keys will be matched to enum values\n",
    "        :return: dict with matching string keys transformed to enum values\n",
    "        \"\"\"\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        assert isinstance(d, dict)\n",
    "        if EnumClass is None:\n",
    "            return d\n",
    "        assert isinstance(EnumClass, AutoEnum.__class__)\n",
    "        d = EnumClass.convert_dict_keys_to_enum(d)\n",
    "        if CollectionsUtils.is_empty_dict(nested_EnumClass_mapping):\n",
    "            return d\n",
    "        assert isinstance(nested_EnumClass_mapping, dict)\n",
    "        out_d = {}\n",
    "        for k, v in d.items():\n",
    "            if err and k not in EnumClass:\n",
    "                raise KeyError(f'Unrecognized param name \"{k}\": valid params names are {list(EnumClass)}.')\n",
    "            if k in nested_EnumClass_mapping and isinstance(v, dict):\n",
    "                assert isinstance(k, AutoEnum), f'Nested key {str(k)} should be as SomeEnum.ENUM_VAL, not SomeEnum'\n",
    "                nested_main_EnumClass = nested_EnumClass_mapping[k]\n",
    "                assert isinstance(nested_main_EnumClass, AutoEnum.__class__)\n",
    "                out_d[k]: Dict = CollectionsUtils.dict_convert_keys_to_enum(\n",
    "                    v, EnumClass=nested_main_EnumClass, nested_EnumClass_mapping=nested_EnumClass_mapping\n",
    "                )\n",
    "            else:\n",
    "                out_d[k] = v\n",
    "        return out_d\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_set_default(d: Dict, default_params: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Sets default values in a dict for missing keys\n",
    "        :param d: input dict\n",
    "        :param default_params: dict of default values\n",
    "        :return: input dict with default values populated for missing keys\n",
    "        \"\"\"\n",
    "        if d is None:\n",
    "            d = {}\n",
    "        assert isinstance(d, dict)\n",
    "        if default_params is None:\n",
    "            return d\n",
    "        assert isinstance(default_params, dict)\n",
    "        for k, v in default_params.items():\n",
    "            if isinstance(v, dict) and isinstance(d.get(k), dict):\n",
    "                ## We need to go deeper:\n",
    "                d[k] = CollectionsUtils.dict_set_default(d[k], v)\n",
    "            else:\n",
    "                d.setdefault(k, v)\n",
    "        return d\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_string_list(l: List[str], pattern: str, ignorecase=False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Filter a list of strings based on an exact match to a regex pattern. Leaves non-string items untouched.\n",
    "        :param l: list of strings\n",
    "        :param pattern: Regex pattern used to match each item in list of strings.\n",
    "        Strings which are not a regex pattern will be expected to exactly match.\n",
    "        E.g. the pattern 'abcd' will only match the string 'abcd'.\n",
    "        To match 'abcdef', pattern 'abcd.*' should be used.\n",
    "        To match 'xyzabcd', patterm '.*abcd' should be used.\n",
    "        To match 'abcdef', 'xyzabcd' and 'xyzabcdef', patterm '.*abcd.*' should be used.\n",
    "        :param ignorecase: whether to ignore case while matching the pattern to the strings.\n",
    "        :return: filtered list of strings which match the pattern.\n",
    "        \"\"\"\n",
    "        if not pattern.startswith('^'):\n",
    "            pattern = '^' + pattern\n",
    "        if not pattern.endswith('$'):\n",
    "            pattern = pattern + '$'\n",
    "        flags = 0\n",
    "        if ignorecase:\n",
    "            flags = flags | re.IGNORECASE\n",
    "        return [x for x in l if not isinstance(x, str) or len(re.findall(pattern, x, flags=flags)) > 0]\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_list_values(l: List[str], values: Any, exclude: bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Filter a list of items (of any type) to a list of values.\n",
    "        :param l: list of items\n",
    "        :param values: list of values\n",
    "        :param exclude: how to use the list of filter values.\n",
    "            - exclude=False, values acts as a whitelist (Default)\n",
    "            - exclude=True, values acts as a blacklist\n",
    "        :return: filtered list of items\n",
    "        \"\"\"\n",
    "        if not isinstance(values, list):\n",
    "            values = [values]\n",
    "        if exclude:\n",
    "            return [x for x in l if x not in values]\n",
    "        return [x for x in l if x in values]\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_dict_keys_on_list(d: Dict, filtered_keys: List, exclude: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Filter values in a dict based on a list of keys.\n",
    "        :param d: dict to filter\n",
    "        :param filtered_keys: list of keys to include/exclude.\n",
    "        :param exclude: whether to keep or remove keys in filtered_keys list.\n",
    "        :return: dict with filtered list of keys\n",
    "        \"\"\"\n",
    "        if exclude:\n",
    "            return {k: d[k] for k in d if k not in filtered_keys}\n",
    "        return {k: d[k] for k in filtered_keys if k in d}\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_and_filter_dict_keys_on_enum(d: Dict, AutoEnumClass: AutoEnum.__class__, exclude: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Filter values in a dict based on those matching an enum.\n",
    "        :param d: dict to filter\n",
    "        :param AutoEnumClass: AutoEnum class on which to filter\n",
    "        :param exclude: whether to keep or remove keys in the AutoEnum class\n",
    "        :return: dict with filtered list of keys\n",
    "        \"\"\"\n",
    "        if AutoEnumClass is None:\n",
    "            return {}\n",
    "        assert isinstance(AutoEnumClass, AutoEnum.__class__)\n",
    "        d = CollectionsUtils.dict_convert_keys_to_enum(d, AutoEnumClass)\n",
    "        return CollectionsUtils.filter_dict_keys_on_list(d, list(AutoEnumClass), exclude=exclude)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_dict_keys_on_pattern(d: Dict, key_pattern: str, ignorecase=False):\n",
    "        \"\"\"\n",
    "        Filter string keys in a dict based on a regex pattern.\n",
    "        :param d: dict to filter\n",
    "        :param key_pattern: regex pattern used to match keys.\n",
    "        Follows same rules as `filter_string_list` method, i.e. only checks string keys and retains non-string keys.\n",
    "        :return: dict with filtered keys\n",
    "        \"\"\"\n",
    "        keys: List = list(d.keys())\n",
    "        filtered_keys: List = CollectionsUtils.filter_string_list(keys, key_pattern, ignorecase=ignorecase)\n",
    "        return CollectionsUtils.filter_dict_keys_on_list(d, filtered_keys)\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_dict_values(d: Dict, values: Any, exclude: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Filter values in a dict (of any type) to a list of values.\n",
    "        :param d: dict to filter\n",
    "        :param values: list of values (of any type)\n",
    "        :param exclude: how to use the list of filter values.\n",
    "            - exclude=False, keep any value in `values`\n",
    "            - exclude=True, remove any value in `values`\n",
    "        :return: dict with filtered values\n",
    "        \"\"\"\n",
    "        if not isinstance(values, list):\n",
    "            values = [values]\n",
    "        if exclude:\n",
    "            return {k: v for k, v in d.items() if v not in values}\n",
    "        return {k: v for k, v in d.items() if v in values}\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_dict_none_values(d: Dict, exclude: bool = True) -> Dict:\n",
    "        return CollectionsUtils.filter_dict_values(d, None, exclude=exclude)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_not_empty_list(l: List) -> bool:\n",
    "        return isinstance(l, list) and len(l) > 0\n",
    "\n",
    "    @staticmethod\n",
    "    def is_empty_list(l: List) -> bool:\n",
    "        return not CollectionsUtils.is_not_empty_list(l)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_subset(small_list: ListOrTuple, big_list: ListOrTuple):\n",
    "        assert CollectionsUtils.is_list_like(small_list)\n",
    "        assert CollectionsUtils.is_list_like(big_list)\n",
    "        return set.intersection(set(small_list), set(big_list))\n",
    "\n",
    "    @staticmethod\n",
    "    def is_subset(small_list: ListOrTuple, big_list: ListOrTuple) -> bool:\n",
    "        return len(CollectionsUtils.get_subset(small_list, big_list)) == len(small_list)\n",
    "\n",
    "    @staticmethod\n",
    "    def assert_not_empty_list(l: List):\n",
    "        assert CollectionsUtils.is_not_empty_list(l)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_list_like(l: Union[List, Tuple]):\n",
    "        return isinstance(l, list) or isinstance(l, tuple) or isinstance(l, np.ndarray)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_not_list_like(l: Union[List, Tuple]):\n",
    "        return not CollectionsUtils.is_list_like(l)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_not_empty_list_like(l: ListOrTuple) -> bool:\n",
    "        return CollectionsUtils.is_list_like(l) and len(l) > 0\n",
    "\n",
    "    @staticmethod\n",
    "    def is_empty_list_like(l: ListOrTuple) -> bool:\n",
    "        return not CollectionsUtils.is_not_empty_list_like(l)\n",
    "\n",
    "    @staticmethod\n",
    "    def assert_not_empty_list_like(l: ListOrTuple, error_message=''):\n",
    "        assert CollectionsUtils.is_not_empty_list_like(l), error_message\n",
    "\n",
    "    @staticmethod\n",
    "    def element_to_list(l):\n",
    "        if CollectionsUtils.is_not_list_like(l):\n",
    "            return [l]\n",
    "        return l\n",
    "\n",
    "    @staticmethod\n",
    "    def is_not_empty_dict(d: Dict) -> bool:\n",
    "        return isinstance(d, dict) and len(d) > 0\n",
    "\n",
    "    @staticmethod\n",
    "    def is_empty_dict(d: Dict) -> bool:\n",
    "        return not CollectionsUtils.is_not_empty_dict(d)\n",
    "\n",
    "    @staticmethod\n",
    "    def assert_not_empty_dict(d: Dict):\n",
    "        assert CollectionsUtils.is_not_empty_dict(d)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_random_dict_key(d: Dict) -> Any:\n",
    "        if CollectionsUtils.is_not_empty_dict(d):\n",
    "            return random.choice(list(d.keys()))\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_random_value(struct: Union[ListOrTuple, Dict, str]) -> Any:\n",
    "        if CollectionsUtils.is_not_empty_list_like(struct) or isinstance(struct, str):\n",
    "            return random.choice(struct)\n",
    "        elif CollectionsUtils.is_not_empty_dict(struct):\n",
    "            return struct[CollectionsUtils.get_random_dict_key(struct)]\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def is_1d_array(l: Union[List, Tuple]):\n",
    "        return CollectionsUtils.is_list_like(l) and len(l) > 0 and not CollectionsUtils.is_list_like(l[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def is_2d_array(l: Union[List, Tuple]):\n",
    "        return CollectionsUtils.is_list_like(l) and len(l) > 0 and CollectionsUtils.is_list_like(l[0])\n",
    "\n",
    "    @classmethod\n",
    "    def convert_1d_or_2d_array_to_dataframe(cls, data: SeriesOrArray1DOrDataFrameOrArray2D) -> PandasDataFrame:\n",
    "        if CollectionsUtils.is_1d_array(data):\n",
    "            data: PandasSeries = cls.convert_1d_array_to_series(data)\n",
    "        if isinstance(data, PandasSeries) or CollectionsUtils.is_2d_array(data):\n",
    "            data: PandasDataFrame = pd.DataFrame(data)\n",
    "        assert isinstance(data, PandasDataFrame)\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def convert_1d_array_to_series(cls, data: SeriesOrArray1D):\n",
    "        if len(data) == 0:\n",
    "            raise ValueError(f'Cannot convert empty data structure to series')\n",
    "        if isinstance(data, PandasSeries):\n",
    "            return data\n",
    "        if not CollectionsUtils.is_list_like(data):\n",
    "            raise ValueError(f'Cannot convert non list-like data structure to series')\n",
    "        return pd.Series(data)\n",
    "\n",
    "    @classmethod\n",
    "    def get_unique_values_list(\n",
    "            cls, data: SeriesOrArray1DOrDataFrameOrArray2D, exclude_nans: bool = True\n",
    "    ) -> List[Any]:\n",
    "        if data is None:\n",
    "            return []\n",
    "        if isinstance(data, PandasSeries) or isinstance(data, PandasDataFrame):\n",
    "            data: np.ndarray = data.values\n",
    "        if CollectionsUtils.is_2d_array(data):\n",
    "            data: np.ndarray = CollectionsUtils.convert_1d_or_2d_array_to_dataframe(data).values\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            data: np.ndarray = np.array(data)\n",
    "        flattened_data = data.ravel('K')  ## 1-D array of all data (w/ nans). Ref: https://stackoverflow.com/a/26977495\n",
    "        if len(flattened_data) == 0:\n",
    "            return []\n",
    "        if exclude_nans:\n",
    "            flattened_data = flattened_data[~pd.isnull(flattened_data)]\n",
    "        flattened_data = np.unique(flattened_data)\n",
    "        return sorted(list(flattened_data))\n",
    "\n",
    "    @classmethod\n",
    "    def get_num_non_null_columns_per_row(cls, df: PandasDataFrame) -> PandasSeries:\n",
    "        ## Ref: https://datascience.stackexchange.com/a/16801/35826\n",
    "        assert isinstance(df, PandasDataFrame)\n",
    "        return (~df.isna()).sum(axis=1)\n",
    "\n",
    "    @classmethod\n",
    "    def get_max_num_non_null_columns_per_row(cls, df: PandasDataFrame) -> int:\n",
    "        assert isinstance(df, PandasDataFrame)\n",
    "        return cls.get_num_non_null_columns_per_row(df).max()\n",
    "\n",
    "    @classmethod\n",
    "    def eval_dict_values(cls, params: Dict):\n",
    "        if not isinstance(params, dict):\n",
    "            raise ValueError(f\"{params} should be of type dict\")\n",
    "        updated_dict = {}\n",
    "        for parameter, value in params.items():\n",
    "            try:\n",
    "                updated_dict[parameter] = literal_eval(value)\n",
    "            except:\n",
    "                updated_dict[parameter] = value\n",
    "        return updated_dict\n",
    "\n",
    "    @classmethod\n",
    "    def assert_parameter_ranges(cls, params: Dict = None, param_ranges: Dict = None):\n",
    "        \"\"\"Checks whether the parameters are in the required ranges.\"\"\"\n",
    "        if params is None or param_ranges is None:\n",
    "            return True\n",
    "        if not isinstance(params, dict):\n",
    "            raise ValueError(f\"{params} should be of type dict\")\n",
    "        if not isinstance(param_ranges, dict):\n",
    "            raise ValueError(f\"{param_ranges} should be of type dict\")\n",
    "        if not PARAM_RANGES_DICT.is_valid(param_ranges):\n",
    "            raise ValueError(f'Invalid dict of param ranges: {param_ranges}')\n",
    "        keys_to_check = set(params.keys()).intersection(set(param_ranges.keys()))\n",
    "        for param_name in keys_to_check:\n",
    "            param_range: ParameterRange = param_ranges[param_name]\n",
    "            param_value = params[param_name]\n",
    "            assert isinstance(param_range, ParameterRange), f'{param_range} is not a valid {ParameterRange.__name__}'\n",
    "            if not param_range.is_valid(param_value):\n",
    "                raise ValueError(\n",
    "                    f'{get_default(param_value, \"`None`\")} is not a valid value for param '\n",
    "                    f'`{param_name}`. {param_range.help_msg()}'\n",
    "                )\n",
    "\n",
    "    class TrieNode:\n",
    "        def __init__(self, parent=None, value=None, children=None):\n",
    "            self.parent = parent\n",
    "            self.is_path_end = False\n",
    "            self.value = value\n",
    "            self.children: Dict[str, Any] = get_default(children, {})\n",
    "            self.depth = self.get_depth(self)\n",
    "\n",
    "        def __eq__(self, other):\n",
    "            return self.is_path_end == other.is_path_end and \\\n",
    "                   self.children == other.children and \\\n",
    "                   self.parent == other.parent\n",
    "\n",
    "        def __getitem__(self, key):\n",
    "            return self.children[key]\n",
    "\n",
    "        @classmethod\n",
    "        def get_depth(cls, cur_node):\n",
    "            \"\"\"Calculates and returns depth of the current node. Root has depth of 0\"\"\"\n",
    "            depth = 0\n",
    "            while cur_node.parent is not None:\n",
    "                depth += 1\n",
    "                cur_node = cur_node.parent\n",
    "            return depth\n",
    "\n",
    "    @classmethod\n",
    "    def create_trie(cls, string_list: List[str], splitter: str = '.', allow_end_at_branch: bool = True) -> TrieNode:\n",
    "        \"\"\"\n",
    "        Creates a trie from a list of strings.\n",
    "        Each node in the trie is a dict with further subdicts. Leafs are identified as dicts with '__end__' in them.\n",
    "        Ref: https://stackoverflow.com/a/11016430\n",
    "        \"\"\"\n",
    "        LIST_OF_STRINGS.check_is_valid(string_list)\n",
    "        trie = cls.TrieNode()\n",
    "        for string in string_list:\n",
    "            current_node = trie\n",
    "            string_split: List[str] = string.split(splitter)\n",
    "            for string_part_i, string_part in enumerate(string_split):\n",
    "                current_node.children.setdefault(string_part, cls.TrieNode(current_node))\n",
    "                current_node = current_node.children[string_part]\n",
    "                if string_part_i != len(string_split) - 1 and not allow_end_at_branch:\n",
    "                    if current_node.is_path_end is True:\n",
    "                        raise ValueError(\n",
    "                            f'Branch nodes cannot be values for this Trie; thus cannot create trie from {string_list}'\n",
    "                        )\n",
    "            current_node.is_path_end = True\n",
    "        return trie\n",
    "\n",
    "\n",
    "from typing import Dict, List, Any, Union, Tuple, Set, Type\n",
    "from ast import literal_eval\n",
    "import math, re, json, sys, inspect\n",
    "import numpy as np\n",
    "from types import FunctionType\n",
    "from datetime import datetime\n",
    "from hashlib import sha256\n",
    "\n",
    "StructuredBlob = Union[List, Dict, List[Dict]]  ## used for type hints.\n",
    "\n",
    "\n",
    "class StringUtils:\n",
    "    EMPTY = ''\n",
    "    SPACE = ' '\n",
    "    DOUBLE_SPACE = SPACE * 2\n",
    "    FOUR_SPACE = SPACE * 4\n",
    "    TAB = '\\t'\n",
    "    NEWLINE = '\\n'\n",
    "    WINDOWS_NEWLINE = '\\r'\n",
    "    BACKSLASH = '\\\\'\n",
    "    SLASH = '/'\n",
    "    PIPE = '|'\n",
    "    SINGLE_QUOTE = \"'\"\n",
    "    DOUBLE_QUOTE = '\"'\n",
    "    COMMA = ','\n",
    "    COMMA_SPACE = ', '\n",
    "    COMMA_NEWLINE = ',\\n'\n",
    "    HYPHEN = '-'\n",
    "    DOUBLE_HYPHEN = '--'\n",
    "    DOT = '.'\n",
    "    ASTERISK = '*'\n",
    "    QUESTION_MARK = '?'\n",
    "    CARET = '^'\n",
    "    DOLLAR = '$'\n",
    "    UNDERSCORE = '_'\n",
    "    COLON = ':'\n",
    "    SEMICOLON = ';'\n",
    "    EQUALS = '='\n",
    "    LEFT_PAREN = '('\n",
    "    RIGHT_PAREN = ')'\n",
    "    BACKTICK = '`'\n",
    "\n",
    "    MATCH_ALL_REGEX_SINGLE_LINE = CARET + DOT + ASTERISK + DOLLAR\n",
    "    MATCH_ALL_REGEX_MULTI_LINE = DOT + ASTERISK\n",
    "\n",
    "    S3_PREFIX = 's3://'\n",
    "    PORT_REGEX = ':(\\d+)'\n",
    "    DOCKER_REGEX = '\\d+\\.dkr\\.ecr\\..*.amazonaws\\.com/.*'\n",
    "\n",
    "    DEFAULT_CHUNK_NAME_PREFIX = 'part'\n",
    "\n",
    "    FILES_TO_IGNORE = ['_SUCCESS', '.DS_Store']\n",
    "\n",
    "    UTF_8 = 'utf-8'\n",
    "\n",
    "    FILE_SIZE_UNITS = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "\n",
    "    ALPHABET = tuple('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "\n",
    "    ## Taken from: https://github.com/django/django/blob/master/django/utils/baseconv.py#L101\n",
    "    BASE2_ALPHABET = '01'\n",
    "    BASE16_ALPHABET = '0123456789ABCDEF'\n",
    "    BASE56_ALPHABET = '23456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnpqrstuvwxyz'\n",
    "    BASE36_ALPHABET = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    BASE62_ALPHABET = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "    BASE64_ALPHABET = BASE62_ALPHABET + '-_'\n",
    "\n",
    "    class BaseConverter:\n",
    "        decimal_digits = '0123456789'\n",
    "\n",
    "        def __init__(self, digits, sign='-'):\n",
    "            self.sign = sign\n",
    "            self.digits = digits\n",
    "            if sign in self.digits:\n",
    "                raise ValueError('Sign character found in converter base digits.')\n",
    "\n",
    "        def __repr__(self):\n",
    "            return \"<%s: base%s (%s)>\" % (self.__class__.__name__, len(self.digits), self.digits)\n",
    "\n",
    "        def encode(self, i):\n",
    "            neg, value = self.convert(i, self.decimal_digits, self.digits, '-')\n",
    "            if neg:\n",
    "                return self.sign + value\n",
    "            return value\n",
    "\n",
    "        def decode(self, s):\n",
    "            neg, value = self.convert(s, self.digits, self.decimal_digits, self.sign)\n",
    "            if neg:\n",
    "                value = '-' + value\n",
    "            return int(value)\n",
    "\n",
    "        def convert(self, number, from_digits, to_digits, sign):\n",
    "            if str(number)[0] == sign:\n",
    "                number = str(number)[1:]\n",
    "                neg = 1\n",
    "            else:\n",
    "                neg = 0\n",
    "\n",
    "            # make an integer out of the number\n",
    "            x = 0\n",
    "            for digit in str(number):\n",
    "                x = x * len(from_digits) + from_digits.index(digit)\n",
    "\n",
    "            # create the result in base 'len(to_digits)'\n",
    "            if x == 0:\n",
    "                res = to_digits[0]\n",
    "            else:\n",
    "                res = ''\n",
    "                while x > 0:\n",
    "                    digit = x % len(to_digits)\n",
    "                    res = to_digits[digit] + res\n",
    "                    x = int(x // len(to_digits))\n",
    "            return neg, res\n",
    "\n",
    "    BASE_CONVERTER_MAP = {\n",
    "        2: BaseConverter(BASE2_ALPHABET),\n",
    "        16: BaseConverter(BASE16_ALPHABET),\n",
    "        36: BaseConverter(BASE36_ALPHABET),\n",
    "        56: BaseConverter(BASE56_ALPHABET),\n",
    "        62: BaseConverter(BASE62_ALPHABET),\n",
    "        64: BaseConverter(BASE64_ALPHABET, sign='$'),\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        raise TypeError(f'Cannot instantiate class \"StringUtils\"')\n",
    "\n",
    "    @classmethod\n",
    "    def assert_not_empty_and_strip(cls, string, error_message='') -> str:\n",
    "        cls.assert_not_empty(string, error_message)\n",
    "        return string.strip()\n",
    "\n",
    "    @classmethod\n",
    "    def strip_if_not_empty(cls, string) -> str:\n",
    "        if cls.is_not_empty(string):\n",
    "            return string.strip()\n",
    "        return string\n",
    "\n",
    "    @classmethod\n",
    "    def is_not_empty(cls, string: str) -> bool:\n",
    "        return isinstance(string, str) and len(string.strip()) > 0\n",
    "\n",
    "    @classmethod\n",
    "    def is_not_empty_bytes(cls, string: bytes) -> bool:\n",
    "        return isinstance(string, bytes) and len(string.strip()) > 0\n",
    "\n",
    "    @classmethod\n",
    "    def is_not_empty_str_or_bytes(cls, string: Union[str, bytes]) -> bool:\n",
    "        return cls.is_not_empty(string) or cls.is_not_empty_bytes(string)\n",
    "\n",
    "    @classmethod\n",
    "    def is_empty(cls, string) -> bool:\n",
    "        return not cls.is_not_empty(string)\n",
    "\n",
    "    @classmethod\n",
    "    def is_empty_bytes(cls, string) -> bool:\n",
    "        return not cls.is_not_empty_bytes(string)\n",
    "\n",
    "    @classmethod\n",
    "    def is_empty_str_or_bytes(cls, string) -> bool:\n",
    "        return not cls.is_not_empty_str_or_bytes(string)\n",
    "\n",
    "    @classmethod\n",
    "    def assert_not_empty(cls, string, error_message=''):\n",
    "        assert cls.is_not_empty(string), error_message\n",
    "\n",
    "    @classmethod\n",
    "    def assert_not_empty_bytes(cls, string, error_message=''):\n",
    "        assert cls.is_not_empty_str_or_bytes(string), error_message\n",
    "\n",
    "    @classmethod\n",
    "    def assert_not_empty_str_or_bytes(cls, string, error_message=''):\n",
    "        assert cls.is_not_empty_str_or_bytes(string), error_message\n",
    "\n",
    "    @classmethod\n",
    "    def is_int(cls, string: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if an input string is an integer.\n",
    "        :param string: input string\n",
    "        :raises: error when input is not a string\n",
    "        :return: True for '123', '-123' but False for '123.0', '1.23', '-1.23' and '1e2'\n",
    "        \"\"\"\n",
    "        cls.assert_not_empty(string)\n",
    "        try:\n",
    "            int(string)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    @classmethod\n",
    "    def is_float(cls, string: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if an input string is a floating-point value.\n",
    "        :param string: input string\n",
    "        :raises: error when input is not a string\n",
    "        :return: True for '123', '1.23', '123.0', '-123', '-123.0', '1e2', '1.23e-5', 'NAN' & 'nan'; but False for 'abc'\n",
    "        \"\"\"\n",
    "        cls.assert_not_empty(string)\n",
    "        try:\n",
    "            float(string)  ## Will return True for NaNs as well.\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    @classmethod\n",
    "    def is_prefix(cls, prefix: str, strings: Union[List[str], Set[str]]) -> bool:\n",
    "        cls.assert_not_empty(prefix)\n",
    "        if isinstance(strings, str):\n",
    "            strings = [strings]\n",
    "        return True in {string.startswith(prefix) for string in strings}\n",
    "\n",
    "    @classmethod\n",
    "    def remove_prefix(cls, string: str, prefix: str) -> str:\n",
    "        cls.assert_not_empty(string)\n",
    "        cls.assert_not_empty(prefix)\n",
    "        if string.startswith(prefix):\n",
    "            string = string[len(prefix):]\n",
    "        return string\n",
    "\n",
    "    @classmethod\n",
    "    def convert_str_to_type(cls, val: str, expected_type: Type) -> Any:\n",
    "        assert isinstance(expected_type, type)\n",
    "        if isinstance(val, expected_type):\n",
    "            return val\n",
    "        if expected_type == str:\n",
    "            return str(val)\n",
    "        if expected_type == bool and isinstance(val, str):\n",
    "            val = val.lower().strip().capitalize()  ## literal_eval does not parse \"false\", only \"False\".\n",
    "        out = literal_eval(StringUtils.assert_not_empty_and_strip(str(val)))\n",
    "        if expected_type == float and isinstance(out, int):\n",
    "            out = float(out)\n",
    "        if expected_type == int and isinstance(out, float) and int(out) == out:\n",
    "            out = int(out)\n",
    "        if expected_type == tuple and isinstance(out, list):\n",
    "            out = tuple(out)\n",
    "        if expected_type == list and isinstance(out, tuple):\n",
    "            out = list(out)\n",
    "        if expected_type == bool and out in [0, 1]:\n",
    "            out = bool(out)\n",
    "        if type(out) != expected_type:\n",
    "            raise ValueError(f'Input value {val} cannot be converted to {str(expected_type)}')\n",
    "        return out\n",
    "\n",
    "    @classmethod\n",
    "    def convert_bytes_to_human_readable(cls, size_in_bytes: int, num_decimals=3) -> str:\n",
    "        sizes: Dict[str, float] = cls.convert_size_from_bytes(size_in_bytes, unit=None, num_decimals=num_decimals)\n",
    "        sorted_sizes: List[Tuple[str, float]] = [\n",
    "            (k, v) for k, v in sorted(sizes.items(), key=lambda item: item[1])\n",
    "        ]\n",
    "        size_unit, size_val = None, None\n",
    "        for size_unit, size_val in sorted_sizes:\n",
    "            if size_val >= 1:\n",
    "                break\n",
    "        return f'{size_val} {size_unit}'\n",
    "\n",
    "    @classmethod\n",
    "    def convert_size_from_bytes(cls, size_in_bytes: int, unit: str = None, num_decimals=3) -> Union[Dict, float]:\n",
    "        size_in_bytes = float(size_in_bytes)\n",
    "        cur_size = size_in_bytes\n",
    "        sizes = {}\n",
    "        for size_name in cls.FILE_SIZE_UNITS:\n",
    "            val = round(cur_size, num_decimals)\n",
    "            i = 1\n",
    "            while val == 0:\n",
    "                val = round(cur_size, num_decimals + i)\n",
    "                i += 1\n",
    "            sizes[size_name] = val\n",
    "            i = int(math.floor(math.log(cur_size, 1024)))\n",
    "            cur_size = cur_size / 1024\n",
    "        if unit is not None:\n",
    "            assert isinstance(unit, str)\n",
    "            unit = unit.upper()\n",
    "            assert unit in cls.FILE_SIZE_UNITS\n",
    "            return sizes[unit]\n",
    "        return sizes\n",
    "\n",
    "    @classmethod\n",
    "    def convert_size_to_bytes(cls, size_in_human_readable: str) -> int:\n",
    "        size_in_human_readable: str = cls.assert_not_empty_and_strip(size_in_human_readable).upper()\n",
    "        size_selection_regex = f'''(\\d+(?:\\.\\d+)?) *({cls.PIPE.join(cls.FILE_SIZE_UNITS)})'''  ## This uses a non-capturing group: https://stackoverflow.com/a/3512530/4900327\n",
    "        matches = re.findall(size_selection_regex, size_in_human_readable)\n",
    "        if len(matches) != 1 or len(matches[0]) != 2:\n",
    "            raise ValueError(f'Cannot convert value \"{size_in_human_readable}\" to bytes.')\n",
    "        val, unit = matches[0]\n",
    "        val = float(val)\n",
    "        for file_size_unit in cls.FILE_SIZE_UNITS:\n",
    "            if unit == file_size_unit:\n",
    "                return int(round(val))\n",
    "            val = val * 1024\n",
    "        raise ValueError(f'Cannot convert value \"{size_in_human_readable}\" to bytes.')\n",
    "\n",
    "    @classmethod\n",
    "    def convert_seconds_to_human_readable(cls, time_in_seconds: float, num_decimals=3) -> str:\n",
    "        times: Dict[str, float] = cls.convert_time_from_seconds(time_in_seconds, unit=None, num_decimals=num_decimals)\n",
    "        sorted_times: List[Tuple[str, float]] = [\n",
    "            (k, v) for k, v in sorted(times.items(), key=lambda item: item[1])\n",
    "        ]\n",
    "        time_unit, time_val = None, None\n",
    "        for time_unit, time_val in sorted_times:\n",
    "            if time_val >= 1:\n",
    "                break\n",
    "        if num_decimals <= 0:\n",
    "            time_val = int(time_val)\n",
    "        return f'{time_val} {time_unit}'\n",
    "\n",
    "    @classmethod\n",
    "    def convert_time_from_seconds(cls, time_in_seconds: float, unit: str = None, num_decimals=3) -> Union[Dict, float]:\n",
    "        TIME_UNITS = {\n",
    "            \"milliseconds\": 1e-3,\n",
    "            \"seconds\": 1,\n",
    "            \"mins\": 60,\n",
    "            \"hours\": 60 * 60,\n",
    "            \"days\": 24 * 60 * 60\n",
    "        }\n",
    "        time_in_seconds = float(time_in_seconds)\n",
    "        times: Dict[str, float] = {\n",
    "            time_unit: round(time_in_seconds / TIME_UNITS[time_unit], num_decimals)\n",
    "            for time_unit in TIME_UNITS\n",
    "        }\n",
    "        if unit is not None:\n",
    "            assert isinstance(unit, str)\n",
    "            unit = unit.lower()\n",
    "            assert unit in TIME_UNITS\n",
    "            return times[unit]\n",
    "        return times\n",
    "\n",
    "    @classmethod\n",
    "    def minify_json(cls, blob: StructuredBlob) -> str:\n",
    "        return json.dumps(blob, indent=None, separators=(cls.COMMA, cls.COLON))\n",
    "\n",
    "    @classmethod\n",
    "    def pad_int_with_leading_zeros(cls, i: int, max_i: int = None) -> str:\n",
    "        assert isinstance(i, int) and i >= 0\n",
    "        if max_i is None:\n",
    "            return str(i)\n",
    "        assert isinstance(max_i, int) and max_i >= i\n",
    "        num_zeros = math.ceil(math.log10(max_i))  ## Ref: https://stackoverflow.com/a/51837162/4900327\n",
    "        if max_i == 10 ** num_zeros:  ## If it is a power of 10\n",
    "            num_zeros += 1\n",
    "        return f'{i:0{num_zeros}}'\n",
    "\n",
    "    @classmethod\n",
    "    def generate_random_strings(\n",
    "            cls, shape=(1,), min_num_chars=6, max_num_chars=6, spaces_prob: float = None, alphabet: Tuple = ALPHABET\n",
    "    ) -> Union[str, np.ndarray]:\n",
    "        assert isinstance(min_num_chars, int) and min_num_chars >= 0, f'min_num_chars must be a non-negative integer; ' \\\n",
    "                                                                      f'found: {str(min_num_chars)}'\n",
    "        assert isinstance(max_num_chars, int) and max_num_chars >= 1, f'max_num_chars must be a positive integer; ' \\\n",
    "                                                                      f'found: {str(max_num_chars)}'\n",
    "        assert min_num_chars <= max_num_chars, \\\n",
    "            f'Must have min_num_chars ({min_num_chars}) <= max_num_chars ({max_num_chars})'\n",
    "        if spaces_prob is not None:\n",
    "            assert isinstance(spaces_prob, float) and 0.0 < spaces_prob < 1.0, \\\n",
    "                f'spaces_prob must be a float in range (0.0, 1.0), and it cannot be 0.0 or 1.0. Found: {spaces_prob}'\n",
    "            num_spaces_to_add: int = int(round(len(alphabet) * spaces_prob / (1 - spaces_prob), 0))\n",
    "            alphabet = alphabet + num_spaces_to_add * (cls.SPACE,)\n",
    "\n",
    "        ## Ref: https://stackoverflow.com/a/25965461/4900327\n",
    "        random_alphabet_lists = np.random.choice(alphabet, shape + (max_num_chars,))\n",
    "        random_strings = np.apply_along_axis(\n",
    "            arr=random_alphabet_lists,\n",
    "            func1d=lambda random_alphabet_list:\n",
    "            ''.join(random_alphabet_list)[:np.random.randint(min_num_chars, max_num_chars + 1)],\n",
    "            axis=len(shape),\n",
    "        )\n",
    "        if shape == (1,):\n",
    "            return random_strings[0]\n",
    "        return random_strings\n",
    "\n",
    "    @classmethod\n",
    "    def parse_datetime(cls, dt: Union[str, int, float, datetime]) -> datetime:\n",
    "        if isinstance(dt, datetime):\n",
    "            return dt\n",
    "        elif type(dt) in [int, float]:\n",
    "            return datetime.fromtimestamp(dt)\n",
    "        elif isinstance(dt, str):\n",
    "            return datetime.fromisoformat(dt)\n",
    "        raise NotImplementedError(f'Cannot parse datetime from value {dt} with type {type(dt)}')\n",
    "\n",
    "    @classmethod\n",
    "    def convert_integer_to_base_n_str(cls, integer: int, base: int) -> str:\n",
    "        assert isinstance(integer, int)\n",
    "        assert isinstance(base, int) and base in cls.BASE_CONVERTER_MAP, \\\n",
    "            f'Param `base` must be an integer in {list(cls.BASE_CONVERTER_MAP.keys())}; found: {base}'\n",
    "        return cls.BASE_CONVERTER_MAP[base].encode(integer)\n",
    "\n",
    "    @classmethod\n",
    "    def hash(cls, val: Union[str, int, float, List, Dict], max_len: int = 256, base: int = 62) -> str:\n",
    "        \"\"\"\n",
    "        Constructs a hash of a JSON object or value.\n",
    "        :param val: any valid JSON value (including str, int, float, list, and dict).\n",
    "        :param max_len: the maximum length of the output hash (will truncate upto this length).\n",
    "        :param base: the base of the output hash.\n",
    "            Defaults to base56, which encodes the output in a ASCII-chars\n",
    "        :return: SHA256 hash.\n",
    "        \"\"\"\n",
    "\n",
    "        def hash_rec(val, base):\n",
    "            if isinstance(val, list):\n",
    "                return hash_rec(','.join([hash_rec(x, base=base) for x in val]), base=base)\n",
    "            elif isinstance(val, dict):\n",
    "                return hash_rec(\n",
    "                    [\n",
    "                        f'{hash_rec(k, base=base)}:{hash_rec(v, base=base)}'\n",
    "                        for k, v in sorted(val.items(), key=lambda kv: kv[0])\n",
    "                    ],\n",
    "                    base=base\n",
    "                )\n",
    "            return cls.convert_integer_to_base_n_str(int(sha256(str(val).encode('utf8')).hexdigest(), 16), base=base)\n",
    "\n",
    "        return hash_rec(val, base)[:max_len]\n",
    "\n",
    "    \n",
    "from typing import Dict, List, Union, Tuple, Optional\n",
    "import io, os, errno, sys, glob, pathlib, traceback, math, copy, time, logging\n",
    "# from eps_data_transformation_lib.util.StringUtils import StringUtils\n",
    "# from eps_data_transformation_lib.util.CollectionsUtils import CollectionsUtils\n",
    "\n",
    "\n",
    "class FileSystemUtil:\n",
    "    def __init__(self):\n",
    "        raise TypeError(f'Cannot instantiate class \"{str(self.__class__)}\"')\n",
    "\n",
    "    @classmethod\n",
    "    def exists(cls, path: str) -> bool:\n",
    "        return pathlib.Path(path).exists()\n",
    "\n",
    "    @classmethod\n",
    "    def dir_exists(cls, path: str) -> bool:\n",
    "        try:\n",
    "            return pathlib.Path(path).is_dir()\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.ENAMETOOLONG:\n",
    "                return False\n",
    "            raise e\n",
    "\n",
    "    @classmethod\n",
    "    def is_path_valid_dir(cls, local_path: str) -> bool:\n",
    "        local_path = StringUtils.assert_not_empty_and_strip(local_path)\n",
    "        return cls.dir_exists(local_path) or local_path.endswith(os.path.sep)\n",
    "\n",
    "    @classmethod\n",
    "    def file_exists(cls, path: str) -> bool:\n",
    "        try:\n",
    "            return pathlib.Path(path).is_file()\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.ENAMETOOLONG:\n",
    "                return False\n",
    "            raise e\n",
    "\n",
    "    @classmethod\n",
    "    def check_file_exists(cls, path: str):\n",
    "        if cls.file_exists(path) is False:\n",
    "            raise FileNotFoundError(f'Could not find file at location \"{path}\"')\n",
    "\n",
    "    @classmethod\n",
    "    def check_dir_exists(cls, path: str):\n",
    "        if cls.dir_exists(path) is False:\n",
    "            raise FileNotFoundError(f'Could not find dir at location \"{path}\"')\n",
    "\n",
    "    @classmethod\n",
    "    def files_exist(cls, paths: List[str]) -> bool:\n",
    "        for path in paths:\n",
    "            if not cls.file_exists(path):\n",
    "                logging.info(f'Path \"{path}\" does not exist')\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @classmethod\n",
    "    def get_dir(cls, path: str) -> str:\n",
    "        '''\n",
    "        Returns the directory of the path. If the path is an existing dir, returns the input.\n",
    "        :param path: input file or directory path.\n",
    "        :return: The dir of the passed path. Always ends in '/'.\n",
    "        '''\n",
    "        out_dir = None\n",
    "        path = StringUtils.assert_not_empty_and_strip(path)\n",
    "        if cls.dir_exists(path):  ## Works for both /home/seldon and /home/seldon/\n",
    "            out_dir = path if path.endswith(os.path.sep) else path + os.path.sep\n",
    "        else:\n",
    "            dir = os.path.dirname(path)\n",
    "            out_dir = dir if dir.endswith(os.path.sep) else dir + os.path.sep\n",
    "        return out_dir\n",
    "\n",
    "    @classmethod\n",
    "    def mkdir_if_does_not_exist(cls, path: str, err=False) -> bool:\n",
    "        try:\n",
    "            dir_path = cls.get_dir(path)\n",
    "            if not cls.is_writable(dir_path):\n",
    "                raise OSError(f'Insufficient permissions to create directory at path {path}')\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            if not cls.dir_exists(dir_path):\n",
    "                raise OSError(f'Could not create directory at path {path}')\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            if err:\n",
    "                raise e\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def is_writable(cls, path: str) -> bool:\n",
    "        '''\n",
    "        `True` if the current user has sufficient permissions to create the passed path; `False` otherwise.\n",
    "        Backs off to checking parent files until it hits the root (this handles cases where the path may not exist yet).\n",
    "        Ref: modified from https://stackoverflow.com/a/34102855\n",
    "        '''\n",
    "        ## Parent directory of the passed path.\n",
    "        dir = cls.get_dir(path)\n",
    "        if cls.dir_exists(dir):\n",
    "            return os.access(dir, os.W_OK)\n",
    "        dir_parents = pathlib.Path(dir).parents\n",
    "        for i in range(len(dir_parents)):\n",
    "            if cls.dir_exists(dir_parents[i]):\n",
    "                return os.access(dir_parents[i], os.W_OK)\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def list_files_in_dir(cls, dir_path, file_glob=StringUtils.ASTERISK, ignored_files=None) -> List[str]:\n",
    "        if ignored_files is None:\n",
    "            ignored_files = []\n",
    "        file_paths: List[str] = glob.glob(os.path.join(dir_path, file_glob))\n",
    "        file_names_map: Dict[str, str] = {file_path: os.path.basename(file_path) for file_path in file_paths}\n",
    "        file_names_map = CollectionsUtils.filter_dict_values(file_names_map, ignored_files, exclude=True)\n",
    "        file_paths = sorted(list(file_names_map.keys()))\n",
    "        return file_paths if len(file_paths) > 0 else []\n",
    "\n",
    "    @classmethod\n",
    "    def list_first_file_in_dir(cls, dir_path, file_glob=StringUtils.ASTERISK, ignored_files=None) -> Optional[str]:\n",
    "        file_paths: List[str] = cls.list_files_in_dir(dir_path, file_glob=file_glob, ignored_files=ignored_files)\n",
    "        return file_paths[0] if len(file_paths) > 0 else None\n",
    "\n",
    "    @classmethod\n",
    "    def list_only_file_in_dir(cls, dir_path, file_glob=StringUtils.ASTERISK, ignored_files=None) -> Optional[str]:\n",
    "        if cls.file_exists(dir_path):\n",
    "            return dir_path  ## Is actually a file\n",
    "        file_paths: List[str] = cls.list_files_in_dir(dir_path, file_glob=file_glob, ignored_files=ignored_files)\n",
    "        if len(file_paths) == 0:\n",
    "            return None\n",
    "        if len(file_paths) > 1:\n",
    "            raise FileNotFoundError(f'Multiple matching files are present in the directory')\n",
    "        return file_paths[0]\n",
    "\n",
    "    @classmethod\n",
    "    def get_file_size(cls, file_path: str, unit=None, num_decimals=3) -> Union[float, str]:\n",
    "        file_path = StringUtils.assert_not_empty_and_strip(file_path)\n",
    "        size_in_bytes = pathlib.Path(file_path).stat().st_size\n",
    "        if unit is not None:\n",
    "            return StringUtils.convert_size_from_bytes(size_in_bytes, unit=unit, num_decimals=num_decimals)\n",
    "        return StringUtils.convert_bytes_to_human_readable(size_in_bytes, num_decimals=num_decimals)\n",
    "\n",
    "    @classmethod\n",
    "    def get_time_last_modified(cls, path: str, num_decimals=3):\n",
    "        path = StringUtils.assert_not_empty_and_strip(path)\n",
    "        assert cls.exists(path)\n",
    "        return round(os.path.getmtime(path), num_decimals)\n",
    "\n",
    "    @classmethod\n",
    "    def get_last_modified_time(cls, path: str):\n",
    "        assert cls.exists(path)\n",
    "        return os.path.getmtime(path)\n",
    "\n",
    "    @classmethod\n",
    "    def get_seconds_since_last_modified(cls, path: str, num_decimals=3):\n",
    "        return round(time.time() - cls.get_last_modified_time(path), num_decimals)\n",
    "\n",
    "    @classmethod\n",
    "    def get_file_str(cls, file_path) -> str:\n",
    "        file_str: str = None\n",
    "        try:\n",
    "            with io.open(file_path, 'r') as inp:\n",
    "                file_str = inp.read()\n",
    "            StringUtils.assert_not_empty(file_str)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "        return file_str\n",
    "\n",
    "    @classmethod\n",
    "    def get_file_bytes(cls, file_path) -> bytes:\n",
    "        file_bytes: bytes = None\n",
    "        try:\n",
    "            with io.open(file_path, 'rb') as inp:\n",
    "                file_bytes = inp.read()\n",
    "            StringUtils.assert_not_empty_bytes(file_bytes)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "        return file_bytes\n",
    "\n",
    "    @classmethod\n",
    "    def put_file_str(cls, file_path, file_str: str, err=False) -> bool:\n",
    "        StringUtils.assert_not_empty(file_str)\n",
    "        try:\n",
    "            with io.open(file_path, 'w') as out:\n",
    "                out.write(file_str)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            if err:\n",
    "                raise e\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @classmethod\n",
    "    def construct_path_of_file_in_dir(cls, local_path: str, name: str, file_ending: str):\n",
    "        \"\"\"\n",
    "        If the path is a dir, uses the inputs to construct a file path. If path is a file, returns unchanged.\n",
    "        :param local_path: path to dir (or file) on filesystem.\n",
    "        :param name: name of the file.\n",
    "        :param file_ending: a string of the file ending.\n",
    "        :return: file path string.\n",
    "        \"\"\"\n",
    "        if cls.is_path_valid_dir(local_path):\n",
    "            file_name: str = StringUtils.assert_not_empty_and_strip(name) + \\\n",
    "                             StringUtils.assert_not_empty_and_strip(file_ending)\n",
    "            return os.path.join(cls.get_dir(local_path), file_name)\n",
    "        else:\n",
    "            return local_path\n",
    "\n",
    "    @classmethod\n",
    "    def is_stream(cls, obj):\n",
    "        return isinstance(obj, io.TextIOBase) and hasattr(obj, 'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([len(elem['context_tokens']) for elem in elems[1:]]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_full = elems[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(bioasq_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bioasq_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'header': {'dataset': 'BioASQ', 'split': 'train'}},\n",
       " {'context': \"Drosophila melanogaster has a single Adar gene encoding a protein related to mammalian ADAR2 that edits transcripts encoding glutamate receptor subunits. We describe the structure of the Drosophila Adar locus and use ModENCODE information to supplement published data on Adar gene transcription, and splicing. We discuss the roles of ADAR in Drosophila in terms of the two main types of RNA molecules edited and roles of ADARs as RNA-binding proteins. Site-specific RNA editing events in transcripts encoding ion channel subunits were initially found serendipitously and subsequent directed searches for editing sites and transcriptome sequencing have now led to 972 edited sites being identified in 597 transcripts. Four percent of D. melanogaster transcripts are site-specifically edited and these encode a wide range of largely membrane-associated proteins expressed particularly in CNS. Electrophysiological studies on the effects of specific RNA editing events on ion channel subunits do not suggest that loss of RNA editing events in ion channels consistently produce a particular outcome such as making Adar mutant neurons more excitable. This possibility would have been consistent with neurodegeneration seen in Adar mutant fly brains. A further set of ADAR targets are dsRNA intermediates in siRNA generation, derived from transposons and from structured RNA loci. Transcripts with convergent overlapping 3' ends are also edited and the first discovered instance of RNA editing in Drosophila, in the Rnp4F transcript, is an example. There is no evidence yet to show that Adar antagonizes RNA interference in Drosophila. Evidence has been obtained that catalytically inactive ADAR proteins exert effects on microRNA generation and RNA interference. Whether all effects of inactive ADARs are due to RNA-binding or to even further roles of these proteins remains to be determined.\",\n",
       "  'qas': [{'question': 'Which is the major RNA editing enzyme in Drosophila melanogaster?',\n",
       "    'answers': ['ADAR', 'adenosine deaminase, RNA-specific'],\n",
       "    'qid': '9bb16ae9ce384988b2c0a173f93c5be4',\n",
       "    'question_tokens': [['Which', 0],\n",
       "     ['is', 6],\n",
       "     ['the', 9],\n",
       "     ['major', 13],\n",
       "     ['RNA', 19],\n",
       "     ['editing', 23],\n",
       "     ['enzyme', 31],\n",
       "     ['in', 38],\n",
       "     ['Drosophila', 41],\n",
       "     ['melanogaster', 52],\n",
       "     ['?', 64]],\n",
       "    'detected_answers': [{'text': 'ADAR',\n",
       "      'token_spans': [[272, 272],\n",
       "       [29, 29],\n",
       "       [5, 5],\n",
       "       [202, 202],\n",
       "       [52, 52],\n",
       "       [40, 40],\n",
       "       [258, 258],\n",
       "       [193, 193],\n",
       "       [177, 177]],\n",
       "      'char_spans': [[1685, 1688],\n",
       "       [198, 201],\n",
       "       [37, 40],\n",
       "       [1262, 1265],\n",
       "       [334, 337],\n",
       "       [271, 274],\n",
       "       [1581, 1584],\n",
       "       [1221, 1224],\n",
       "       [1110, 1113]]}]}],\n",
       "  'context_tokens': [['Drosophila', 0],\n",
       "   ['melanogaster', 11],\n",
       "   ['has', 24],\n",
       "   ['a', 28],\n",
       "   ['single', 30],\n",
       "   ['Adar', 37],\n",
       "   ['gene', 42],\n",
       "   ['encoding', 47],\n",
       "   ['a', 56],\n",
       "   ['protein', 58],\n",
       "   ['related', 66],\n",
       "   ['to', 74],\n",
       "   ['mammalian', 77],\n",
       "   ['ADAR2', 87],\n",
       "   ['that', 93],\n",
       "   ['edits', 98],\n",
       "   ['transcripts', 104],\n",
       "   ['encoding', 116],\n",
       "   ['glutamate', 125],\n",
       "   ['receptor', 135],\n",
       "   ['subunits', 144],\n",
       "   ['.', 152],\n",
       "   ['We', 154],\n",
       "   ['describe', 157],\n",
       "   ['the', 166],\n",
       "   ['structure', 170],\n",
       "   ['of', 180],\n",
       "   ['the', 183],\n",
       "   ['Drosophila', 187],\n",
       "   ['Adar', 198],\n",
       "   ['locus', 203],\n",
       "   ['and', 209],\n",
       "   ['use', 213],\n",
       "   ['ModENCODE', 217],\n",
       "   ['information', 227],\n",
       "   ['to', 239],\n",
       "   ['supplement', 242],\n",
       "   ['published', 253],\n",
       "   ['data', 263],\n",
       "   ['on', 268],\n",
       "   ['Adar', 271],\n",
       "   ['gene', 276],\n",
       "   ['transcription', 281],\n",
       "   [',', 294],\n",
       "   ['and', 296],\n",
       "   ['splicing', 300],\n",
       "   ['.', 308],\n",
       "   ['We', 310],\n",
       "   ['discuss', 313],\n",
       "   ['the', 321],\n",
       "   ['roles', 325],\n",
       "   ['of', 331],\n",
       "   ['ADAR', 334],\n",
       "   ['in', 339],\n",
       "   ['Drosophila', 342],\n",
       "   ['in', 353],\n",
       "   ['terms', 356],\n",
       "   ['of', 362],\n",
       "   ['the', 365],\n",
       "   ['two', 369],\n",
       "   ['main', 373],\n",
       "   ['types', 378],\n",
       "   ['of', 384],\n",
       "   ['RNA', 387],\n",
       "   ['molecules', 391],\n",
       "   ['edited', 401],\n",
       "   ['and', 408],\n",
       "   ['roles', 412],\n",
       "   ['of', 418],\n",
       "   ['ADARs', 421],\n",
       "   ['as', 427],\n",
       "   ['RNA', 430],\n",
       "   ['-', 433],\n",
       "   ['binding', 434],\n",
       "   ['proteins', 442],\n",
       "   ['.', 450],\n",
       "   ['Site', 452],\n",
       "   ['-', 456],\n",
       "   ['specific', 457],\n",
       "   ['RNA', 466],\n",
       "   ['editing', 470],\n",
       "   ['events', 478],\n",
       "   ['in', 485],\n",
       "   ['transcripts', 488],\n",
       "   ['encoding', 500],\n",
       "   ['ion', 509],\n",
       "   ['channel', 513],\n",
       "   ['subunits', 521],\n",
       "   ['were', 530],\n",
       "   ['initially', 535],\n",
       "   ['found', 545],\n",
       "   ['serendipitously', 551],\n",
       "   ['and', 567],\n",
       "   ['subsequent', 571],\n",
       "   ['directed', 582],\n",
       "   ['searches', 591],\n",
       "   ['for', 600],\n",
       "   ['editing', 604],\n",
       "   ['sites', 612],\n",
       "   ['and', 618],\n",
       "   ['transcriptome', 622],\n",
       "   ['sequencing', 636],\n",
       "   ['have', 647],\n",
       "   ['now', 652],\n",
       "   ['led', 656],\n",
       "   ['to', 660],\n",
       "   ['972', 663],\n",
       "   ['edited', 667],\n",
       "   ['sites', 674],\n",
       "   ['being', 680],\n",
       "   ['identified', 686],\n",
       "   ['in', 697],\n",
       "   ['597', 700],\n",
       "   ['transcripts', 704],\n",
       "   ['.', 715],\n",
       "   ['Four', 717],\n",
       "   ['percent', 722],\n",
       "   ['of', 730],\n",
       "   ['D.', 733],\n",
       "   ['melanogaster', 736],\n",
       "   ['transcripts', 749],\n",
       "   ['are', 761],\n",
       "   ['site', 765],\n",
       "   ['-', 769],\n",
       "   ['specifically', 770],\n",
       "   ['edited', 783],\n",
       "   ['and', 790],\n",
       "   ['these', 794],\n",
       "   ['encode', 800],\n",
       "   ['a', 807],\n",
       "   ['wide', 809],\n",
       "   ['range', 814],\n",
       "   ['of', 820],\n",
       "   ['largely', 823],\n",
       "   ['membrane', 831],\n",
       "   ['-', 839],\n",
       "   ['associated', 840],\n",
       "   ['proteins', 851],\n",
       "   ['expressed', 860],\n",
       "   ['particularly', 870],\n",
       "   ['in', 883],\n",
       "   ['CNS', 886],\n",
       "   ['.', 889],\n",
       "   ['Electrophysiological', 891],\n",
       "   ['studies', 912],\n",
       "   ['on', 920],\n",
       "   ['the', 923],\n",
       "   ['effects', 927],\n",
       "   ['of', 935],\n",
       "   ['specific', 938],\n",
       "   ['RNA', 947],\n",
       "   ['editing', 951],\n",
       "   ['events', 959],\n",
       "   ['on', 966],\n",
       "   ['ion', 969],\n",
       "   ['channel', 973],\n",
       "   ['subunits', 981],\n",
       "   ['do', 990],\n",
       "   ['not', 993],\n",
       "   ['suggest', 997],\n",
       "   ['that', 1005],\n",
       "   ['loss', 1010],\n",
       "   ['of', 1015],\n",
       "   ['RNA', 1018],\n",
       "   ['editing', 1022],\n",
       "   ['events', 1030],\n",
       "   ['in', 1037],\n",
       "   ['ion', 1040],\n",
       "   ['channels', 1044],\n",
       "   ['consistently', 1053],\n",
       "   ['produce', 1066],\n",
       "   ['a', 1074],\n",
       "   ['particular', 1076],\n",
       "   ['outcome', 1087],\n",
       "   ['such', 1095],\n",
       "   ['as', 1100],\n",
       "   ['making', 1103],\n",
       "   ['Adar', 1110],\n",
       "   ['mutant', 1115],\n",
       "   ['neurons', 1122],\n",
       "   ['more', 1130],\n",
       "   ['excitable', 1135],\n",
       "   ['.', 1144],\n",
       "   ['This', 1146],\n",
       "   ['possibility', 1151],\n",
       "   ['would', 1163],\n",
       "   ['have', 1169],\n",
       "   ['been', 1174],\n",
       "   ['consistent', 1179],\n",
       "   ['with', 1190],\n",
       "   ['neurodegeneration', 1195],\n",
       "   ['seen', 1213],\n",
       "   ['in', 1218],\n",
       "   ['Adar', 1221],\n",
       "   ['mutant', 1226],\n",
       "   ['fly', 1233],\n",
       "   ['brains', 1237],\n",
       "   ['.', 1243],\n",
       "   ['A', 1245],\n",
       "   ['further', 1247],\n",
       "   ['set', 1255],\n",
       "   ['of', 1259],\n",
       "   ['ADAR', 1262],\n",
       "   ['targets', 1267],\n",
       "   ['are', 1275],\n",
       "   ['dsRNA', 1279],\n",
       "   ['intermediates', 1285],\n",
       "   ['in', 1299],\n",
       "   ['siRNA', 1302],\n",
       "   ['generation', 1308],\n",
       "   [',', 1318],\n",
       "   ['derived', 1320],\n",
       "   ['from', 1328],\n",
       "   ['transposons', 1333],\n",
       "   ['and', 1345],\n",
       "   ['from', 1349],\n",
       "   ['structured', 1354],\n",
       "   ['RNA', 1365],\n",
       "   ['loci', 1369],\n",
       "   ['.', 1373],\n",
       "   ['Transcripts', 1375],\n",
       "   ['with', 1387],\n",
       "   ['convergent', 1392],\n",
       "   ['overlapping', 1403],\n",
       "   ['3', 1415],\n",
       "   [\"'\", 1416],\n",
       "   ['ends', 1418],\n",
       "   ['are', 1423],\n",
       "   ['also', 1427],\n",
       "   ['edited', 1432],\n",
       "   ['and', 1439],\n",
       "   ['the', 1443],\n",
       "   ['first', 1447],\n",
       "   ['discovered', 1453],\n",
       "   ['instance', 1464],\n",
       "   ['of', 1473],\n",
       "   ['RNA', 1476],\n",
       "   ['editing', 1480],\n",
       "   ['in', 1488],\n",
       "   ['Drosophila', 1491],\n",
       "   [',', 1501],\n",
       "   ['in', 1503],\n",
       "   ['the', 1506],\n",
       "   ['Rnp4F', 1510],\n",
       "   ['transcript', 1516],\n",
       "   [',', 1526],\n",
       "   ['is', 1528],\n",
       "   ['an', 1531],\n",
       "   ['example', 1534],\n",
       "   ['.', 1541],\n",
       "   ['There', 1543],\n",
       "   ['is', 1549],\n",
       "   ['no', 1552],\n",
       "   ['evidence', 1555],\n",
       "   ['yet', 1564],\n",
       "   ['to', 1568],\n",
       "   ['show', 1571],\n",
       "   ['that', 1576],\n",
       "   ['Adar', 1581],\n",
       "   ['antagonizes', 1586],\n",
       "   ['RNA', 1598],\n",
       "   ['interference', 1602],\n",
       "   ['in', 1615],\n",
       "   ['Drosophila', 1618],\n",
       "   ['.', 1628],\n",
       "   ['Evidence', 1630],\n",
       "   ['has', 1639],\n",
       "   ['been', 1643],\n",
       "   ['obtained', 1648],\n",
       "   ['that', 1657],\n",
       "   ['catalytically', 1662],\n",
       "   ['inactive', 1676],\n",
       "   ['ADAR', 1685],\n",
       "   ['proteins', 1690],\n",
       "   ['exert', 1699],\n",
       "   ['effects', 1705],\n",
       "   ['on', 1713],\n",
       "   ['microRNA', 1716],\n",
       "   ['generation', 1725],\n",
       "   ['and', 1736],\n",
       "   ['RNA', 1740],\n",
       "   ['interference', 1744],\n",
       "   ['.', 1756],\n",
       "   ['Whether', 1758],\n",
       "   ['all', 1766],\n",
       "   ['effects', 1770],\n",
       "   ['of', 1778],\n",
       "   ['inactive', 1781],\n",
       "   ['ADARs', 1790],\n",
       "   ['are', 1796],\n",
       "   ['due', 1800],\n",
       "   ['to', 1804],\n",
       "   ['RNA', 1807],\n",
       "   ['-', 1810],\n",
       "   ['binding', 1811],\n",
       "   ['or', 1819],\n",
       "   ['to', 1822],\n",
       "   ['even', 1825],\n",
       "   ['further', 1830],\n",
       "   ['roles', 1838],\n",
       "   ['of', 1844],\n",
       "   ['these', 1847],\n",
       "   ['proteins', 1853],\n",
       "   ['remains', 1862],\n",
       "   ['to', 1870],\n",
       "   ['be', 1873],\n",
       "   ['determined', 1876],\n",
       "   ['.', 1886]]},\n",
       " {'context': \"Kx is lacking in the RBCs of patients with the McLeod syndrome. This condition is sometimes associated with chronic granulomatous disease (CGD). If given allogeneic RBCs, CGD patients with the McLeod phenotype may produce anti-Kx and anti-Km, and only phenotypically matched McLeod blood would be compatible. McLeod phenotype persons without CGD have made anti-Km but not anti-Kx (2 examples), and thus both McLeod and K(O) blood would be compatible. RBCs from a transfused patient with the McLeod phenotype but not with CGD (non-CGD McLeod) were typed for the Kell blood group antigens, and the plasma was analyzed for the presence of antibody by agglutination. The molecular basis was determined by analyzing for XK protein on RBC membranes by Western immunoblotting, by sequencing the XK gene, and by RFLP. The RBCs did not react with anti-Kx + anti-Km and showed weakening of Kell system antigens. The patient's plasma reacted moderately (2+) with RBCs of common Kell type and strongly (4+) with K(O) RBCs and RBCs of common Kell type treated with dithiothreitol, and did not react with McLeod RBCs. XK protein was absent from the RBC membranes. The XK gene had a point mutation in the donor splice site of intron 1 (G>C). This is the first report describing the molecular alteration in a non-CGD McLeod patient who has made anti-Kx. The immune response of people with the McLeod phenotype can vary, and K(O) blood may not always be compatible.\",\n",
       "  'qas': [{'question': 'Mutation of which gene is associated with McLeod syndrome?',\n",
       "    'answers': ['XK'],\n",
       "    'qid': 'ae5bb34ab378486298ab61b3973ece7b',\n",
       "    'question_tokens': [['Mutation', 0],\n",
       "     ['of', 9],\n",
       "     ['which', 12],\n",
       "     ['gene', 18],\n",
       "     ['is', 23],\n",
       "     ['associated', 26],\n",
       "     ['with', 37],\n",
       "     ['McLeod', 42],\n",
       "     ['syndrome', 49],\n",
       "     ['?', 57]],\n",
       "    'detected_answers': [{'text': 'XK',\n",
       "      'token_spans': [[232, 232], [150, 150], [222, 222], [138, 138]],\n",
       "      'char_spans': [[1154, 1155], [788, 789], [1104, 1105], [715, 716]]}]}],\n",
       "  'context_tokens': [['Kx', 0],\n",
       "   ['is', 3],\n",
       "   ['lacking', 6],\n",
       "   ['in', 14],\n",
       "   ['the', 17],\n",
       "   ['RBCs', 21],\n",
       "   ['of', 26],\n",
       "   ['patients', 29],\n",
       "   ['with', 38],\n",
       "   ['the', 43],\n",
       "   ['McLeod', 47],\n",
       "   ['syndrome', 54],\n",
       "   ['.', 62],\n",
       "   ['This', 64],\n",
       "   ['condition', 69],\n",
       "   ['is', 79],\n",
       "   ['sometimes', 82],\n",
       "   ['associated', 92],\n",
       "   ['with', 103],\n",
       "   ['chronic', 108],\n",
       "   ['granulomatous', 116],\n",
       "   ['disease', 130],\n",
       "   ['(', 138],\n",
       "   ['CGD', 139],\n",
       "   [')', 142],\n",
       "   ['.', 143],\n",
       "   ['If', 145],\n",
       "   ['given', 148],\n",
       "   ['allogeneic', 154],\n",
       "   ['RBCs', 165],\n",
       "   [',', 169],\n",
       "   ['CGD', 171],\n",
       "   ['patients', 175],\n",
       "   ['with', 184],\n",
       "   ['the', 189],\n",
       "   ['McLeod', 193],\n",
       "   ['phenotype', 200],\n",
       "   ['may', 210],\n",
       "   ['produce', 214],\n",
       "   ['anti', 222],\n",
       "   ['-', 226],\n",
       "   ['Kx', 227],\n",
       "   ['and', 230],\n",
       "   ['anti', 234],\n",
       "   ['-', 238],\n",
       "   ['Km', 239],\n",
       "   [',', 241],\n",
       "   ['and', 243],\n",
       "   ['only', 247],\n",
       "   ['phenotypically', 252],\n",
       "   ['matched', 267],\n",
       "   ['McLeod', 275],\n",
       "   ['blood', 282],\n",
       "   ['would', 288],\n",
       "   ['be', 294],\n",
       "   ['compatible', 297],\n",
       "   ['.', 307],\n",
       "   ['McLeod', 309],\n",
       "   ['phenotype', 316],\n",
       "   ['persons', 326],\n",
       "   ['without', 334],\n",
       "   ['CGD', 342],\n",
       "   ['have', 346],\n",
       "   ['made', 351],\n",
       "   ['anti', 356],\n",
       "   ['-', 360],\n",
       "   ['Km', 361],\n",
       "   ['but', 364],\n",
       "   ['not', 368],\n",
       "   ['anti', 372],\n",
       "   ['-', 376],\n",
       "   ['Kx', 377],\n",
       "   ['(', 380],\n",
       "   ['2', 381],\n",
       "   ['examples', 383],\n",
       "   [')', 391],\n",
       "   [',', 392],\n",
       "   ['and', 394],\n",
       "   ['thus', 398],\n",
       "   ['both', 403],\n",
       "   ['McLeod', 408],\n",
       "   ['and', 415],\n",
       "   ['K(O', 419],\n",
       "   [')', 422],\n",
       "   ['blood', 424],\n",
       "   ['would', 430],\n",
       "   ['be', 436],\n",
       "   ['compatible', 439],\n",
       "   ['.', 449],\n",
       "   ['RBCs', 451],\n",
       "   ['from', 456],\n",
       "   ['a', 461],\n",
       "   ['transfused', 463],\n",
       "   ['patient', 474],\n",
       "   ['with', 482],\n",
       "   ['the', 487],\n",
       "   ['McLeod', 491],\n",
       "   ['phenotype', 498],\n",
       "   ['but', 508],\n",
       "   ['not', 512],\n",
       "   ['with', 516],\n",
       "   ['CGD', 521],\n",
       "   ['(', 525],\n",
       "   ['non', 526],\n",
       "   ['-', 529],\n",
       "   ['CGD', 530],\n",
       "   ['McLeod', 534],\n",
       "   [')', 540],\n",
       "   ['were', 542],\n",
       "   ['typed', 547],\n",
       "   ['for', 553],\n",
       "   ['the', 557],\n",
       "   ['Kell', 561],\n",
       "   ['blood', 566],\n",
       "   ['group', 572],\n",
       "   ['antigens', 578],\n",
       "   [',', 586],\n",
       "   ['and', 588],\n",
       "   ['the', 592],\n",
       "   ['plasma', 596],\n",
       "   ['was', 603],\n",
       "   ['analyzed', 607],\n",
       "   ['for', 616],\n",
       "   ['the', 620],\n",
       "   ['presence', 624],\n",
       "   ['of', 633],\n",
       "   ['antibody', 636],\n",
       "   ['by', 645],\n",
       "   ['agglutination', 648],\n",
       "   ['.', 661],\n",
       "   ['The', 663],\n",
       "   ['molecular', 667],\n",
       "   ['basis', 677],\n",
       "   ['was', 683],\n",
       "   ['determined', 687],\n",
       "   ['by', 698],\n",
       "   ['analyzing', 701],\n",
       "   ['for', 711],\n",
       "   ['XK', 715],\n",
       "   ['protein', 718],\n",
       "   ['on', 726],\n",
       "   ['RBC', 729],\n",
       "   ['membranes', 733],\n",
       "   ['by', 743],\n",
       "   ['Western', 746],\n",
       "   ['immunoblotting', 754],\n",
       "   [',', 768],\n",
       "   ['by', 770],\n",
       "   ['sequencing', 773],\n",
       "   ['the', 784],\n",
       "   ['XK', 788],\n",
       "   ['gene', 791],\n",
       "   [',', 795],\n",
       "   ['and', 797],\n",
       "   ['by', 801],\n",
       "   ['RFLP', 804],\n",
       "   ['.', 808],\n",
       "   ['The', 810],\n",
       "   ['RBCs', 814],\n",
       "   ['did', 819],\n",
       "   ['not', 823],\n",
       "   ['react', 827],\n",
       "   ['with', 833],\n",
       "   ['anti', 838],\n",
       "   ['-', 842],\n",
       "   ['Kx', 843],\n",
       "   ['+', 846],\n",
       "   ['anti', 848],\n",
       "   ['-', 852],\n",
       "   ['Km', 853],\n",
       "   ['and', 856],\n",
       "   ['showed', 860],\n",
       "   ['weakening', 867],\n",
       "   ['of', 877],\n",
       "   ['Kell', 880],\n",
       "   ['system', 885],\n",
       "   ['antigens', 892],\n",
       "   ['.', 900],\n",
       "   ['The', 902],\n",
       "   ['patient', 906],\n",
       "   [\"'s\", 913],\n",
       "   ['plasma', 916],\n",
       "   ['reacted', 923],\n",
       "   ['moderately', 931],\n",
       "   ['(', 942],\n",
       "   ['2', 943],\n",
       "   ['+', 944],\n",
       "   [')', 945],\n",
       "   ['with', 947],\n",
       "   ['RBCs', 952],\n",
       "   ['of', 957],\n",
       "   ['common', 960],\n",
       "   ['Kell', 967],\n",
       "   ['type', 972],\n",
       "   ['and', 977],\n",
       "   ['strongly', 981],\n",
       "   ['(', 990],\n",
       "   ['4', 991],\n",
       "   ['+', 992],\n",
       "   [')', 993],\n",
       "   ['with', 995],\n",
       "   ['K(O', 1000],\n",
       "   [')', 1003],\n",
       "   ['RBCs', 1005],\n",
       "   ['and', 1010],\n",
       "   ['RBCs', 1014],\n",
       "   ['of', 1019],\n",
       "   ['common', 1022],\n",
       "   ['Kell', 1029],\n",
       "   ['type', 1034],\n",
       "   ['treated', 1039],\n",
       "   ['with', 1047],\n",
       "   ['dithiothreitol', 1052],\n",
       "   [',', 1066],\n",
       "   ['and', 1068],\n",
       "   ['did', 1072],\n",
       "   ['not', 1076],\n",
       "   ['react', 1080],\n",
       "   ['with', 1086],\n",
       "   ['McLeod', 1091],\n",
       "   ['RBCs', 1098],\n",
       "   ['.', 1102],\n",
       "   ['XK', 1104],\n",
       "   ['protein', 1107],\n",
       "   ['was', 1115],\n",
       "   ['absent', 1119],\n",
       "   ['from', 1126],\n",
       "   ['the', 1131],\n",
       "   ['RBC', 1135],\n",
       "   ['membranes', 1139],\n",
       "   ['.', 1148],\n",
       "   ['The', 1150],\n",
       "   ['XK', 1154],\n",
       "   ['gene', 1157],\n",
       "   ['had', 1162],\n",
       "   ['a', 1166],\n",
       "   ['point', 1168],\n",
       "   ['mutation', 1174],\n",
       "   ['in', 1183],\n",
       "   ['the', 1186],\n",
       "   ['donor', 1190],\n",
       "   ['splice', 1196],\n",
       "   ['site', 1203],\n",
       "   ['of', 1208],\n",
       "   ['intron', 1211],\n",
       "   ['1', 1218],\n",
       "   ['(', 1220],\n",
       "   ['G', 1221],\n",
       "   ['>', 1222],\n",
       "   ['C', 1223],\n",
       "   [')', 1224],\n",
       "   ['.', 1225],\n",
       "   ['This', 1227],\n",
       "   ['is', 1232],\n",
       "   ['the', 1235],\n",
       "   ['first', 1239],\n",
       "   ['report', 1245],\n",
       "   ['describing', 1252],\n",
       "   ['the', 1263],\n",
       "   ['molecular', 1267],\n",
       "   ['alteration', 1277],\n",
       "   ['in', 1288],\n",
       "   ['a', 1291],\n",
       "   ['non', 1293],\n",
       "   ['-', 1296],\n",
       "   ['CGD', 1297],\n",
       "   ['McLeod', 1301],\n",
       "   ['patient', 1308],\n",
       "   ['who', 1316],\n",
       "   ['has', 1320],\n",
       "   ['made', 1324],\n",
       "   ['anti', 1329],\n",
       "   ['-', 1333],\n",
       "   ['Kx', 1334],\n",
       "   ['.', 1336],\n",
       "   ['The', 1338],\n",
       "   ['immune', 1342],\n",
       "   ['response', 1349],\n",
       "   ['of', 1358],\n",
       "   ['people', 1361],\n",
       "   ['with', 1368],\n",
       "   ['the', 1373],\n",
       "   ['McLeod', 1377],\n",
       "   ['phenotype', 1384],\n",
       "   ['can', 1394],\n",
       "   ['vary', 1398],\n",
       "   [',', 1402],\n",
       "   ['and', 1404],\n",
       "   ['K(O', 1408],\n",
       "   [')', 1411],\n",
       "   ['blood', 1413],\n",
       "   ['may', 1419],\n",
       "   ['not', 1423],\n",
       "   ['always', 1427],\n",
       "   ['be', 1434],\n",
       "   ['compatible', 1437],\n",
       "   ['.', 1447]]}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioasq_train = bioasq_full[ :round(0.7*len(bioasq_full))]\n",
    "bioasq_train.insert(0, {'header': {'dataset': 'BioASQ', 'split': 'train'}})\n",
    "print(len(bioasq_train))\n",
    "bioasq_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('datasets/bioasq_train.jsonl.gz', 'wb') as f:\n",
    "    for ex in bioasq_train:\n",
    "        ## Ref: https://stackoverflow.com/a/39451012\n",
    "        f.write((json.dumps(ex)+'\\n').encode('utf-8'))\n",
    "        \n",
    "with gzip.open('datasets/bioasq_dev.jsonl.gz', 'wb') as f:\n",
    "    for ex in bioasq_dev:\n",
    "        ## Ref: https://stackoverflow.com/a/39451012\n",
    "        f.write((json.dumps(ex)+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'header': {'dataset': 'BioASQ', 'split': 'dev'}},\n",
       " {'context': 'Dasatinib (BMS-354825) is a Src/ABL tyrosine kinase inhibitor currently approved for the treatment of chronic myeloid leukemia. Dasatinib has increased potency against ABL compared to the current therapy imatinib, and is effective in many cases where disease is resistant to imatinib. Dasatinib also inhibits many Src-family tyrosine kinases. We have demonstrated in this study that dasatinib is able to block the function of normal human T-lymphocytes in vitro at clinically relevant concentrations. T-cell functions including proliferation, activation and cytokine production were all uniformly inhibited in the presence of dasatinib. We also demonstrated inhibition of TCR signalling through Src-family kinase LCK, and predicted that inhibition of LCK and other kinases involved in T-cell signalling by dasatinib is responsible for the suppression of T-cell function. These findings raise the concern about potential T-cell inhibition in patients taking dasatinib, and suggest a possible application for the treatment of T-cell mediated immune disorders.',\n",
       "  'qas': [{'question': 'Does dasatinib promote or inhibit T-cell proliferation?',\n",
       "    'answers': ['inhibits'],\n",
       "    'qid': '5b937d99df5342ca8ffb9a12ec8714ce',\n",
       "    'question_tokens': [['Does', 0],\n",
       "     ['dasatinib', 5],\n",
       "     ['promote', 15],\n",
       "     ['or', 23],\n",
       "     ['inhibit', 26],\n",
       "     ['T', 34],\n",
       "     ['-', 35],\n",
       "     ['cell', 36],\n",
       "     ['proliferation', 41],\n",
       "     ['?', 54]],\n",
       "    'detected_answers': [{'text': 'inhibits',\n",
       "      'token_spans': [[50, 50]],\n",
       "      'char_spans': [[300, 307]]}]}],\n",
       "  'context_tokens': [['Dasatinib', 0],\n",
       "   ['(', 10],\n",
       "   ['BMS-354825', 11],\n",
       "   [')', 21],\n",
       "   ['is', 23],\n",
       "   ['a', 26],\n",
       "   ['Src', 28],\n",
       "   ['/', 31],\n",
       "   ['ABL', 32],\n",
       "   ['tyrosine', 36],\n",
       "   ['kinase', 45],\n",
       "   ['inhibitor', 52],\n",
       "   ['currently', 62],\n",
       "   ['approved', 72],\n",
       "   ['for', 81],\n",
       "   ['the', 85],\n",
       "   ['treatment', 89],\n",
       "   ['of', 99],\n",
       "   ['chronic', 102],\n",
       "   ['myeloid', 110],\n",
       "   ['leukemia', 118],\n",
       "   ['.', 126],\n",
       "   ['Dasatinib', 128],\n",
       "   ['has', 138],\n",
       "   ['increased', 142],\n",
       "   ['potency', 152],\n",
       "   ['against', 160],\n",
       "   ['ABL', 168],\n",
       "   ['compared', 172],\n",
       "   ['to', 181],\n",
       "   ['the', 184],\n",
       "   ['current', 188],\n",
       "   ['therapy', 196],\n",
       "   ['imatinib', 204],\n",
       "   [',', 212],\n",
       "   ['and', 214],\n",
       "   ['is', 218],\n",
       "   ['effective', 221],\n",
       "   ['in', 231],\n",
       "   ['many', 234],\n",
       "   ['cases', 239],\n",
       "   ['where', 245],\n",
       "   ['disease', 251],\n",
       "   ['is', 259],\n",
       "   ['resistant', 262],\n",
       "   ['to', 272],\n",
       "   ['imatinib', 275],\n",
       "   ['.', 283],\n",
       "   ['Dasatinib', 285],\n",
       "   ['also', 295],\n",
       "   ['inhibits', 300],\n",
       "   ['many', 309],\n",
       "   ['Src', 314],\n",
       "   ['-', 317],\n",
       "   ['family', 318],\n",
       "   ['tyrosine', 325],\n",
       "   ['kinases', 334],\n",
       "   ['.', 341],\n",
       "   ['We', 343],\n",
       "   ['have', 346],\n",
       "   ['demonstrated', 351],\n",
       "   ['in', 364],\n",
       "   ['this', 367],\n",
       "   ['study', 372],\n",
       "   ['that', 378],\n",
       "   ['dasatinib', 383],\n",
       "   ['is', 393],\n",
       "   ['able', 396],\n",
       "   ['to', 401],\n",
       "   ['block', 404],\n",
       "   ['the', 410],\n",
       "   ['function', 414],\n",
       "   ['of', 423],\n",
       "   ['normal', 426],\n",
       "   ['human', 433],\n",
       "   ['T', 439],\n",
       "   ['-', 440],\n",
       "   ['lymphocytes', 441],\n",
       "   ['in', 453],\n",
       "   ['vitro', 456],\n",
       "   ['at', 462],\n",
       "   ['clinically', 465],\n",
       "   ['relevant', 476],\n",
       "   ['concentrations', 485],\n",
       "   ['.', 499],\n",
       "   ['T', 501],\n",
       "   ['-', 502],\n",
       "   ['cell', 503],\n",
       "   ['functions', 508],\n",
       "   ['including', 518],\n",
       "   ['proliferation', 528],\n",
       "   [',', 541],\n",
       "   ['activation', 543],\n",
       "   ['and', 554],\n",
       "   ['cytokine', 558],\n",
       "   ['production', 567],\n",
       "   ['were', 578],\n",
       "   ['all', 583],\n",
       "   ['uniformly', 587],\n",
       "   ['inhibited', 597],\n",
       "   ['in', 607],\n",
       "   ['the', 610],\n",
       "   ['presence', 614],\n",
       "   ['of', 623],\n",
       "   ['dasatinib', 626],\n",
       "   ['.', 635],\n",
       "   ['We', 637],\n",
       "   ['also', 640],\n",
       "   ['demonstrated', 645],\n",
       "   ['inhibition', 658],\n",
       "   ['of', 669],\n",
       "   ['TCR', 672],\n",
       "   ['signalling', 676],\n",
       "   ['through', 687],\n",
       "   ['Src', 695],\n",
       "   ['-', 698],\n",
       "   ['family', 699],\n",
       "   ['kinase', 706],\n",
       "   ['LCK', 713],\n",
       "   [',', 716],\n",
       "   ['and', 718],\n",
       "   ['predicted', 722],\n",
       "   ['that', 732],\n",
       "   ['inhibition', 737],\n",
       "   ['of', 748],\n",
       "   ['LCK', 751],\n",
       "   ['and', 755],\n",
       "   ['other', 759],\n",
       "   ['kinases', 765],\n",
       "   ['involved', 773],\n",
       "   ['in', 782],\n",
       "   ['T', 785],\n",
       "   ['-', 786],\n",
       "   ['cell', 787],\n",
       "   ['signalling', 792],\n",
       "   ['by', 803],\n",
       "   ['dasatinib', 806],\n",
       "   ['is', 816],\n",
       "   ['responsible', 819],\n",
       "   ['for', 831],\n",
       "   ['the', 835],\n",
       "   ['suppression', 839],\n",
       "   ['of', 851],\n",
       "   ['T', 854],\n",
       "   ['-', 855],\n",
       "   ['cell', 856],\n",
       "   ['function', 861],\n",
       "   ['.', 869],\n",
       "   ['These', 871],\n",
       "   ['findings', 877],\n",
       "   ['raise', 886],\n",
       "   ['the', 892],\n",
       "   ['concern', 896],\n",
       "   ['about', 904],\n",
       "   ['potential', 910],\n",
       "   ['T', 920],\n",
       "   ['-', 921],\n",
       "   ['cell', 922],\n",
       "   ['inhibition', 927],\n",
       "   ['in', 938],\n",
       "   ['patients', 941],\n",
       "   ['taking', 950],\n",
       "   ['dasatinib', 957],\n",
       "   [',', 966],\n",
       "   ['and', 968],\n",
       "   ['suggest', 972],\n",
       "   ['a', 980],\n",
       "   ['possible', 982],\n",
       "   ['application', 991],\n",
       "   ['for', 1003],\n",
       "   ['the', 1007],\n",
       "   ['treatment', 1011],\n",
       "   ['of', 1021],\n",
       "   ['T', 1024],\n",
       "   ['-', 1025],\n",
       "   ['cell', 1026],\n",
       "   ['mediated', 1031],\n",
       "   ['immune', 1040],\n",
       "   ['disorders', 1047],\n",
       "   ['.', 1056]]},\n",
       " {'context': 'Mutations in solute carrier family 9 isoform 6 on chromosome Xq26.3 encoding sodium-hydrogen exchanger 6, a protein mainly expressed in early and recycling endosomes are known to cause a complex and slowly progressive degenerative human neurological disease. Three resulting phenotypes have so far been reported: an X-linked Angelman syndrome-like condition, Christianson syndrome and corticobasal degeneration with tau deposition, with each characterized by severe intellectual disability, epilepsy, autistic behaviour and ataxia. Hypothesizing that a sodium-hydrogen exchanger 6 deficiency would most likely disrupt the endosomal-lysosomal system of neurons, we examined Slc9a6 knockout mice with tissue staining and related techniques commonly used to study lysosomal storage disorders. As a result, we found that sodium-hydrogen exchanger 6 depletion leads to abnormal accumulation of GM2 ganglioside and unesterified cholesterol within late endosomes and lysosomes of neurons in selective brain regions, most notably the basolateral nuclei of the amygdala, the CA3 and CA4 regions and dentate gyrus of the hippocampus and some areas of cerebral cortex. In these select neuronal populations, histochemical staining for β-hexosaminidase activity, a lysosomal enzyme involved in the degradation of GM2 ganglioside, was undetectable. Neuroaxonal dystrophy similar to that observed in lysosomal disease was observed in the cerebellum and was accompanied by a marked and progressive loss of Purkinje cells, particularly in those lacking the expression of Zebrin II. On behavioural testing, Slc9a6 knockout mice displayed a discrete clinical phenotype attributable to motor hyperactivity and cerebellar dysfunction. Importantly, these findings show that sodium-hydrogen exchanger 6 loss of function in the Slc9a6-targeted mouse model leads to compromise of endosomal-lysosomal function similar to lysosomal disease and to conspicuous neuronal abnormalities in specific brain regions, which in concert could provide a unified explanation for the cellular and clinical phenotypes in humans with SLC9A6 mutations.',\n",
       "  'qas': [{'question': 'Mutation of which gene is implicated in the Christianson syndrome?',\n",
       "    'answers': ['SLC9A6'],\n",
       "    'qid': '3b4719a2c58345f4acb8bac904ff6d5c',\n",
       "    'question_tokens': [['Mutation', 0],\n",
       "     ['of', 9],\n",
       "     ['which', 12],\n",
       "     ['gene', 18],\n",
       "     ['is', 23],\n",
       "     ['implicated', 26],\n",
       "     ['in', 37],\n",
       "     ['the', 40],\n",
       "     ['Christianson', 44],\n",
       "     ['syndrome', 57],\n",
       "     ['?', 65]],\n",
       "    'detected_answers': [{'text': 'SLC9A6',\n",
       "      'token_spans': [[329, 329], [255, 255], [107, 107]],\n",
       "      'char_spans': [[2091, 2096], [1589, 1594], [673, 678]]}]}],\n",
       "  'context_tokens': [['Mutations', 0],\n",
       "   ['in', 10],\n",
       "   ['solute', 13],\n",
       "   ['carrier', 20],\n",
       "   ['family', 28],\n",
       "   ['9', 35],\n",
       "   ['isoform', 37],\n",
       "   ['6', 45],\n",
       "   ['on', 47],\n",
       "   ['chromosome', 50],\n",
       "   ['Xq26.3', 61],\n",
       "   ['encoding', 68],\n",
       "   ['sodium', 77],\n",
       "   ['-', 83],\n",
       "   ['hydrogen', 84],\n",
       "   ['exchanger', 93],\n",
       "   ['6', 103],\n",
       "   [',', 104],\n",
       "   ['a', 106],\n",
       "   ['protein', 108],\n",
       "   ['mainly', 116],\n",
       "   ['expressed', 123],\n",
       "   ['in', 133],\n",
       "   ['early', 136],\n",
       "   ['and', 142],\n",
       "   ['recycling', 146],\n",
       "   ['endosomes', 156],\n",
       "   ['are', 166],\n",
       "   ['known', 170],\n",
       "   ['to', 176],\n",
       "   ['cause', 179],\n",
       "   ['a', 185],\n",
       "   ['complex', 187],\n",
       "   ['and', 195],\n",
       "   ['slowly', 199],\n",
       "   ['progressive', 206],\n",
       "   ['degenerative', 218],\n",
       "   ['human', 231],\n",
       "   ['neurological', 237],\n",
       "   ['disease', 250],\n",
       "   ['.', 257],\n",
       "   ['Three', 259],\n",
       "   ['resulting', 265],\n",
       "   ['phenotypes', 275],\n",
       "   ['have', 286],\n",
       "   ['so', 291],\n",
       "   ['far', 294],\n",
       "   ['been', 298],\n",
       "   ['reported', 303],\n",
       "   [':', 311],\n",
       "   ['an', 313],\n",
       "   ['X', 316],\n",
       "   ['-', 317],\n",
       "   ['linked', 318],\n",
       "   ['Angelman', 325],\n",
       "   ['syndrome', 334],\n",
       "   ['-', 342],\n",
       "   ['like', 343],\n",
       "   ['condition', 348],\n",
       "   [',', 357],\n",
       "   ['Christianson', 359],\n",
       "   ['syndrome', 372],\n",
       "   ['and', 381],\n",
       "   ['corticobasal', 385],\n",
       "   ['degeneration', 398],\n",
       "   ['with', 411],\n",
       "   ['tau', 416],\n",
       "   ['deposition', 420],\n",
       "   [',', 430],\n",
       "   ['with', 432],\n",
       "   ['each', 437],\n",
       "   ['characterized', 442],\n",
       "   ['by', 456],\n",
       "   ['severe', 459],\n",
       "   ['intellectual', 466],\n",
       "   ['disability', 479],\n",
       "   [',', 489],\n",
       "   ['epilepsy', 491],\n",
       "   [',', 499],\n",
       "   ['autistic', 501],\n",
       "   ['behaviour', 510],\n",
       "   ['and', 520],\n",
       "   ['ataxia', 524],\n",
       "   ['.', 530],\n",
       "   ['Hypothesizing', 532],\n",
       "   ['that', 546],\n",
       "   ['a', 551],\n",
       "   ['sodium', 553],\n",
       "   ['-', 559],\n",
       "   ['hydrogen', 560],\n",
       "   ['exchanger', 569],\n",
       "   ['6', 579],\n",
       "   ['deficiency', 581],\n",
       "   ['would', 592],\n",
       "   ['most', 598],\n",
       "   ['likely', 603],\n",
       "   ['disrupt', 610],\n",
       "   ['the', 618],\n",
       "   ['endosomal', 622],\n",
       "   ['-', 631],\n",
       "   ['lysosomal', 632],\n",
       "   ['system', 642],\n",
       "   ['of', 649],\n",
       "   ['neurons', 652],\n",
       "   [',', 659],\n",
       "   ['we', 661],\n",
       "   ['examined', 664],\n",
       "   ['Slc9a6', 673],\n",
       "   ['knockout', 680],\n",
       "   ['mice', 689],\n",
       "   ['with', 694],\n",
       "   ['tissue', 699],\n",
       "   ['staining', 706],\n",
       "   ['and', 715],\n",
       "   ['related', 719],\n",
       "   ['techniques', 727],\n",
       "   ['commonly', 738],\n",
       "   ['used', 747],\n",
       "   ['to', 752],\n",
       "   ['study', 755],\n",
       "   ['lysosomal', 761],\n",
       "   ['storage', 771],\n",
       "   ['disorders', 779],\n",
       "   ['.', 788],\n",
       "   ['As', 790],\n",
       "   ['a', 793],\n",
       "   ['result', 795],\n",
       "   [',', 801],\n",
       "   ['we', 803],\n",
       "   ['found', 806],\n",
       "   ['that', 812],\n",
       "   ['sodium', 817],\n",
       "   ['-', 823],\n",
       "   ['hydrogen', 824],\n",
       "   ['exchanger', 833],\n",
       "   ['6', 843],\n",
       "   ['depletion', 845],\n",
       "   ['leads', 855],\n",
       "   ['to', 861],\n",
       "   ['abnormal', 864],\n",
       "   ['accumulation', 873],\n",
       "   ['of', 886],\n",
       "   ['GM2', 889],\n",
       "   ['ganglioside', 893],\n",
       "   ['and', 905],\n",
       "   ['unesterified', 909],\n",
       "   ['cholesterol', 922],\n",
       "   ['within', 934],\n",
       "   ['late', 941],\n",
       "   ['endosomes', 946],\n",
       "   ['and', 956],\n",
       "   ['lysosomes', 960],\n",
       "   ['of', 970],\n",
       "   ['neurons', 973],\n",
       "   ['in', 981],\n",
       "   ['selective', 984],\n",
       "   ['brain', 994],\n",
       "   ['regions', 1000],\n",
       "   [',', 1007],\n",
       "   ['most', 1009],\n",
       "   ['notably', 1014],\n",
       "   ['the', 1022],\n",
       "   ['basolateral', 1026],\n",
       "   ['nuclei', 1038],\n",
       "   ['of', 1045],\n",
       "   ['the', 1048],\n",
       "   ['amygdala', 1052],\n",
       "   [',', 1060],\n",
       "   ['the', 1062],\n",
       "   ['CA3', 1066],\n",
       "   ['and', 1070],\n",
       "   ['CA4', 1074],\n",
       "   ['regions', 1078],\n",
       "   ['and', 1086],\n",
       "   ['dentate', 1090],\n",
       "   ['gyrus', 1098],\n",
       "   ['of', 1104],\n",
       "   ['the', 1107],\n",
       "   ['hippocampus', 1111],\n",
       "   ['and', 1123],\n",
       "   ['some', 1127],\n",
       "   ['areas', 1132],\n",
       "   ['of', 1138],\n",
       "   ['cerebral', 1141],\n",
       "   ['cortex', 1150],\n",
       "   ['.', 1156],\n",
       "   ['In', 1158],\n",
       "   ['these', 1161],\n",
       "   ['select', 1167],\n",
       "   ['neuronal', 1174],\n",
       "   ['populations', 1183],\n",
       "   [',', 1194],\n",
       "   ['histochemical', 1196],\n",
       "   ['staining', 1210],\n",
       "   ['for', 1219],\n",
       "   ['β', 1223],\n",
       "   ['-', 1224],\n",
       "   ['hexosaminidase', 1225],\n",
       "   ['activity', 1240],\n",
       "   [',', 1248],\n",
       "   ['a', 1250],\n",
       "   ['lysosomal', 1252],\n",
       "   ['enzyme', 1262],\n",
       "   ['involved', 1269],\n",
       "   ['in', 1278],\n",
       "   ['the', 1281],\n",
       "   ['degradation', 1285],\n",
       "   ['of', 1297],\n",
       "   ['GM2', 1300],\n",
       "   ['ganglioside', 1304],\n",
       "   [',', 1315],\n",
       "   ['was', 1317],\n",
       "   ['undetectable', 1321],\n",
       "   ['.', 1333],\n",
       "   ['Neuroaxonal', 1335],\n",
       "   ['dystrophy', 1347],\n",
       "   ['similar', 1357],\n",
       "   ['to', 1365],\n",
       "   ['that', 1368],\n",
       "   ['observed', 1373],\n",
       "   ['in', 1382],\n",
       "   ['lysosomal', 1385],\n",
       "   ['disease', 1395],\n",
       "   ['was', 1403],\n",
       "   ['observed', 1407],\n",
       "   ['in', 1416],\n",
       "   ['the', 1419],\n",
       "   ['cerebellum', 1423],\n",
       "   ['and', 1434],\n",
       "   ['was', 1438],\n",
       "   ['accompanied', 1442],\n",
       "   ['by', 1454],\n",
       "   ['a', 1457],\n",
       "   ['marked', 1459],\n",
       "   ['and', 1466],\n",
       "   ['progressive', 1470],\n",
       "   ['loss', 1482],\n",
       "   ['of', 1487],\n",
       "   ['Purkinje', 1490],\n",
       "   ['cells', 1499],\n",
       "   [',', 1504],\n",
       "   ['particularly', 1506],\n",
       "   ['in', 1519],\n",
       "   ['those', 1522],\n",
       "   ['lacking', 1528],\n",
       "   ['the', 1536],\n",
       "   ['expression', 1540],\n",
       "   ['of', 1551],\n",
       "   ['Zebrin', 1554],\n",
       "   ['II', 1561],\n",
       "   ['.', 1563],\n",
       "   ['On', 1565],\n",
       "   ['behavioural', 1568],\n",
       "   ['testing', 1580],\n",
       "   [',', 1587],\n",
       "   ['Slc9a6', 1589],\n",
       "   ['knockout', 1596],\n",
       "   ['mice', 1605],\n",
       "   ['displayed', 1610],\n",
       "   ['a', 1620],\n",
       "   ['discrete', 1622],\n",
       "   ['clinical', 1631],\n",
       "   ['phenotype', 1640],\n",
       "   ['attributable', 1650],\n",
       "   ['to', 1663],\n",
       "   ['motor', 1666],\n",
       "   ['hyperactivity', 1672],\n",
       "   ['and', 1686],\n",
       "   ['cerebellar', 1690],\n",
       "   ['dysfunction', 1701],\n",
       "   ['.', 1712],\n",
       "   ['Importantly', 1714],\n",
       "   [',', 1725],\n",
       "   ['these', 1727],\n",
       "   ['findings', 1733],\n",
       "   ['show', 1742],\n",
       "   ['that', 1747],\n",
       "   ['sodium', 1752],\n",
       "   ['-', 1758],\n",
       "   ['hydrogen', 1759],\n",
       "   ['exchanger', 1768],\n",
       "   ['6', 1778],\n",
       "   ['loss', 1780],\n",
       "   ['of', 1785],\n",
       "   ['function', 1788],\n",
       "   ['in', 1797],\n",
       "   ['the', 1800],\n",
       "   ['Slc9a6-targeted', 1804],\n",
       "   ['mouse', 1820],\n",
       "   ['model', 1826],\n",
       "   ['leads', 1832],\n",
       "   ['to', 1838],\n",
       "   ['compromise', 1841],\n",
       "   ['of', 1852],\n",
       "   ['endosomal', 1855],\n",
       "   ['-', 1864],\n",
       "   ['lysosomal', 1865],\n",
       "   ['function', 1875],\n",
       "   ['similar', 1884],\n",
       "   ['to', 1892],\n",
       "   ['lysosomal', 1895],\n",
       "   ['disease', 1905],\n",
       "   ['and', 1913],\n",
       "   ['to', 1917],\n",
       "   ['conspicuous', 1920],\n",
       "   ['neuronal', 1932],\n",
       "   ['abnormalities', 1941],\n",
       "   ['in', 1955],\n",
       "   ['specific', 1958],\n",
       "   ['brain', 1967],\n",
       "   ['regions', 1973],\n",
       "   [',', 1980],\n",
       "   ['which', 1982],\n",
       "   ['in', 1988],\n",
       "   ['concert', 1991],\n",
       "   ['could', 1999],\n",
       "   ['provide', 2005],\n",
       "   ['a', 2013],\n",
       "   ['unified', 2015],\n",
       "   ['explanation', 2023],\n",
       "   ['for', 2035],\n",
       "   ['the', 2039],\n",
       "   ['cellular', 2043],\n",
       "   ['and', 2052],\n",
       "   ['clinical', 2056],\n",
       "   ['phenotypes', 2065],\n",
       "   ['in', 2076],\n",
       "   ['humans', 2079],\n",
       "   ['with', 2086],\n",
       "   ['SLC9A6', 2091],\n",
       "   ['mutations', 2098],\n",
       "   ['.', 2107]]}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioasq_dev = bioasq_full[round(0.7*len(bioasq_full)): ]\n",
    "bioasq_dev.insert(0, {'header': {'dataset': 'BioASQ', 'split': 'dev'}})\n",
    "print(len(bioasq_dev))\n",
    "bioasq_dev[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friend', 2223]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_context_length = 5000\n",
    "passage_tokens_idxs[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'OPRAH.com', ')', '--', 'He', 'can', 'saw', 'himself', 'in', 'half', ',', 'sing', 'a', 'selection', 'of', 'Broadway', 'showtunes', 'and', 'swing', 'on', 'a', 'flying', 'trapeze', '.', 'Neil', 'Patrick', 'Harris', 'says', 'he', \"'ll\", 'try', 'to', 'make', 'viewers', 'feel', 'like', 'they', \"'re\", 'in', 'good', 'hands', 'with', 'him', 'as', 'Emmy', 'host', '.', 'When', 'Neil', 'Patrick', 'Harris', ',', 'one', 'of', 'the', 'stars', 'of', 'the', 'hit', 'CBS', 'sitcom', '\"', 'How', 'I', 'Met', 'Your', 'Mother', ',', '\"', 'is', \"n't\", 'dabbling', 'in', 'the', 'extraordinary', ',', 'well', ',', 'he', \"'s\", 'probably', 'hosting', 'an', 'awards', 'show', '.', 'In', 'the', 'late', \"'\", '80s', ',', 'Neil', '--', 'known', 'as', 'NPH', 'to', 'his', 'fans', '--', 'landed', 'the', 'starring', 'role', 'on', '\"', 'Doogie', 'Howser', ',', 'M.D.', '\"', 'After', 'years', 'of', 'child', 'stardom', 'and', 'teen', 'heartthrob', 'status', ',', 'Neil', 'left', 'the', 'small', 'screen', 'for', 'the', 'stage', '.', 'He', 'became', 'a', 'respected', 'Broadway', 'actor', ',', 'starring', 'in', 'shows', 'like', '\"', 'Rent', ',', '\"', '\"', 'Cabaret', '\"', 'and', '\"', 'Proof', ',', '\"', 'before', 'returning', 'to', 'television', '.', 'Now', ',', 'millions', 'know', 'Neil', 'as', 'Barney', 'Stinson', ',', 'the', 'womanizing', ',', 'slap', '-', 'happy', 'sidekick', 'on', '\"', 'How', 'I', 'Met', 'Your', 'Mother', ',', '\"', 'which', 'begins', 'its', 'fifth', 'season', 'September', '21', '.', 'Like', 'Billy', 'Crystal', 'and', 'Johnny', 'Carson', 'before', 'him', ',', 'this', 'man', '-', 'of', '-', 'many', '-', 'talents', 'is', 'also', 'making', 'his', 'mark', 'as', 'an', 'awards', 'show', 'host', '.', 'On', 'Sunday', ',', 'September', '20', ',', 'Neil', 'will', 'host', 'the', '61st', 'Primetime', 'Emmy', 'Awards', '.', 'He', 'shares', 'his', 'thoughts', 'on', 'fate', ',', 'finding', 'balance', 'and', 'making', 'out', 'with', 'his', 'co', '-', 'star', '.', 'Kari', 'Forsee', ':', 'How', 'are', 'you', 'preparing', 'for', 'Emmy', 'night', '?', 'Neil', 'Patrick', 'Harris', ':', 'I', \"'m\", 'just', 'trying', 'to', 'make', 'sure', 'all', 'the', 'comedy', 'host', 'elements', 'are', 'in', 'place', '.', 'We', \"'ll\", 'have', 'a', 'good', 'opening', 'bit', 'and', 'a', 'couple', 'surprise', 'things', 'throughout', '.', 'We', 'want', 'to', 'balance', 'respecting', 'the', 'show', 'and', 'the', 'doling', 'out', 'of', 'the', 'awards', 'with', 'the', 'sort', 'of', 'random', 'things', 'that', 'will', 'keep', 'the', 'audience', \"'s\", 'attention', 'in', 'other', 'ways', '.', 'So', 'that', \"'s\", 'kind', 'of', 'been', 'my', 'job', '.', 'You', 'want', 'to', 'make', 'it', 'unique', 'and', ',', 'yet', ',', 'classic', '.', 'That', \"'s\", 'a', 'tricky', 'dynamic', '.', 'Oprah.com', ':', 'Planning', 'an', 'Emmys', 'party', '?', 'Get', '4', 'entertaining', 'solutions', 'KF', ':', 'I', 'can', 'imagine', '.', 'How', 'often', 'are', 'you', 'rehearsing', '?', 'NPH', ':', 'Well', ',', 'it', \"'s\", 'sort', 'of', 'a', 'litany', 'of', 'e', '-', 'mails', 'and', 'phone', 'calls', 'all', 'day', 'with', 'the', 'producers', '.', 'We', 'had', 'a', 'great', 'opening', 'short', 'film', 'we', 'are', 'going', 'to', 'shoot', ',', 'and', 'it', 'would', 'be', 'the', 'first', 'thing', 'you', 'shot', '.', 'That', 'was', 'going', 'to', 'be', 'with', 'Alec', 'Baldwin', ',', 'and', 'he', 'withdrew', 'at', 'the', 'last', 'minute', '.', 'So', 'that', 'got', 'scrapped', ',', 'and', 'we', \"'re\", 'off', 'to', 'plan', 'D', ',', 'E', 'or', 'F.', 'It', \"'s\", 'sort', 'of', 'like', 'now', 'you', 'go', ':', '\"', 'That', \"'s\", 'fantastic', ',', 'great', '.', 'We', \"'ve\", 'got', 'that', 'person', ',', '\"', 'or', '\"', 'Oh', ',', 'that', 'person', 'did', \"n't\", 'work', '.', 'Now', 'what', 'do', 'we', 'do', '?', '\"', 'A', 'lot', 'of', '\"', 'now', 'what', 'do', 'we', 'do', '?', '\"', 'questions', '.', 'KF', ':', 'Now', 'at', 'the', 'Tony', 'Awards', ',', 'you', 'sang', 'a', ',', 'may', 'I', 'say', ',', 'legendary', 'closing', 'number', '.', 'Will', 'you', 'be', 'singing', 'at', 'the', 'Emmys', ',', 'or', 'is', 'dancing', 'more', 'the', 'focus', '?', 'NPH', ':', 'I', 'suspect', 'you', 'wo', \"n't\", 'see', 'me', 'dancing', 'very', 'much', '.', 'That', \"'s\", 'not', 'my', 'forte', '.', 'But', 'yeah', ',', 'I', 'might', 'throw', 'some', 'sort', 'of', 'singing', 'into', 'it', '.', 'I', 'have', \"n't\", 'quite', 'decided', '.', 'I', 'sort', 'of', 'feel', 'like', 'the', 'Emmys', 'are', 'so', 'classy', 'and', 'glamorous', 'and', 'black', 'tie', ',', 'the', 'host', 'really', 'needs', 'to', 'respect', 'his', 'job', 'title', '.', 'I', 'think', 'too', 'much', '\"', 'Look', 'at', 'me', '!', 'Look', 'at', 'me', '!', '\"', 'as', 'the', 'host', 'of', 'a', 'show', 'that', 'big', 'is', 'counterproductive', '.', 'So', 'long', 'as', 'I', 'make', 'you', 'feel', 'confident', 'that', 'you', \"'re\", 'in', 'good', 'hands', 'with', 'me', 'as', 'the', 'host', ',', 'then', 'it', \"'s\", 'my', 'real', 'responsibility', 'to', 'introduce', 'you', 'to', 'a', 'lot', 'of', 'other', 'people', 'and', 'elements', '--', 'other', 'presenters', 'who', 'are', 'then', 'going', 'to', 'talk', 'to', 'you', 'or', 'other', 'introductions', 'of', 'next', 'sections', '.', 'That', \"'s\", 'my', 'role', '.', 'It', \"'s\", 'not', 'really', 'to', 'be', 'a', 'song', '-', 'and', '-', 'dance', 'man', '.', 'KF', ':', 'Did', 'you', 'look', 'back', 'at', 'past', 'Emmy', 'hosts', 'for', 'inspiration', '?', 'NPH', ':', 'Very', 'much', '.', 'Steve', 'Allen', 'hosted', 'the', 'first', 'televised', 'awards', ',', 'which', 'was', 'the', '7th', 'Annual', 'Emmy', 'Awards', ',', 'in', ',', 'I', 'think', ',', '1955', ',', 'and', 'he', 'was', 'great', '.', 'That', 'was', 'sort', 'of', 'my', 'inspiration', 'for', 'all', 'of', 'this', '.', 'He', 'just', 'had', 'such', 'a', 'dry', 'wit', ',', 'a', 'commanding', 'voice', ',', 'a', 'great', 'presence', '.', 'You', 'knew', 'when', 'you', 'were']\n",
      "{'id': './cnn/stories/8b66f5754a70c62dbacda0e7ab9d1a369b0b6f2e.story#0', 'question': 'What character does he play on \"How I Met Your Mother\"?', 'answers': ['Barney Stinson,'], 'qid': 'fd58ed81f9ea41e2b803c29dc3d424d0', 'question_tokens': [['What', 0], ['character', 5], ['does', 15], ['he', 20], ['play', 23], ['on', 28], ['\"', 31], ['How', 32], ['I', 36], ['Met', 38], ['Your', 42], ['Mother', 47], ['\"', 53], ['?', 54]], 'detected_answers': [{'text': 'Barney Stinson,', 'char_spans': [[756, 770]], 'token_spans': [[165, 167]]}]}\n",
      "['Barney', 'Stinson', ',']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for elem_i in np.random.permutation(np.arange(0, len(elems))[1:] ):\n",
    "    elem = elems[elem_i]\n",
    "    context = elem['context']\n",
    "#     print(context)\n",
    "    passage = [x[0] for x in elem['context_tokens']]\n",
    "    print(passage)\n",
    "    for qa in elem['qas']:\n",
    "        print(qa)\n",
    "        print(passage[qa['detected_answers'][0]['token_spans'][0][0]: 1 + qa['detected_answers'][0]['token_spans'][0][1]])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Reuters', 0], ['is', 8], ['a', 11], ['global', 13], ['information', 20], ['company', 32], ['providing', 40], ['material', 50], ['tailored', 59], ['for', 68]]\n",
      "<START>Reuters is a global information company providing material tailored for<END>\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "max_context_length = 10\n",
    "passage_tokens_idxs: List[Tuple[str, int]] = elem['context_tokens']\n",
    "passage_tokens: List[str] = [\n",
    "    token.lower()\n",
    "    for (token, offset) in passage_tokens_idxs\n",
    "][:max_context_length]\n",
    "print(passage_tokens_idxs[:max_context_length])\n",
    "passage: str = elem['context']\n",
    "final_passage_token_idx: int = min(max_context_length, len(passage_tokens_idxs)) - 1\n",
    "final_passage_token__start_idx: int = passage_tokens_idxs[final_passage_token_idx][1]\n",
    "final_passage_token_len = len(passage_tokens_idxs[final_passage_token_idx][0])\n",
    "final_passage_idx = final_passage_token__start_idx + final_passage_token_len\n",
    "passage: str = passage[:final_passage_idx]\n",
    "print(f\"<START>{passage}<END>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'--': 2, 'his': 2, 'the': 2, 'to': 2, '(CNN)': 1, 'A': 1, 'phone': 1, 'hacking': 1, 'scandal': 1, 'may': 1, 'have': 1, 'cost': 1, 'Rupert': 1, 'Murdoch': 1, 'biggest-selling': 1, 'newspaper': 1, 'in': 1, '2011': 1, ',': 1, 'but': 1, 'billionaire': 1, 'media': 1, 'mogul': 1, 'managed': 1, 'end': 1, 'year': 1, 'with': 1, 'a': 1, 'modest': 1, 'addition': 1, 'empire': 1, 'an': 1, 'account': 1, 'on': 1, 'Twitter': 1, '.': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ngrams(tokens: Union[str, List[str]], n_gram: int) -> Counter:\n",
    "    assert isinstance(n_gram, int) and n_gram >= 1\n",
    "    ngrams_counts = Counter()\n",
    "    if n_gram == 1:\n",
    "        for token in tokens:\n",
    "            ngrams_counts[token] += 1\n",
    "        return ngrams_counts\n",
    "\n",
    "    for i in range(len(tokens) - n_gram + 1):\n",
    "        n_gram_slice = tuple(tokens[i: i + n_gram])\n",
    "        ngrams_counts[n_gram_slice] += 1\n",
    "    return ngrams_counts\n",
    "print(get_ngrams(passage_tokens, 2))\n",
    "len(get_ngrams(passage_tokens, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Which', 0], ['President', 6], [\"'s\", 15], ['death', 18], ['was', 24]]\n",
      "<START>Which President's death was<END>\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    "max_question_length = 5\n",
    "question_tokens_idxs: List[Tuple[str, int]] = qa['question_tokens']\n",
    "question_tokens: List[str] = [\n",
    "    token.lower()\n",
    "    for (token, offset) in question_tokens_idxs\n",
    "][:max_question_length]\n",
    "print(question_tokens_idxs[:max_question_length])\n",
    "question: str = qa['question']\n",
    "final_question_token_idx: int = min(max_question_length, len(question_tokens_idxs)) - 1\n",
    "final_question_token_start_idx: int = question_tokens_idxs[final_question_token_idx][1]\n",
    "final_question_token_len = len(question_tokens_idxs[final_question_token_idx][0])\n",
    "final_question_idx = final_question_token_start_idx + final_question_token_len\n",
    "question: str = question[:final_question_idx]\n",
    "print(f\"<START>{question}<END>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'google/pegasus-large'\n",
    "# model_name = 'google/pegasus-xsum'\n",
    "# model_name = 'tuner007/pegasus_paraphrase'\n",
    "model_name = 'google/pegasus-cnn_dailymail'\n",
    "# model_name = 'google/pegasus-multi_news'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "if 'model' in globals():\n",
    "    del model\n",
    "    import gc; gc.collect()\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text, num_return_sequences, num_beams, max_length):\n",
    "    if isinstance(input_text, str):\n",
    "        input_text = [input_text]\n",
    "    batch = tokenizer(input_text, truncation=True,padding='longest', max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "    paraphrased_token_ids = model.generate(**batch,max_length=max_length, num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "#     print(paraphrased_token_ids)\n",
    "    paraphrases = tokenizer.batch_decode(paraphrased_token_ids, skip_special_tokens=True)\n",
    "    paraphrased_tokens: List[str] = [\n",
    "        [## The character ▁ (NOT an underscore) is used by sentencepiece to represent a space.\n",
    "        ## Ref: https://huggingface.co/transformers/tokenizer_summary.html#sentencepiece\n",
    "            token#.replace('▁', '')\n",
    "            for token in tokenizer.convert_ids_to_tokens(paraphrased_token_ids_list, skip_special_tokens=True)\n",
    "        ]\n",
    "#         tokenizer.decode(paraphrased_token_ids_list, skip_special_tokens=True, clean_up_tokenization_spaces=False, spaces_between_special_tokens=True).split(' ')\n",
    "        for paraphrased_token_ids_list in paraphrased_token_ids\n",
    "    ]\n",
    "    del batch, paraphrased_token_ids\n",
    "    print('Paraphrased tokens:')\n",
    "    for paraphrased_token_list in paraphrased_tokens:\n",
    "        print(paraphrased_token_list)\n",
    "    return paraphrases, paraphrased_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer.decode(\n",
    "#     ['▁Around', '▁midnight', '▁at', '▁London', \"'\", 's', '▁Leicester', '▁Square', ',', '▁as', '▁news', '▁of', '▁Jackson', \"'\", 's', '▁death', '▁spread', ',', '▁Luis', '▁Carlos', '▁A', 'me', 'ida', '▁and', '▁his', '▁friends', '▁were', '▁surrounding']\n",
    "# )\n",
    "# tokenizer.decode(\n",
    "#     [0, 14915, 13635, 16923,  4195,     1],\n",
    "#     skip_special_tokens=False,\n",
    "#     clean_up_tokenization_spaces=False,\n",
    "#     spaces_between_special_tokens=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrased tokens:\n",
      "['▁Peter', '▁Mai', 'y', 'oh', '▁is', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', '▁', '.', '<n>', 'He', '▁says', '▁Jackson', '▁\"', 'was', '▁there', '▁before', '▁Tiger', '▁Woods', ',', '▁before', '▁Michael', '▁Jordan', ',', '▁even', '▁before', '▁Barack', '▁Obama', '\"', '<n>', 'Mai', 'y', 'oh', ':', '▁\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', '\"']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', '▁is', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', '▁', '.', '<n>', 'He', '▁says', '▁Jackson', '▁\"', 'was', '▁there', '▁before', '▁Tiger', '▁Woods', ',', '▁before', '▁Michael', '▁Jordan', ',', '▁even', '▁before', '▁Barack', '▁Obama', '\"', '<n>', 'Mai', 'y', 'oh', ':', '▁I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', '.']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', ',', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', ',', '▁calls', '▁Jackson', '▁\"', 'the', '▁voice', '▁of', '▁change', '\"', '<n>', 'Mai', 'y', 'oh', ':', '▁\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', '\"']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', ',', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', ',', '▁calls', '▁Jackson', '▁\"', 'the', '▁voice', '▁of', '▁change', '\"', '<n>', '\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', ',\"', '▁says', '▁Mai', 'y', 'oh', '▁', '.']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', '▁is', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', '▁', '.', '<n>', 'He', '▁says', '▁Jackson', '▁\"', 'was', '▁there', '▁before', '▁Tiger', '▁Woods', ',', '▁before', '▁Michael', '▁Jordan', ',', '▁even', '▁before', '▁Barack', '▁Obama', '\"', '<n>', 'Mai', 'y', 'oh', ':', '▁I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', '▁', '.']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', ',', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', ',', '▁calls', '▁Jackson', '▁\"', 'the', '▁voice', '▁of', '▁change', '\"', '<n>', '\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', ',\"', '▁Mai', 'y', 'oh', '▁says', '▁', '.']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', '▁is', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', '▁', '.', '<n>', 'He', '▁says', '▁Jackson', '▁\"', 'was', '▁there', '▁before', '▁Tiger', '▁Woods', ',', '▁before', '▁Michael', '▁Jordan', ',', '▁even', '▁before', '▁Barack', '▁Obama', '\"', '<n>', 'Mai', 'y', 'oh', ':', '▁\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', '.\"']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', ',', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁calls', '▁Jackson', '▁\"', 'the', '▁voice', '▁of', '▁change', '\"', '<n>', '\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', ',\"', '▁says', '▁Mai', 'y', 'oh', '▁', '.']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', '▁is', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', '▁', '.', '<n>', '\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', ',\"', '▁he', '▁says', '▁', '.']\n",
      "['▁Peter', '▁Mai', 'y', 'oh', ',', '▁a', '▁Kenyan', '▁student', '▁studying', '▁in', '▁the', '▁U', '.', 'S', '.', '▁city', '▁of', '▁Kansas', ',', '▁Missouri', ',', '▁calls', '▁Jackson', '▁\"', 'the', '▁voice', '▁of', '▁change', '\"', '<n>', '\"', 'I', '▁hope', '▁people', '▁remember', '▁him', '▁for', '▁the', '▁work', '▁he', '▁did', ',\"', '▁says', '▁Mai', 'y', 'oh', '.']\n"
     ]
    }
   ],
   "source": [
    "paraphrase = get_response(\n",
    "#     \"\"\"In Adelaide, Australia, Christos Winter of the MJ Fan Club had organized a petition to bring Jackson to tour there. \"It didn't matter if you were 60, 40 or 20 like I am. Michael Jackson's music just spoke to everyone ... It was always uplifting and happy music,\" Winter told CNN.\"\"\",\n",
    "#     \"\"\"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning, initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\"\"\",\n",
    "    \"\"\"Another iReporter, Peter Maiyoh, a Kenyan student studying in the U.S. city of Kansas, Missouri, called Jackson \"the voice of change,\" saying \"he was there before Tiger Woods, before Michael Jordan, even before Barack Obama ... I hope people remember him for the work he did.\"\"\",\n",
    "#     \"\"\"Around midnight at London's Leicester Square, as news of Jackson's death spread, Luis Carlos Ameida and his friends were surrounding a car listening to the star's music. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\"\"\", \n",
    "    10, 10, 120\n",
    ")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peter Maiyoh is a Kenyan student studying in the U.S. city of Kansas, Missouri.<n>He says Jackson \"was there before Tiger Woods, before Michael Jordan, even before Barack Obama\"<n>Maiyoh: \"I hope people remember him for the work he did\"'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[741,\n",
       " 40155,\n",
       " 158,\n",
       " 105,\n",
       " 55229,\n",
       " 57810,\n",
       " 11388,\n",
       " 4378,\n",
       " 44041,\n",
       " 20388,\n",
       " 2130,\n",
       " 544,\n",
       " 65636,\n",
       " 108,\n",
       " 34045,\n",
       " 108,\n",
       " 4581,\n",
       " 1313,\n",
       " 304,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 4468,\n",
       " 304,\n",
       " 26419,\n",
       " 1313,\n",
       " 2449,\n",
       " 18107,\n",
       " 14866,\n",
       " 6479,\n",
       " 108,\n",
       " 12152,\n",
       " 22023,\n",
       " 11339,\n",
       " 105,\n",
       " 41732,\n",
       " 20388,\n",
       " 107,\n",
       " 39892,\n",
       " 661,\n",
       " 20388,\n",
       " 30086,\n",
       " 36313,\n",
       " 105,\n",
       " 3030,\n",
       " 10072,\n",
       " 105,\n",
       " 1313,\n",
       " 105,\n",
       " 74283,\n",
       " 8109,\n",
       " 105,\n",
       " 544,\n",
       " 44041,\n",
       " 1313,\n",
       " 23958,\n",
       " 2130,\n",
       " 13062,\n",
       " 4581,\n",
       " 14866,\n",
       " 6479,\n",
       " 108,\n",
       " 60108,\n",
       " 41732,\n",
       " 107,\n",
       " 105,\n",
       " 108,\n",
       " 4442,\n",
       " 108,\n",
       " 8161,\n",
       " 10140,\n",
       " 30086,\n",
       " 3030,\n",
       " 105,\n",
       " 108,\n",
       " 105,\n",
       " 92425,\n",
       " 526,\n",
       " 105,\n",
       " 108,\n",
       " 60108,\n",
       " 41732,\n",
       " 107,\n",
       " 5277,\n",
       " 105,\n",
       " 1659,\n",
       " 57824,\n",
       " 1897,\n",
       " 20604,\n",
       " 37787,\n",
       " 107,\n",
       " 12152,\n",
       " 105,\n",
       " 105,\n",
       " 661,\n",
       " 13280,\n",
       " 108,\n",
       " 8996,\n",
       " 19748,\n",
       " 8109,\n",
       " 105,\n",
       " 544,\n",
       " 105,\n",
       " 44041,\n",
       " 1313,\n",
       " 10072,\n",
       " 105,\n",
       " 33374,\n",
       " 13062,\n",
       " 4581,\n",
       " 526,\n",
       " 23612,\n",
       " 19973,\n",
       " 105,\n",
       " 10234,\n",
       " 30665,\n",
       " 544,\n",
       " 2907,\n",
       " 107,\n",
       " 12800,\n",
       " 20388,\n",
       " 108,\n",
       " 304,\n",
       " 9534,\n",
       " 18301,\n",
       " 497,\n",
       " 544,\n",
       " 105,\n",
       " 13586,\n",
       " 105,\n",
       " 40155,\n",
       " 3713,\n",
       " 304,\n",
       " 105,\n",
       " 10234,\n",
       " 13586,\n",
       " 34762,\n",
       " 22258,\n",
       " 386,\n",
       " 544,\n",
       " 4581,\n",
       " 107,\n",
       " 159,\n",
       " 9534,\n",
       " 108,\n",
       " 6062,\n",
       " 10140,\n",
       " 2957,\n",
       " 50211,\n",
       " 497,\n",
       " 32494,\n",
       " 661,\n",
       " 544,\n",
       " 27948,\n",
       " 108,\n",
       " 19706,\n",
       " 2957,\n",
       " 75308,\n",
       " 544,\n",
       " 46162,\n",
       " 1313,\n",
       " 544,\n",
       " 105,\n",
       " 10234,\n",
       " 22258,\n",
       " 2130,\n",
       " 105,\n",
       " 105,\n",
       " 4581,\n",
       " 107,\n",
       " 159,\n",
       " 9534,\n",
       " 19706,\n",
       " 2957,\n",
       " 13561,\n",
       " 74282,\n",
       " 7747,\n",
       " 544,\n",
       " 10234,\n",
       " 10140,\n",
       " 22258,\n",
       " 2130,\n",
       " 544,\n",
       " 56910,\n",
       " 107,\n",
       " 39892,\n",
       " 22258,\n",
       " 544,\n",
       " 8824,\n",
       " 8996,\n",
       " 44041,\n",
       " 14866,\n",
       " 6479,\n",
       " 18701,\n",
       " 56577,\n",
       " 497,\n",
       " 20058,\n",
       " 1321,\n",
       " 82540,\n",
       " 526,\n",
       " 16107,\n",
       " 105,\n",
       " 661,\n",
       " 105,\n",
       " 3316,\n",
       " 497,\n",
       " 304,\n",
       " 30179,\n",
       " 92425,\n",
       " 105,\n",
       " 108,\n",
       " 526,\n",
       " 1321,\n",
       " 25669,\n",
       " 16107,\n",
       " 105,\n",
       " 107,\n",
       " 105,\n",
       " 10140,\n",
       " 2957,\n",
       " 4581,\n",
       " 2130,\n",
       " 544,\n",
       " 1139,\n",
       " 206,\n",
       " 105,\n",
       " 22258,\n",
       " 22998,\n",
       " 8109,\n",
       " 304,\n",
       " 105,\n",
       " 105,\n",
       " 32503,\n",
       " 1313,\n",
       " 13062,\n",
       " 105,\n",
       " 107,\n",
       " 159,\n",
       " 105,\n",
       " 44041,\n",
       " 1313,\n",
       " 544,\n",
       " 8824,\n",
       " 16125,\n",
       " 23958,\n",
       " 108,\n",
       " 2884,\n",
       " 1313,\n",
       " 105,\n",
       " 26749,\n",
       " 33984,\n",
       " 121,\n",
       " 5339,\n",
       " 108,\n",
       " 24517,\n",
       " 7708,\n",
       " 34762,\n",
       " 32591,\n",
       " 7747,\n",
       " 6417,\n",
       " 26749,\n",
       " 22258,\n",
       " 1897,\n",
       " 194,\n",
       " 105,\n",
       " 108,\n",
       " 2619,\n",
       " 2957,\n",
       " 44148,\n",
       " 490,\n",
       " 20741,\n",
       " 108,\n",
       " 194,\n",
       " 105,\n",
       " 36745,\n",
       " 105,\n",
       " 20087,\n",
       " 38280,\n",
       " 19151,\n",
       " 105,\n",
       " 40155,\n",
       " 661,\n",
       " 13280,\n",
       " 107,\n",
       " 1199,\n",
       " 16125,\n",
       " 105,\n",
       " 26749,\n",
       " 105,\n",
       " 105,\n",
       " 108,\n",
       " 105,\n",
       " 107,\n",
       " 19833,\n",
       " 105,\n",
       " 1313,\n",
       " 544,\n",
       " 65636,\n",
       " 12152,\n",
       " 25835,\n",
       " 41732,\n",
       " 16717,\n",
       " 108,\n",
       " 3030,\n",
       " 10072,\n",
       " 1313,\n",
       " 544,\n",
       " 105,\n",
       " 20545,\n",
       " 497,\n",
       " 105,\n",
       " 107,\n",
       " 7341,\n",
       " 304,\n",
       " 5399,\n",
       " 13178,\n",
       " 108,\n",
       " 304,\n",
       " 19973,\n",
       " 105,\n",
       " 105,\n",
       " 1313,\n",
       " 105,\n",
       " 526,\n",
       " 105,\n",
       " 92425,\n",
       " 108,\n",
       " 105,\n",
       " 105,\n",
       " 14866,\n",
       " 6479,\n",
       " 107,\n",
       " 55229,\n",
       " 105,\n",
       " 544,\n",
       " 105,\n",
       " 3713,\n",
       " 5403,\n",
       " 2467,\n",
       " 544,\n",
       " 16107,\n",
       " 8109,\n",
       " 544,\n",
       " 194,\n",
       " 105,\n",
       " 1313,\n",
       " 544,\n",
       " 72892,\n",
       " 108,\n",
       " 194,\n",
       " 3509,\n",
       " 41732,\n",
       " 107,\n",
       " 43325,\n",
       " 24291,\n",
       " 544,\n",
       " 105,\n",
       " 19060,\n",
       " 57810,\n",
       " 544,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 1313,\n",
       " 8996,\n",
       " 44041,\n",
       " 661,\n",
       " 544,\n",
       " 14753,\n",
       " 16105,\n",
       " 1313,\n",
       " 544,\n",
       " 2907,\n",
       " 108,\n",
       " 3509,\n",
       " 21658,\n",
       " 107,\n",
       " 251,\n",
       " 105,\n",
       " 16107,\n",
       " 105,\n",
       " 5468,\n",
       " 105,\n",
       " 497,\n",
       " 3046,\n",
       " 304,\n",
       " 105,\n",
       " 105,\n",
       " 27212,\n",
       " 8492,\n",
       " 544,\n",
       " 68090,\n",
       " 386,\n",
       " 544,\n",
       " 105,\n",
       " 107,\n",
       " 1189,\n",
       " 13194,\n",
       " 108,\n",
       " 105,\n",
       " 105,\n",
       " 497,\n",
       " 544,\n",
       " 2907,\n",
       " 108,\n",
       " 105,\n",
       " 768,\n",
       " 544,\n",
       " 27212,\n",
       " 526,\n",
       " 22258,\n",
       " 304,\n",
       " 14753,\n",
       " 10234,\n",
       " 108,\n",
       " 105,\n",
       " 41732,\n",
       " 107,\n",
       " 251,\n",
       " 74189,\n",
       " 16107,\n",
       " 1313,\n",
       " 544,\n",
       " 2907,\n",
       " 526,\n",
       " 38345,\n",
       " 22258,\n",
       " 8996,\n",
       " 4378,\n",
       " 44041,\n",
       " 386,\n",
       " 304,\n",
       " 62178,\n",
       " 8544,\n",
       " 526,\n",
       " 304,\n",
       " 81008,\n",
       " 10234,\n",
       " 386,\n",
       " 304,\n",
       " 105,\n",
       " 27212,\n",
       " 30665,\n",
       " 544,\n",
       " 4581,\n",
       " 107,\n",
       " 15367,\n",
       " 27527,\n",
       " 105,\n",
       " 105,\n",
       " 26749,\n",
       " 10642,\n",
       " 661,\n",
       " 544,\n",
       " 105,\n",
       " 108,\n",
       " 526,\n",
       " 544,\n",
       " 44041,\n",
       " 26749,\n",
       " 386,\n",
       " 88395,\n",
       " 46463,\n",
       " 1313,\n",
       " 105,\n",
       " 108,\n",
       " 41732,\n",
       " 38280,\n",
       " 108,\n",
       " 2532,\n",
       " 4109,\n",
       " 1418,\n",
       " 60307,\n",
       " 497,\n",
       " 105,\n",
       " 544,\n",
       " 18817,\n",
       " 1313,\n",
       " 544,\n",
       " 105,\n",
       " 107,\n",
       " 105,\n",
       " 41732,\n",
       " 105,\n",
       " 48762,\n",
       " 13062,\n",
       " 15577,\n",
       " 1483,\n",
       " 304,\n",
       " 194,\n",
       " 105,\n",
       " 107,\n",
       " 194,\n",
       " 194,\n",
       " 1097,\n",
       " 105,\n",
       " 11009,\n",
       " 526,\n",
       " 105,\n",
       " 768,\n",
       " 50991,\n",
       " 16578,\n",
       " 526,\n",
       " 45775,\n",
       " 1418,\n",
       " 497,\n",
       " 59434,\n",
       " 105,\n",
       " 497,\n",
       " 11709,\n",
       " 304,\n",
       " 45526,\n",
       " 105,\n",
       " 108,\n",
       " 194,\n",
       " 3509,\n",
       " 41732,\n",
       " 107,\n",
       " 105,\n",
       " 10140,\n",
       " 105,\n",
       " 1313,\n",
       " 304,\n",
       " 45232,\n",
       " 105,\n",
       " 526,\n",
       " 10140,\n",
       " 105,\n",
       " 4698,\n",
       " 53971,\n",
       " 497,\n",
       " 25072,\n",
       " 108,\n",
       " 105,\n",
       " 41732,\n",
       " 107,\n",
       " 40155,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 105,\n",
       " 497,\n",
       " 4775,\n",
       " 31800,\n",
       " 107]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(passage) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "__input_text = context\n",
    "__batch = tokenizer(__input_text,truncation=True, padding='longest',max_length=len(__input_text), return_tensors=\"pt\").to(device)\n",
    "__translated = model.generate(**__batch, max_length=len(__input_text), num_beams=10, num_return_sequences=10, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(**__batch, max_length=len(__input_text), num_beams=10, num_return_sequences=10, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  6053,   151, 24643,  2058,   541,   154,  3573,   134,  6786,\n",
       "           412,  3422,   131,   116,   238,   110,   107,   106, 17321,   151,\n",
       "           412,  3422,  3131,   122,   668,  7751,   113, 30459,  5939,   108,\n",
       "          1564,   416,   110,   107,   106, 13157,   151,   624,   307,   513,\n",
       "           374,   134,   412,  3422,   131,   116,  7894,   108,  3698,   108,\n",
       "           238,   110,   107,   106, 11712, 21298,   256,   133,   174,   186,\n",
       "           118,   198,  6479,   116,   108,   175,   146,   590,   132,   231,\n",
       "           745, 53898,   649,   110,   107,     1,     0,     0],\n",
       "        [    0,  6053,   151, 24643,  2058,   541,   154,  3573,   134,  6786,\n",
       "           412,  3422,   131,   116,   238,   110,   107,   106, 17321,   151,\n",
       "           412,  3422,  3131,   122,   668,  7751,   113, 30459,  5939,   108,\n",
       "          1564,   416,   110,   107,   106, 11712, 21298,   113,  1029,   652,\n",
       "           374,   134,   412,  3422,   131,   116,  7894,   108,  3698,   108,\n",
       "           238,   289,   396,   110,   107,   106,   812,  3422,   140, 11445,\n",
       "           113,   114, 12900, 12841,   326,   111,   140, 27154,   135,  5667,\n",
       "           112,  5109,   110,   107,     1,     0,     0,     0],\n",
       "        [    0,  6053,   151,  5107,   154,  3573,   374,   134,  6786,   412,\n",
       "          3422,   131,   116,   238,  1842,   108,  1564,   416,   110,   107,\n",
       "           106, 17321,   151,   412,  3422,  3131,   122,   668,  7751,   113,\n",
       "         30459,  5939,   108,  1564,   416,   110,   107,   106, 11712, 21298,\n",
       "           113,  1029,   652,   374,   134,   412,  3422,   131,   116,  7894,\n",
       "           108,  3698,   108,   238,   289,   396,   110,   107,   106,   812,\n",
       "          3422,   140, 11445,   113,   114, 12900, 12841,   326,   111,   140,\n",
       "         27154,   135,  5667,   112,  5109,   110,   107,     1],\n",
       "        [    0,  6053,   151,  5107,   154,  3573,  2642,   134,  6786,   412,\n",
       "          3422,   131,   116,   238,  1842,   108,  1564,   416,   110,   107,\n",
       "           106, 17321,   151,   412,  3422,  3131,   122,   668,  7751,   113,\n",
       "         30459,  5939,   108,  1564,   416,   110,   107,   106, 11712, 21298,\n",
       "           113,  1029,   652,   374,   134,   412,  3422,   131,   116,  7894,\n",
       "           108,  3698,   108,   238,   289,   396,   110,   107,   106,   812,\n",
       "          3422,   140, 11445,   113,   114, 12900, 12841,   326,   111,   140,\n",
       "         27154,   135,  5667,   112,  5109,   110,   107,     1],\n",
       "        [    0,  6053,   151,  5107,   154,  3573,   374,   134,  6786,   412,\n",
       "          3422,   131,   116,   238,  1842,   108,  1564,   416,   110,   107,\n",
       "           106, 17321,   151,   412,  3422,  3131,   122,   668,  7751,   113,\n",
       "         30459,  5939,   108,  1564,   416,   110,   107,   106, 11712, 21298,\n",
       "           113,  1029,   652,   374,   134,   412,  3422,   131,   116,   238,\n",
       "           289,   396,   108,  1564,   416,   110,   107,   106,   812,  3422,\n",
       "           140, 11445,   113,   114, 12900, 12841,   326,   111,   140, 27154,\n",
       "           135,  5667,   112,  5109,   110,   107,     1,     0],\n",
       "        [    0,  6053,   151,  5107,   154,  3573,  2642,   134,  6786,   412,\n",
       "          3422,   131,   116,   238,  1842,   108,  1564,   416,   110,   107,\n",
       "           106, 17321,   151,   412,  3422,  3131,   122,   668,  7751,   113,\n",
       "         30459,  5939,   108,  1564,   416,   110,   107,   106, 11712, 21298,\n",
       "           113,  1029,   652,   374,   134,   412,  3422,   131,   116,   238,\n",
       "           289,   396,   108,  1564,   416,   110,   107,   106,   812,  3422,\n",
       "           140, 11445,   113,   114, 12900, 12841,   326,   111,   140, 27154,\n",
       "           135,  5667,   112,  5109,   110,   107,     1,     0],\n",
       "        [    0,  6053,   151,  5107,   154,  3573,   374,   134,  6786,   412,\n",
       "          3422,   131,   116,   238,  1842,   108,  1564,   416,   110,   107,\n",
       "           106, 17321,   151,   412,  3422,  3131,   122,   668,  7751,   113,\n",
       "         30459,  5939,   108,  1564,   416,   110,   107,   106, 11712, 21298,\n",
       "           113,  1029,   652,   374,   134,   412,  3422,   131,   116,  7894,\n",
       "           108,  3698,   108,   238,   289,   396,   110,   107,   106, 13157,\n",
       "           151,   624,   307,   513,   374,   134,   412,  3422,   131,   116,\n",
       "           238,  1842,   110,   107,     1,     0,     0,     0],\n",
       "        [    0,  6053,   151, 24643,  2058,   541,   154,  3573,   134,  6786,\n",
       "           412,  3422,   131,   116,   238,   110,   107,   106, 17321,   151,\n",
       "           412,  3422,  3131,   122,   668,  7751,   113, 30459,  5939,   108,\n",
       "          1564,   416,   110,   107,   106, 13157,   151,   624,   307,   513,\n",
       "           374,   134,   412,  3422,   131,   116,  7894,   108,  3698,   108,\n",
       "           238,   110,   107,   106, 11712, 21298,   113,  1029,   652,   374,\n",
       "           134,   412,  3422,   131,   116,   238,   289,   396,   110,   107,\n",
       "             1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  6053,   151, 24643,  2058,   541,   154,  3573,   134,  6786,\n",
       "           412,  3422,   131,   116,   238,   110,   107,   106, 17321,   151,\n",
       "           412,  3422,  3131,   122,   668,  7751,   113, 30459,  5939,   108,\n",
       "          1564,   416,   110,   107,   106, 13157,   151,   624,   307,   513,\n",
       "           374,   134,   412,  3422,   131,   116,  7894,   108,  3698,   108,\n",
       "           238,   110,   107,   106, 11712, 21298,   256,   133,   174,   186,\n",
       "           118,   198,  6479,   116,   108,   175,   146,   590,   132,   231,\n",
       "           745,  1571,   649,   110,   107,     1,     0,     0],\n",
       "        [    0,  6053,   151, 24643,  2058,   541,   154,  3573,   134,  6786,\n",
       "           412,  3422,   131,   116,   238,   110,   107,   106, 17321,   151,\n",
       "           412,  3422,  3131,   122,   668,  7751,   113, 30459,  5939,   108,\n",
       "          1564,   416,   110,   107,   106, 11712, 21298,   113,  1029,   652,\n",
       "           374,   134,   412,  3422,   131,   116,  7894,   108,  3698,   108,\n",
       "           238,   289,   396,   110,   107,   106,   812,  3422,   140, 11445,\n",
       "           113,   114, 12900, 12841,   326,   111,   140, 27154,   135,  5667,\n",
       "           112, 11031,  1564,   416,   110,   107,     1,     0]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glastonbury',\n",
       " ',',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'\",\n",
       " 's',\n",
       " 'largest',\n",
       " 'music',\n",
       " 'festivals',\n",
       " ',',\n",
       " 'was',\n",
       " 'to',\n",
       " 'kick',\n",
       " 'off',\n",
       " 'Friday',\n",
       " 'morning',\n",
       " '',\n",
       " '.',\n",
       " '<n>',\n",
       " 'In',\n",
       " 'southern',\n",
       " 'England',\n",
       " ',',\n",
       " 'where',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'\",\n",
       " 's',\n",
       " 'largest',\n",
       " 'music',\n",
       " 'festivals',\n",
       " 'was',\n",
       " 'to',\n",
       " 'kick',\n",
       " 'off',\n",
       " 'Friday',\n",
       " 'morning',\n",
       " ',',\n",
       " 'initial',\n",
       " 'rumors',\n",
       " 'and',\n",
       " 'then',\n",
       " 'confirmation',\n",
       " 'of',\n",
       " 'Jackson',\n",
       " \"'\",\n",
       " 's',\n",
       " 'death',\n",
       " 'added',\n",
       " 'to',\n",
       " 'confusion',\n",
       " 'and',\n",
       " 'shock',\n",
       " 'among',\n",
       " 'festival',\n",
       " 'goers',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.convert_tokens_to_string(\n",
    "[\n",
    "    token.replace('▁', '')\n",
    "    for token in \n",
    "    tokenizer.convert_ids_to_tokens(__translated[0], skip_special_tokens=True)\n",
    "]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'▁' == '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# get_response([\n",
    "#     \"\"\"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning, initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\"\"\",\n",
    "# #     \"\"\"On a street in New Delhi, India, 31-year-old Sachina Verma said on Friday, \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music. Literally, people have been inspired by his dance movements, by his music.\"\"\",\n",
    "# #     \"\"\"In Adelaide, Australia, Christos Winter of the MJ Fan Club had organized a petition to bring Jackson to tour there. \"It didn't matter if you were 60, 40 or 20 like I am. Michael Jackson's music just spoke to everyone ... It was always uplifting and happy music,\" Winter told CNN.\"\"\",\n",
    "# #     \"\"\"Another iReporter, Peter Maiyoh, a Kenyan student studying in the U.S. city of Kansas, Missouri, called Jackson \"the voice of change,\" saying \"he was there before Tiger Woods, before Michael Jordan, even before Barack Obama ... I hope people remember him for the work he did.\"\"\",\n",
    "# #     \"\"\"Around midnight at London's Leicester Square, as news of Jackson's death spread, Luis Carlos Ameida and his friends were surrounding a car listening to the star's music. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\"\"\",\n",
    "# ], num_return_sequences=10, num_beams=10, max_length=int(1.5*51))\n",
    "# end = time.time()\n",
    "# print(f'{end-start:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lol',\n",
       " 'what',\n",
       " 'the',\n",
       " 'fuck',\n",
       " ';',\n",
       " 'I',\n",
       " 'thought',\n",
       " '?',\n",
       " 'Huh',\n",
       " ',',\n",
       " 'I',\n",
       " 'guessed',\n",
       " 'I',\n",
       " 'never',\n",
       " '...',\n",
       " 'whatever',\n",
       " ',',\n",
       " 'man',\n",
       " '.']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('lol what the fuck; I thought? Huh, I guessed I never...whatever, man.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': {'dataset': 'NewsQA', 'split': 'dev'}}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords = {'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than'}\n",
    "from utils import lcs\n",
    "def get_paraphrase(context, num_beams=75, len_multiplier=1.5):\n",
    "#     print(num_beams)\n",
    "    context = re.sub('(\\n)+', '\\n', context)\n",
    "    context = re.sub('( )+', ' ', context)\n",
    "    responses = get_response(context, num_return_sequences=num_beams, num_beams=num_beams, max_length=int(len_multiplier*len(context.split(' '))))\n",
    "    responses = [response.replace('  ', ' ') for response in responses]\n",
    "#     print(len(responses))\n",
    "    paraphrase_scores = []\n",
    "    for response in responses:\n",
    "        response = response.replace('<n>', ' ')\n",
    "#         print(response)\n",
    "#         print()\n",
    "        overlap_score = lcs(context.split(' '), response.split(' '))[0]\n",
    "        unique_score = len(set(response.split(' ')))  ## Can change to unique bigrams score\n",
    "        num_unseen_unigrams = len(set(context.split(' ')).union(set(response.split(' '))) - set(context.split(' ')) - stopwords)\n",
    "        paraphrase_score = round(unique_score / (overlap_score + num_unseen_unigrams), 3)\n",
    "#         print('Overlap between orig and paraphrase', overlap_score)\n",
    "#         print('No. unique tokens in paraphrase: ', unique_score)\n",
    "#         print('paraphrase score: ', paraphrase_score)\n",
    "        paraphrase_scores.append((paraphrase_score, response))\n",
    "    paraphrase_scores = list(set(paraphrase_scores))\n",
    "#     print('='*50)\n",
    "    return sorted(paraphrase_scores, key=lambda x: x[0], reverse=True)\n",
    "def print_paraphrase(context, num_beams=75, len_multiplier=1.5,):    \n",
    "    import time\n",
    "    start = time.time()\n",
    "    for x in get_paraphrase(context, num_beams=num_beams, len_multiplier=len_multiplier):\n",
    "        print(x)\n",
    "    end = time.time()\n",
    "    print(f'{end-start:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "(CNN) -- A phone hacking scandal may have cost Rupert Murdoch his biggest-selling newspaper in 2011, but the billionaire media mogul managed to end the year with a modest addition to his empire -- an account on Twitter.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.643, 'Rupert Murdoch opened a Twitter account in 2011. The account was set up in the wake of the phone hacking scandal that rocked his media empire.')\n",
      "(1.632, \"Rupert Murdoch opened a Twitter account in 2011. The account was set up in the wake of the phone hacking scandal that rocked his media empire. Murdoch is one of the world's richest and most influential media moguls.\")\n",
      "(1.632, \"Rupert Murdoch launched a Twitter account in 2011. The account was set up in the wake of the phone hacking scandal that rocked his media empire. Murdoch is one of the world's richest and most influential media moguls.\")\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "Within 48 hours of debuting with tweets about family, work and politics, Murdoch had pulled in more than 45,000 followers and stirred internet debate over why the 80-year-old was now embracing a technology often used to attack him.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.182, 'Within 48 hours of debuting with tweets about family, work and politics, the 80-year-old had pulled in more than 45,000 followers. Murdoch has stirred internet debate over why he is now embracing a technology often used to attack him.')\n",
      "(1.088, 'Within 48 hours of debuting with tweets about family, work and politics, Murdoch had pulled in more than 45,000 followers. Murdoch has stirred internet debate over why he is now embracing a technology often used to attack him.')\n",
      "(1.086, 'Within 48 hours of debuting with tweets about family, work and politics, the 80-year-old had pulled in more than 45,000 followers. Murdoch has stirred internet debate over why the 80-year-old is now embracing a technology often used to attack him.')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "The tweets also raised doubts that the notorious technophobe was writing the messages himself. Twitter creator Jack Dorsey -- one of only four people being followed by Murdoch -- however insisted that the media mogul was writing \"with his own voice, in his own way.\".\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.667, 'Jack Dorsey is one of only four people being followed by Murdoch. The tweets also raised doubts that the notorious technophobe was writing the messages himself.')\n",
      "(1.368, 'Twitter creator Jack Dorsey insisted that the media mogul was writing \"with his own voice, in his own way\" The tweets also raised doubts that the notorious technophobe was writing the messages himself.')\n",
      "(1.36, 'Twitter creator Jack Dorsey -- one of only four people being followed by Murdoch -- insists the media mogul was writing \"with his own voice\" The tweets also raised doubts that the notorious technophobe was writing the messages himself.')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "Murdoch appears to have made his Twitter debut on New Year's Eve with a couple of brief comments on books including the biography of late Apple boss Steve Jobs, which he called \"interesting but unfair.\".\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.042, 'Murdoch appears to have made his Twitter debut on New Year\\'s Eve. He called the biography of late Apple boss Steve Jobs \"interesting but unfair\"')\n",
      "(1.032, 'Murdoch appears to have made his Twitter debut on New Year\\'s Eve. He made brief comments about books including the biography of late Apple boss Steve Jobs, which he called \"interesting but unfair\"')\n",
      "(1.0, 'Murdoch appears to have made his Twitter debut on New Year\\'s Eve. He posted a couple of brief comments about books including the biography of late Apple boss Steve Jobs, which he called \"interesting but unfair\"')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "These were followed by praise for cinema releases \"We Bought a Zoo,\" and \"The Descendants,\" both produced by Murdoch's Fox Movies.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.385, 'Both \"We Bought a Zoo\" and \"The Descendants\" were produced by Murdoch\\'s Fox Movies. These were followed by praise for')\n",
      "(1.111, 'These were followed by praise for cinema releases \"We Bought a Zoo,\" and \"The Descendants\" Murdoch\\'s Fox Movies has produced')\n",
      "(1.111, 'These were followed by praise for cinema releases \"We Bought a Zoo\" and \"The Descendants\" Murdoch\\'s Fox Movies produced both')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "These fueled suspicions that Murdoch's Twitter account was being used as a publicity tool to help improve his image after a damaging year.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.133, \"Murdoch's Twitter account was being used to help improve his image after a damaging year. Murdoch's Twitter account has been\")\n",
      "(1.118, \"Rupert Murdoch's Twitter account was being used to help improve his image after a damaging year. Murdoch's Twitter account was set up in\")\n",
      "(1.118, \"Speculation that Murdoch's Twitter account was being used as a publicity tool to help improve his image. Murdoch's Twitter account has been\")\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "\"Could be brilliant News Corp PR operation,\" Murdoch biographer Michael Wolff tweeted after earlier commenting: \"Might be somebody who knows Murdoch, but it's not Rupert (he doesn't use a computer unassisted nor get his own email).\".\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.455, '\"Might be somebody who knows Murdoch, but it\\'s not Rupert (he doesn\\'t use a computer unassisted nor get his own email)\" \"Could be brilliant News Corp PR operation,\" Murdoch biographer Michael Wolff tweeted.')\n",
      "(1.364, '\"Might be somebody who knows Murdoch, but it\\'s not Rupert (he doesn\\'t use a computer unassisted nor get his own email)\" \"Could be brilliant News Corp PR operation,\" Murdoch biographer tweeted.')\n",
      "(1.364, '\"Might be somebody who knows Murdoch, but it\\'s not Rupert (he doesn\\'t use a computer unassisted nor get his own email)\" \"Could be brilliant News Corp PR operation,\" Murdoch biographer tweeted. \"Might be somebody who knows Murdoch')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "Others claimed that the voice of the tweets, as well as their faltering grammar and punctuation, were unmistakably Murdoch. \"You can tell by the tweets he's doing it himself,\" wrote CNN's Piers Morgan, a former editor of one of Murdoch's newspapers.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.667, '\"You can tell by the tweets he\\'s doing it himself,\" wrote Piers Morgan, a former editor of one of Murdoch\\'s newspapers. Others claimed that the voice of the tweets, as well as their faltering grammar and punctuation, were unmistakably Murdoch.')\n",
      "(1.667, '\"You can tell by the tweets he\\'s doing it himself,\" wrote Piers Morgan, a former editor of one of Murdoch\\'s newspapers. Others claimed that the voice of the tweets, as well as their faltering grammar and punctuation, were unmistakably Murdoch. \"You can')\n",
      "(1.647, '\"You can tell by the tweets he\\'s doing it himself,\" wrote CNN\\'s Piers Morgan. Others claimed that the voice of the tweets, and their faltering grammar and punctuation, were unmistakably Murdoch.')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "A spokesperson for Murdoch's News Corp. confirmed to CNN the account is genuine. The account could offer new insight into a businessman whose life has been under intense scrutiny this year after revelations that journalists at News of the World, one of his most profitable newspapers, illegally accessed the voicemail messages of scores of celebrities and public figures.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.588, \"The account could offer new insight into a businessman whose life has been under scrutiny. A spokesperson for Murdoch's News Corp. confirmed to CNN the account is genuine.\")\n",
      "(1.556, \"The account could offer new insight into a businessman whose life has been under intense scrutiny. A spokesperson for Murdoch's News Corp. confirmed to CNN the account is genuine.\")\n",
      "(1.526, \"The account could offer new insight into a businessman whose life has been under scrutiny this year. A spokesperson for Murdoch's News Corp. confirmed to CNN the account is genuine.\")\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "Twitter played a prominent role at the height of the scandal when it was used to pressure advertisers into boycotting the paper.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.238, 'Twitter played a prominent role in the scandal when it was used to pressure advertisers into boycotting the paper. The site has now been taken down by')\n",
      "(1.2, 'Twitter played a prominent role in the scandal when it was used to pressure advertisers into boycotting the paper. The site is now being used as a')\n",
      "(1.182, 'Twitter played a prominent role in the scandal when it was used to pressure advertisers into boycotting the paper. The site has since been taken down by')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "Commentators said the loss of revenue was a key factor in Murdoch's decision to shut the paper down. Murdoch's subsequent appearance before a British parliamentary inquiry into phone hacking also caused a sensation on Twitter, particularly after his wife, Wendi Deng, pounced on a man who tried to attack him with a foam pie.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.2, \"Commentators said loss of revenue was a key factor in Murdoch's decision to shut the paper down. Wendi Deng pounced on a man who tried to attack him with a foam pie. Murdoch's subsequent appearance before a British parliamentary inquiry into phone hacking also caused a sensation on Twitter.\")\n",
      "(1.171, \"Commentators said the loss of revenue was a key factor in Murdoch's decision to shut the paper down. Wendi Deng pounced on a man who tried to attack him with a foam pie. Murdoch's appearance before a British parliamentary inquiry into phone hacking also caused a sensation on Twitter.\")\n",
      "(1.167, \"Commentators said the loss of revenue was a key factor in Murdoch's decision to shut the paper down. Murdoch's wife, Wendi Deng, pounced on a man who tried to attack him with a foam pie. Murdoch's appearance before a British parliamentary inquiry into phone hacking also caused a sensation on Twitter.\")\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "There were echoes of Murdoch's parliamentary appearance -- which he called the \"most humble day day of my life\" -- in New Year pledges which he tweeted in a January 1 message to Dorsey.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.438, 'There were echoes of Murdoch\\'s parliamentary appearance in a January 1 message to Dorsey. Murdoch called it the \"most humble day of my life\"')\n",
      "(1.438, 'There were echoes of Murdoch\\'s parliamentary appearance in a January 1 message to Dorsey. Murdoch called the day \"the most humble day of my life\"')\n",
      "(1.438, 'There were echoes of Murdoch\\'s parliamentary appearance in a New Year\\'s message to Dorsey. Murdoch called it his \"most humble day of my life\"')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "\"My resolutions, try to maintain humility and always curiosity. And of course diet!\". But there were also signs that the media mogul was still getting to grips with social media. Reports suggested he was forced to quickly delete one post -- possibly after Deng leapt to his aid once again.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.394, '\"My resolutions. Try to maintain humility and always curiosity. And of course diet!\" Reports suggested he was forced to quickly delete one post -- possibly after Deng leapt to his aid once again. But there were also signs that the media mogul was still getting to grips with social media.')\n",
      "(1.394, '\"My resolutions. Try to maintain humility and always curiosity. And of course diet!\" Reports suggest he was forced to quickly delete one post -- possibly after Deng leapt to his aid once again. But there were also signs that the media mogul was still getting to grips with social media.')\n",
      "(1.303, '\"My resolutions. Try to maintain humility and always curiosity. And of course diet!\" Reports suggested he was forced to quickly delete one post -- possibly after Deng leapt to his aid once again. But there were also signs that he was still getting to grips with social media.')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "The Sydney Morning Herald -- a fierce rival of his Australian publications -- was among news outlets claiming that Murdoch was guilty of \"tweeting-before-thinking\" for suggesting that the British have too many holidays for a \"broke country.\".\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(0.963, 'The Sydney Morning Herald was among news outlets claiming that Murdoch was guilty of \"tweeting-before-thinking\" Murdoch had suggested that the British have too many holidays for a \"broke country\"')\n",
      "(0.926, 'The Sydney Morning Herald was among news outlets claiming that Murdoch was guilty of \"tweeting-before-thinking\" Murdoch suggested that the British have too many holidays for a \"broke country\"')\n",
      "(0.923, 'Sydney Morning Herald was among news outlets claiming that Murdoch was guilty of \"tweeting-before-thinking\" Murdoch suggested that the British have too many holidays for a \"broke country\"')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "The message was apparently removed, but not before someone tweeting as Wendi Deng implored: \"RUPERT!!! delete tweet!\" A further post on the unverified Deng account later added: \"EVERY1 @rupertmurdoch was only having a joke pROMSIE!!!\" [sic].\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.222, 'Wendi Deng tweeted \"rupertmurdoch was only having a joke pROM\" Message was apparently removed, but not before someone tweeted as Wendi Deng implored: \"RUPERT!!! delete tweet!\"')\n",
      "(1.2, 'Wendi Deng tweeted: \"RUPERT!!! delete tweet!\" A further post on the unverified Deng account later added: \"EVERY1 @rupertmurdoch was only having a joke pROM\" The tweet was apparently removed, but not before')\n",
      "(1.2, 'The message was apparently removed, but not before someone tweeting as Wendi Deng implored: \"RUPERT!!! delete tweet!\" \"EVERY1 @rupertmurdoch was only having a joke pROM,\" a further post on the unverified Deng account')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "Murdoch also follows an account that appears on the surface to be Google CEO Larry Page but is actually run by a man in Virginia.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(1.143, 'Murdoch follows an account that appears to be Google CEO Larry Page but is actually run by a man in Virginia. Murdoch also follows an account that appears on the')\n",
      "(1.12, 'Murdoch also follows an account that appears to be Google CEO Larry Page but is actually run by a man in Virginia. The account was set up by a man in Virginia and')\n",
      "(1.107, 'Murdoch also follows an account that appears on the surface to be Google CEO Larry Page but is actually run by a man in Virginia. The account has since been closed and')\n",
      "==================================================\n",
      "\n",
      "Original:\n",
      "\n",
      "It's not clear whether Murdoch realizes he's not following the real Larry Page. Among other tweets by Murdoch, who also follows Zynga CEO Mark Pincus and Silcon Valley entrepreneur and British businessman Alan Sugar, were an expression of support for Republican presidential hopeful Rick Santorum.\n",
      "\n",
      "Paraphrased:\n",
      "\n",
      "(2.0, \"Murdoch also follows Zynga CEO Mark Pincus and British businessman Alan Sugar. Among other tweets by Murdoch, he expresses support for Rick Santorum. It's not clear whether Murdoch realizes he's not following the real Larry Page.\")\n",
      "(1.944, \"Murdoch also follows Zynga CEO Mark Pincus and Silcon Valley entrepreneur Alan Sugar. Among other tweets by Murdoch, he expresses support for Rick Santorum. It's not clear whether Murdoch realizes he's not following the real Larry Page.\")\n",
      "(1.944, \"Murdoch also follows Zynga CEO Mark Pincus and British businessman Alan Sugar. Among other tweets by Murdoch, he supports Republican presidential hopeful Rick Santorum. It's not clear whether Murdoch realizes he's not following the real Larry Page.\")\n",
      "Time taken: 104.469\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "question: How many followers does Rupert have?\n",
      "\n",
      "detected_answers:\n",
      "1) 45,000\n",
      "\n",
      "Answer span: ['45,000']\n",
      "\n",
      "==================================================\n",
      "question: How many followers does Murdoch have on twitter?\n",
      "\n",
      "detected_answers:\n",
      "1) 45,000\n",
      "\n",
      "Answer span: ['45,000']\n",
      "\n",
      "==================================================\n",
      "question: What do his tweets talk about?\n",
      "\n",
      "detected_answers:\n",
      "1) family, work and politics,\n",
      "\n",
      "Answer span: ['family', ',', 'work', 'and', 'politics', ',']\n",
      "\n",
      "==================================================\n",
      "question: What is his age?\n",
      "\n",
      "detected_answers:\n",
      "1) 80-year-old\n",
      "\n",
      "Answer span: ['80-year', '-', 'old']\n",
      "\n",
      "==================================================\n",
      "question: what age is the person?\n",
      "\n",
      "detected_answers:\n",
      "1) 80-year-old\n",
      "\n",
      "Answer span: ['80-year', '-', 'old']\n",
      "\n",
      "==================================================\n",
      "question: What types of tweets does Murdoch write?\n",
      "\n",
      "detected_answers:\n",
      "1) about family, work and politics,\n",
      "\n",
      "Answer span: ['about', 'family', ',', 'work', 'and', 'politics', ',']\n",
      "\n",
      "==================================================\n",
      "question: Which news channel was this information confirmed to?\n",
      "\n",
      "detected_answers:\n",
      "1) CNN\n",
      "\n",
      "Answer span: ['CNN']\n",
      "\n",
      "==================================================\n",
      "question: What is number of followers Murdoch has?\n",
      "\n",
      "detected_answers:\n",
      "1) 45,000\n",
      "\n",
      "Answer span: ['45,000']\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "NORMALIZED_SENT_LEN = 20  ## words\n",
    "elem = elems[11]\n",
    "passage_tokens = [x[0] for x in elem['context_tokens']]\n",
    "context = elem['context']\n",
    "context = re.sub('(\\n)+', '\\n', context)\n",
    "context = re.sub('( )+', ' ', context)\n",
    "context = context.split('\\n')\n",
    "\n",
    "context_sents_split = []\n",
    "for cx_para in context:\n",
    "    if len(cx_para.split(' ')) < NORMALIZED_SENT_LEN:\n",
    "        context_sents_split.append(cx_para)\n",
    "    else:\n",
    "        cx_para_concats = []\n",
    "        for line in cx_para.split('. '):\n",
    "            if not line.endswith('.'):\n",
    "                line += '.'\n",
    "            if len(cx_para_concats) == 0:\n",
    "                cx_para_concats.append(line)\n",
    "            else:\n",
    "                if len(cx_para_concats[-1].split(' ')) < NORMALIZED_SENT_LEN:\n",
    "                    cx_para_concats[-1] += ' ' + line\n",
    "                else:\n",
    "                    cx_para_concats.append(line)\n",
    "        context_sents_split.extend(cx_para_concats)\n",
    "context = context_sents_split\n",
    "    \n",
    "context_sents_concat = []\n",
    "for cx_para in context:\n",
    "    if len(context_sents_concat) == 0:\n",
    "        context_sents_concat.append(cx_para)\n",
    "    else:\n",
    "        if len(context_sents_concat[-1].split(' ')) < NORMALIZED_SENT_LEN:\n",
    "            context_sents_concat[-1] += ' ' + cx_para\n",
    "        else:\n",
    "            context_sents_concat.append(cx_para)\n",
    "context = context_sents_concat\n",
    "\n",
    "start = time.time()\n",
    "for paragraph in context:\n",
    "    print('='*50, end='\\n\\n')\n",
    "    print('Original:\\n')\n",
    "    print(paragraph)\n",
    "    print('\\nParaphrased:\\n')\n",
    "    for x in get_paraphrase(\n",
    "        paragraph,\n",
    "        num_beams=75,\n",
    "        len_multiplier=1.5,\n",
    "    )[0:3]:\n",
    "        print(x)\n",
    "end = time.time()\n",
    "print(f'Time taken: {end-start:.3f}')\n",
    "\n",
    "print()\n",
    "print('='*80)\n",
    "print('='*80)\n",
    "print('='*80)\n",
    "print()\n",
    "\n",
    "questions = elem['qas']\n",
    "for question in questions:\n",
    "    print('\\n' + '='*50 + f'\\nquestion: {question[\"question\"]}')\n",
    "    detected_answers = question['detected_answers']\n",
    "\n",
    "    print(f'\\ndetected_answers:')\n",
    "    for detected_ans_i, detected_ans in enumerate(detected_answers):\n",
    "        print(f'{detected_ans_i+1}) {detected_ans[\"text\"]}')\n",
    "        span_idxs = (detected_ans['token_spans'][0][0], detected_ans['token_spans'][0][1]+1)\n",
    "        span = passage_tokens[span_idxs[0]: span_idxs[1]]\n",
    "        print(f'\\nAnswer span: {span}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original    #unique ngrams: 39\n",
      "Paraphrased #unique ngrams: 25\n",
      "Hallcinated unigrams: 22: {('account', 'in'), ('rocked', 'his'), ('media', 'empire.'), ('set', 'up'), ('in', 'the'), ('his', 'media'), ('scandal', 'that'), ('The', 'account'), ('Twitter', 'account'), ('2011.', 'The'), ('a', 'Twitter'), ('the', 'phone'), ('the', 'wake'), ('account', 'was'), ('of', 'the'), ('was', 'set'), ('that', 'rocked'), ('wake', 'of'), ('opened', 'a'), ('Murdoch', 'opened'), ('up', 'in'), ('in', '2011.')}\n"
     ]
    }
   ],
   "source": [
    "n_gram = 1\n",
    "stopwords_and_punctuation = {',', ';', ':', '.', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than'}\n",
    "passage_tokens = '(CNN) -- A phone hacking scandal may have cost Rupert Murdoch his biggest-selling newspaper in 2011 , but the billionaire media mogul managed to end the year with a modest addition to his empire -- an account on Twitter .'.split(' ')\n",
    "orig_ngrams = get_ngrams(passage_tokens, n_gram)\n",
    "paraphrased_tokens = 'Rupert Murdoch opened a Twitter account in 2011. The account was set up in the wake of the phone hacking scandal that rocked his media empire.'.split(' ')\n",
    "paraphrased_ngrams = get_ngrams(paraphrased_tokens, n_gram)\n",
    "print(f'Original    #unique ngrams: {len(orig_ngrams)}')\n",
    "print(f'Paraphrased #unique ngrams: {len(paraphrased_ngrams)}')\n",
    "hallucinated_unigrams = set(paraphrased_ngrams.keys()) - set(orig_ngrams.keys()) - stopwords_and_punctuation\n",
    "print(f'Hallcinated unigrams: {len(hallucinated_unigrams)}: {hallucinated_unigrams}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print_paraphrase(\n",
    "#     \"\"\"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning, initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\"\"\",\n",
    "#     num_beams=50,\n",
    "#     len_multiplier=1.5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = [\"Pegasus is <mask_2> . <mask_1> it <mask_2> the model .\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_string = [\"<s> It is pure white . \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_string = [\"It is pure white . </s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'bos_token': '<s>'} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[51881,   117,     3,   110,   107,     2,   126,     3,   109,   861,\n",
      "           110,   107]], device='cuda:0')\n",
      "tensor([[ 110,  105,  116, 2314,  168,  117, 3763,  695,  110,  107]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 168,  117, 3763,  695,  110,  107,    1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_string, add_special_tokens=False, return_tensors=\"pt\").input_ids.to(device)\n",
    "print(input_ids)\n",
    "decoder_input_ids = tokenizer(decoder_input_string, add_special_tokens=False, return_tensors=\"pt\", bos_token='<s>').input_ids.to(device)\n",
    "print(decoder_input_ids)\n",
    "labels = tokenizer(labels_string, add_special_tokens=False, return_tensors=\"pt\").input_ids.to(device)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 'hatsour')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import lcs\n",
    "lcs('xyzhat sourdough', 'thatso urmantra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from nltk) (4.44.1)\n",
      "Requirement already satisfied: regex in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_new/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.2\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aae554cf0aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(1.025, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the biggest in the world, drawing people from all over the world.\")\n",
      "(1.024390243902439, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest in the world, drawing people from all over the world.\")\n",
      "(1.0238095238095237, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest in the world, drawing more than 200,000 people each year.\")\n",
      "(1.0238095238095237, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest in the world, drawing more than 100,000 people each year.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the world's largest, drawing more than 100,000 people each year.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the world's largest, drawing more than 200,000 people each year.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the world's largest, drawing people from all over the world.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the world's largest, drawing people from all over the globe.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the world's largest, drawing more than 100,000 people each year.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the world's largest, drawing people from all over the world.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson pronounced dead at 2:26 p.m. local time at hospital where he was being treated.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson, 50, was pronounced dead at 2:26 p.m. local time Thursday at hospital where he was being treated.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson was pronounced dead at 2:26 p.m. local time at hospital where he was being treated.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the world's largest, drawing people from all over the world.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the world's largest, drawing more than 200,000 people each year.\")\n",
      "(1.0, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson was pronounced dead at 2:26 p.m. local time at the hospital where he was being treated.\")\n",
      "(0.9767441860465116, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest in the world, drawing tens of thousands of people each year.\")\n",
      "(0.975609756097561, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. More than 100,000 people are expected to attend this year's festival.\")\n",
      "(0.975609756097561, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. More than 200,000 people are expected to attend this year's festival.\")\n",
      "(0.975, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The festival is one of the world's largest, drawing people from all walks of life.\")\n",
      "(0.9743589743589743, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest of its kind in the world.\")\n",
      "(0.9743589743589743, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. One of the world's largest music festivals, Glastonbury is one of the most popular in the world.\")\n",
      "(0.9736842105263158, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the largest of its kind in the world.\")\n",
      "(0.9565217391304348, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson, 50, was pronounced dead at 2:26 p.m. local time at his Los Angeles home.\")\n",
      "(0.9555555555555556, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson was pronounced dead at 2:26 p.m. local time at his Los Angeles home.\")\n",
      "(0.9555555555555556, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson was pronounced dead at 2:26 p.m. local time at hospital in Los Angeles.\")\n",
      "(0.9523809523809523, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson's death was announced at 2:26 p.m. local time in Los Angeles.\")\n",
      "(0.9512195121951219, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Jackson's death was reported at 2:26 p.m. local time in Los Angeles.\")\n",
      "(0.9512195121951219, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson's death was announced at 2:26 p.m. local time in London.\")\n",
      "(0.9512195121951219, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Jackson's death was announced at 2:26 p.m. local time in Los Angeles.\")\n",
      "(0.95, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest gatherings of musicians in the world.\")\n",
      "(0.95, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest gatherings of music fans in the world.\")\n",
      "(0.95, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Jackson's death was announced at 2:26 p.m. local time in London.\")\n",
      "(0.95, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. One of the world's largest music festivals, Glastonbury is scheduled to run through Sunday.\")\n",
      "(0.9487179487179487, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. For more video from Glastonbury click here.\")\n",
      "(0.9473684210526315, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. The three-day festival is one of the biggest in the world.\")\n",
      "(0.9393939393939394, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation that Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.9375, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion. Shock among festival goers.\")\n",
      "(0.9285714285714286, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion.\")\n",
      "(0.9259259259259259, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion.\")\n",
      "(0.925, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Michael Jackson's death was announced at 2:26 p.m. local time.\")\n",
      "(0.9230769230769231, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Jackson's death was announced at 2:26 p.m. local time.\")\n",
      "(0.9230769230769231, \"In Glastonbury, southern England, one of the world's largest music festivals was to start Friday. Initial rumors and then confirmation of Jackson's death added to confusion.\")\n",
      "(0.9166666666666666, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. Glastonbury is one of the world's largest music festivals.\")\n",
      "(0.9142857142857143, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. One of the world's largest music festivals was to kick off Friday morning.\")\n",
      "(0.9117647058823529, \"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning, initial rumors and then confirmation of Jackson's death added to confusion and shock among festival goers.\")\n",
      "(0.9090909090909091, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and thenConfirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.9090909090909091, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors, then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.9090909090909091, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and shock among festival goers.\")\n",
      "(0.90625, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and shock among festival goers.\")\n",
      "(0.9032258064516129, \"In Glastonbury, southern England, one of the world's largest music festivals was to start Friday. Initial rumors and then confirmation of Jackson's death added to confusion and shock among festival goers.\")\n",
      "(0.9, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and shock.\")\n",
      "(0.896551724137931, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and shock.\")\n",
      "(0.8888888888888888, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. One of the world's largest music festivals.\")\n",
      "(0.8857142857142857, \"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8857142857142857, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning.  Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8857142857142857, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. \")\n",
      "(0.8857142857142857, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. One of the world's largest music festivals was to kick off Friday morning.\")\n",
      "(0.8857142857142857, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Michael Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8857142857142857, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning.  initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival attendees.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death adds to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers. One of the world's largest music festivals was to kick off Friday.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death Added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial Rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then Confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday.  initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday afternoon. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson’s death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's biggest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death add to confusion and then shock among festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock amongst festival goers.\")\n",
      "(0.8823529411764706, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festivalgoers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festivals was to open Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festivals was to launch Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival-goers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festival was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8787878787878788, \"In Glastonbury, southern England, one of the world's largest music festivals was to start Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.875, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festivalgoers.\")\n",
      "(0.875, \"In Glastonbury, southern England, one of the world's largest music festivals was to begin Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.875, \"In Glastonbury, southern England, one of the world's largest music festivals was to start Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.875, \"In Glastonbury, southern England, one of the world's largest music festival was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\")\n",
      "(0.8709677419354839, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday morning. Initial rumors and then confirmation of Jackson's death added to confusion and then shock.\")\n",
      "(0.8666666666666667, \"In Glastonbury, southern England, one of the world's largest music festivals was to kick off Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock.\")\n",
      "(0.8620689655172413, \"In Glastonbury, southern England, one of the world's largest music festivals was to start Friday. Initial rumors and then confirmation of Jackson's death added to confusion and then shock.\")\n"
     ]
    }
   ],
   "source": [
    "for x in get_paraphrase(\"\"\"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning, initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\"\"\"):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(1.56, 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.5384615384615385, 'Luis Carlos Ameida was in London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.5185185185185186, 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to the star\\'s music.')\n",
      "(1.5, 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.4615384615384615, 'Luis Carlos Ameida was at London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.4583333333333333, 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music as news of his death spread.')\n",
      "(1.4444444444444444, 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.44, 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music as news of his death spread.')\n",
      "(1.4285714285714286, 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.4137931034482758, 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.4074074074074074, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music as news of his death spread.')\n",
      "(1.4074074074074074, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music as news of his death spread.')\n",
      "(1.3928571428571428, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music as news of his death spread.')\n",
      "(1.3928571428571428, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music as news of his death spread.')\n",
      "(1.36, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to the star\\'s music.')\n",
      "(1.3571428571428572, 'Luis Carlos Ameida and friends were in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.32, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.3076923076923077, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\\'s music.')\n",
      "(1.2692307692307692, 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(1.2142857142857142, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was outside Leicester Square when news of Jackson\\'s death spread.')\n",
      "(1.206896551724138, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was outside Leicester Square when news of Jackson\\'s death spread.')\n",
      "(1.2, 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(1.1923076923076923, 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(1.1428571428571428, 'Luis Carlos Ameida and friends were in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(1.1333333333333333, 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(1.1111111111111112, 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(1.0666666666666667, 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(1.064516129032258, 'Luis Carlos Ameida was in London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(1.032258064516129, 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(1.03125, 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(1.0, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.9615384615384616, 'Luis Carlos Ameida got tickets to see Jackson\\'s \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9615384615384616, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This is It\" concerts beginning on July 13 in London.')\n",
      "(0.96, 'Luis Carlos Ameida got tickets to see Jackson\\'s \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.96, 'Luis Carlos Ameida had gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.9583333333333334, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(0.9259259259259259, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(0.9259259259259259, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.9259259259259259, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts begin on July 13 in London.')\n",
      "(0.9259259259259259, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts starting on July 13 in London.')\n",
      "(0.9259259259259259, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts Beginning on July 13 in London.')\n",
      "(0.9259259259259259, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts begin on July 13 in London.')\n",
      "(0.9230769230769231, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9230769230769231, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9230769230769231, 'Luis Carlos Ameida says he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9230769230769231, 'Luis Carlos Ameida says he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.9230769230769231, 'Luis Carlos Ameida had gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9230769230769231, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.92, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.92, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.92, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.92, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9166666666666666, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9166666666666666, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.')\n",
      "(0.9166666666666666, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(0.9130434782608695, 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.9130434782608695, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(0.9090909090909091, 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8928571428571429, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8928571428571429, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8888888888888888, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8888888888888888, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8888888888888888, 'Luis Carlos Ameida says he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8888888888888888, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8846153846153846, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8846153846153846, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8846153846153846, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8846153846153846, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.88, 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.')\n",
      "(0.88, 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.875, 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n",
      "(0.8695652173913043, 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.')\n"
     ]
    }
   ],
   "source": [
    "print_paraphrase(\"\"\"Around midnight at London's Leicester Square, as news of Jackson's death spread, Luis Carlos Ameida and his friends were surrounding a car listening to the star's music. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "==================================================\n",
      "(1.0357142857142858, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she says.')\n",
      "(1.0344827586206897, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" Sachina Verma says. \"People have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(1.0344827586206897, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds.')\n",
      "(1.0, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" says Sachina Verma. People have been inspired by his dance movements, by his music, she says.')\n",
      "(1.0, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(1.0, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" Sachina Verma says. \"Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9743589743589743, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds. \"Any of the baby boomer generation or, you know, people from my age or our time,\" she says.')\n",
      "(0.9743589743589743, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds. \"I mean they have grown up on his music,\" Verma says.')\n",
      "(0.9743589743589743, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she says. \"I mean they have grown up on his music,\" Verma adds.')\n",
      "(0.9743589743589743, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds. \"Any of the baby boomer generation or, you know, people from my age or our time,\" Verma says.')\n",
      "(0.9736842105263158, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. People have been inspired by his dance movements, by his music, she added.')\n",
      "(0.9736842105263158, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds.')\n",
      "(0.9736842105263158, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she says. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" she adds.')\n",
      "(0.9736842105263158, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" she says.')\n",
      "(0.9736842105263158, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she says. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Verma adds.')\n",
      "(0.9736842105263158, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she adds. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Verma says.')\n",
      "(0.972972972972973, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. People have been inspired by his dance movements, by his music, she said.')\n",
      "(0.972972972972973, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she says. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Verma says.')\n",
      "(0.972972972972973, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, she says.')\n",
      "(0.972972972972973, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"People have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.96875, '\"Any of the baby boomer generation or, you know, people from my age or our time,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9534883720930233, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. Sachin Verma: \"People have been inspired by his dance movements, by his music\"')\n",
      "(0.9523809523809523, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. Sachin Verma: \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music\"')\n",
      "(0.9523809523809523, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"People have been inspired by his dance movements, by his music,\" Verma says.')\n",
      "(0.9512195121951219, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. People have been inspired by his dance movements, by his music, she says.')\n",
      "(0.9512195121951219, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"Literally, people have been inspired by his dance movements, by his music,\" she adds. Sachin Verma: \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music\"')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \" Literally, people have been inspired by his dance movements, by his music,\" Verma added. \"People have been inspired by his dance movements, by his music,\" she said.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"People have been inspired by his dance movements, by his music,\" the 31-year-old says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"Any of the baby boomer generation or, you know, people from my age or our time,\" she says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"People have been inspired by his dance movements, by his music,\" she says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"I mean they have grown up on his music,\" Verma says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"People have been inspired by his dance movements, by his music,\" Verma says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"People have been inspired by his dance movements, by his music,\" she says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"Any of the baby boomer generation or, you know, people from my age or our time,\" she says.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \" Literally, people have been inspired by his dance movements, by his music,\" she added. \"People have been inspired by his dance movements, by his music,\" Verma said.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma says. \"People have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.95, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she says. \"People have been inspired by his dance movements, by his music,\" Verma adds.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"Literally, people have been inspired by his dance movements, by his music,\" she adds. \"People have been inspired by his dance movements, by his music,\" Verma says.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Verma says.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \" Literally, people have been inspired by his dance movements, by his music,\" she added.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" she says.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" she says.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. People have been inspired by his dance movements, by his music, she adds.')\n",
      "(0.9487179487179487, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. People have been inspired by his dance movements, by his music, she says.')\n",
      "(0.9473684210526315, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9473684210526315, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9473684210526315, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \" Literally, people have been inspired by his dance movements, by his music,\" she said.')\n",
      "(0.9473684210526315, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \"Literally, people have been inspired by his dance movements, by his music,\" she added.')\n",
      "(0.9473684210526315, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" she says.')\n",
      "(0.9473684210526315, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, Verma adds.')\n",
      "(0.9459459459459459, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"Literally, people have been inspired by his dance movements, by his music,\" she says.')\n",
      "(0.9459459459459459, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. People have been inspired by his dance movements, by his music, Verma says.')\n",
      "(0.926829268292683, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" she adds. \"People have been inspired by his dance movements, by his music,\" says Verma.')\n",
      "(0.925, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" she says.')\n",
      "(0.925, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" says Verma. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" she adds.')\n",
      "(0.925, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds.')\n",
      "(0.925, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"Any of the baby boomer generation or, you know, people from my age or our time,\"')\n",
      "(0.925, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"People have been inspired by his dance movements, by his music,\" Verma says.')\n",
      "(0.925, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9230769230769231, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \"literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9230769230769231, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds.')\n",
      "(0.9230769230769231, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \"Literally, people have been inspired by his dance movements, by his music,\" she adds.')\n",
      "(0.9230769230769231, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \" Literally, people have been inspired by his dance movements, by his music,\" Verma added.')\n",
      "(0.9230769230769231, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma adds. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Verma says.')\n",
      "(0.9210526315789473, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma said. \" Literally, people have been inspired by his dance movements, by his music,\" Verma said.')\n",
      "(0.9210526315789473, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"literally, people have been inspired by his dance movements, by his music,\" Verma adds.')\n",
      "(0.9210526315789473, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \"Literally, people have been inspired by his dance movements, by his music,\" Verma adds.')\n",
      "(0.9210526315789473, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" Sachina Verma says. \" Literally, people have been inspired by his dance movements, by his music,\" Verma says.')\n",
      "(0.9, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" says Verma. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" adds Verma.')\n",
      "(0.9, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" says Verma. \"Any of the baby boomer generation or, you know, people from my age or our time,\" says Verma.')\n",
      "(0.9, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" says Verma. \"People have been inspired by his dance movements, by his music,\" says Verma.')\n",
      "(0.8974358974358975, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" says Verma.')\n",
      "(0.8974358974358975, '\"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Sachina Verma. \" Literally, people have been inspired by his dance movements, by his music,\" says Verma. \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music,\" says Verma.')\n"
     ]
    }
   ],
   "source": [
    "print_paraphrase(\"\"\"On a street in New Delhi, India, 31-year-old Sachina Verma said on Friday, \"Any of the baby boomer generation or, you know, people from my age or our time, I mean they have grown up on his music. Literally, people have been inspired by his dance movements, by his music.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Around midnight at London's Leicester Square, as news of Jackson's death spread, Luis Carlos Ameida and his friends were surrounding a car listening to the star's music. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "\n",
      "\n",
      "['Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida had gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"', 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This I', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This I', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to', 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'s', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>As news of Jackson\\'s death spread, Ameida', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'s', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida was in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This I', 'Luis Carlos Ameida says he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening', 'Luis Carlos Ameida got tickets to see Jackson\\'s \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car', 'Luis Carlos Ameida was in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'s', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening to Jackson', 'Luis Carlos Ameida was at London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'s', 'Luis Carlos Ameida says he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida got tickets to see Jackson\\'s \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was surrounding a car listening to Jackson', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding', 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was outside Leicester Square when news of Jackson\\'s death', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'s music', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida: \"I', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening to the star', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and friends were surrounding a car listening', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida says he and his friends were surrounding a car listening to Jackson\\'s', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and friends were surrounding a car listening to Jackson\\'s', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening', 'Luis Carlos Ameida says he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida says he and his friends were surrounding a car', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said news of Jackson\\'s death spread around', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to the', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida says he and his friends were surrounding a car', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to the star\\'', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.', 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida says he and his friends were surrounding a car listening to Jackson\\'s', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to Jackson\\'', 'Luis Carlos Ameida was in London\\'s Leicester Square at the time of Jackson\\'s death.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to the star\\'', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>He said news of Jackson\\'s death', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was surrounding a car listening to Jackson', 'Luis Carlos Ameida and friends were in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida on Jackson\\'s death: \"It\\'', 'Luis Carlos Ameida had gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida: \"I\\'ve', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was outside Leicester Square when news of', 'Luis Carlos Ameida was at London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening to the', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was surrounded by', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was surrounding a car listening', 'Luis Carlos Ameida got tickets to see Jackson\\'s \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was outside Leicester', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were surrounding a car listening', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was surrounded by', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d', 'Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he and his friends were', 'Luis Carlos Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida said he was surrounding a', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>Ameida says he and his friends were surrounding a car listening to Jackson\\'', 'Luis Carlos Ameida was in London\\'s Leicester Square when news of Jackson\\'s death spread.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.<n>Ameida said he and his friends were surrounding a car listening to the star\\'', 'Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts.<n>Ameida said he\\'d gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.<n>As news of Jackson\\'s death spread, Ameida and his friends were']\n",
      "100\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  20\n",
      "paraphrase score:  0.9090909090909091\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  22\n",
      "paraphrase score:  1.0476190476190477\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  21\n",
      "paraphrase score:  0.9545454545454546\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  20\n",
      "paraphrase score:  0.9090909090909091\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida had gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  25\n",
      "paraphrase score:  1.0416666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This I\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.4761904761904763\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  1.0952380952380953\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This I\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.2916666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  38\n",
      "paraphrase score:  1.8095238095238095\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  30\n",
      "paraphrase score:  1.25\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. As news of Jackson's death spread, Ameida\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  29\n",
      "paraphrase score:  1.2083333333333333\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  21\n",
      "paraphrase score:  0.9545454545454546\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  20\n",
      "paraphrase score:  0.9090909090909091\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\n",
      "Overlap between orig and paraphrase 23\n",
      "No. unique tokens in paraphrase:  38\n",
      "paraphrase score:  1.6521739130434783\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  25\n",
      "paraphrase score:  1.0416666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"\n",
      "Overlap between orig and paraphrase 27\n",
      "No. unique tokens in paraphrase:  33\n",
      "paraphrase score:  1.2222222222222223\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  21\n",
      "paraphrase score:  0.9545454545454546\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  22\n",
      "paraphrase score:  0.9166666666666666\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson'\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  33\n",
      "paraphrase score:  1.375\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  38\n",
      "paraphrase score:  1.5833333333333333\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  22\n",
      "paraphrase score:  0.9166666666666666\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This I\n",
      "Overlap between orig and paraphrase 23\n",
      "No. unique tokens in paraphrase:  32\n",
      "paraphrase score:  1.391304347826087\n",
      "==================================================\n",
      "Luis Carlos Ameida says he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening\n",
      "Overlap between orig and paraphrase 26\n",
      "No. unique tokens in paraphrase:  39\n",
      "paraphrase score:  1.5\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson's \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  25\n",
      "paraphrase score:  1.0416666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.2916666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 23\n",
      "No. unique tokens in paraphrase:  39\n",
      "paraphrase score:  1.6956521739130435\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  37\n",
      "paraphrase score:  1.5416666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  21\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to Jackson\n",
      "Overlap between orig and paraphrase 27\n",
      "No. unique tokens in paraphrase:  40\n",
      "paraphrase score:  1.4814814814814814\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  37\n",
      "paraphrase score:  1.6818181818181819\n",
      "==================================================\n",
      "Luis Carlos Ameida says he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson's \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  22\n",
      "paraphrase score:  1.0476190476190477\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was surrounding a car listening to Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  29\n",
      "paraphrase score:  1.2083333333333333\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 23\n",
      "No. unique tokens in paraphrase:  33\n",
      "paraphrase score:  1.434782608695652\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  32\n",
      "paraphrase score:  1.3333333333333333\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  26\n",
      "paraphrase score:  1.1818181818181819\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  30\n",
      "paraphrase score:  1.4285714285714286\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was outside Leicester Square when news of Jackson's death\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  34\n",
      "paraphrase score:  1.4166666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson's music\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  32\n",
      "paraphrase score:  1.5238095238095237\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  26\n",
      "paraphrase score:  1.0833333333333333\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida: \"I\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  1.0454545454545454\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to the star\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  34\n",
      "paraphrase score:  1.4166666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  1.0952380952380953\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and friends were surrounding a car listening\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.2916666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida says he and his friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  39\n",
      "paraphrase score:  1.625\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  20\n",
      "paraphrase score:  0.9090909090909091\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  33\n",
      "paraphrase score:  1.375\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening\n",
      "Overlap between orig and paraphrase 27\n",
      "No. unique tokens in paraphrase:  38\n",
      "paraphrase score:  1.4074074074074074\n",
      "==================================================\n",
      "Luis Carlos Ameida says he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida says he and his friends were surrounding a car\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.2916666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said news of Jackson's death spread around\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  29\n",
      "paraphrase score:  1.2083333333333333\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to the\n",
      "Overlap between orig and paraphrase 23\n",
      "No. unique tokens in paraphrase:  39\n",
      "paraphrase score:  1.6956521739130435\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at\n",
      "Overlap between orig and paraphrase 26\n",
      "No. unique tokens in paraphrase:  34\n",
      "paraphrase score:  1.3076923076923077\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida says he and his friends were surrounding a car\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.2916666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to the star'\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  40\n",
      "paraphrase score:  1.6666666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  30\n",
      "paraphrase score:  1.25\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida says he and his friends were surrounding a car listening to Jackson's\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  39\n",
      "paraphrase score:  1.8571428571428572\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to Jackson'\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  32\n",
      "paraphrase score:  1.5238095238095237\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square at the time of Jackson's death. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to the star'\n",
      "Overlap between orig and paraphrase 21\n",
      "No. unique tokens in paraphrase:  39\n",
      "paraphrase score:  1.8571428571428572\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. He said news of Jackson's death\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  28\n",
      "paraphrase score:  1.1666666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was surrounding a car listening to Jackson\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  30\n",
      "paraphrase score:  1.25\n",
      "==================================================\n",
      "Luis Carlos Ameida and friends were in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 26\n",
      "No. unique tokens in paraphrase:  34\n",
      "paraphrase score:  1.3076923076923077\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida on Jackson's death: \"It'\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  26\n",
      "paraphrase score:  1.0833333333333333\n",
      "==================================================\n",
      "Luis Carlos Ameida had gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  23\n",
      "paraphrase score:  0.9583333333333334\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  25\n",
      "paraphrase score:  1.0416666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida: \"I've\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  25\n",
      "paraphrase score:  1.0416666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was outside Leicester Square when news of\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  31\n",
      "paraphrase score:  1.2916666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was at London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening to the\n",
      "Overlap between orig and paraphrase 27\n",
      "No. unique tokens in paraphrase:  41\n",
      "paraphrase score:  1.5185185185185186\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was surrounded by\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  27\n",
      "paraphrase score:  1.125\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was surrounding a car listening\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  27\n",
      "paraphrase score:  1.2272727272727273\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson's \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was outside Leicester\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  27\n",
      "paraphrase score:  1.125\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts starting July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were surrounding a car listening\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  33\n",
      "paraphrase score:  1.375\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was surrounded by\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0909090909090908\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  22\n",
      "paraphrase score:  0.9166666666666666\n",
      "==================================================\n",
      "Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he and his friends were\n",
      "Overlap between orig and paraphrase 22\n",
      "No. unique tokens in paraphrase:  24\n",
      "paraphrase score:  1.0909090909090908\n",
      "==================================================\n",
      "Luis Carlos Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida said he was surrounding a\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  27\n",
      "paraphrase score:  1.125\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. Ameida says he and his friends were surrounding a car listening to Jackson'\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  34\n",
      "paraphrase score:  1.4166666666666667\n",
      "==================================================\n",
      "Luis Carlos Ameida was in London's Leicester Square when news of Jackson's death spread. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13. Ameida said he and his friends were surrounding a car listening to the star'\n",
      "Overlap between orig and paraphrase 23\n",
      "No. unique tokens in paraphrase:  41\n",
      "paraphrase score:  1.7826086956521738\n",
      "==================================================\n",
      "Luis Carlos Ameida got tickets to see Jackson at his \"This Is It\" concerts. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London. As news of Jackson's death spread, Ameida and his friends were\n",
      "Overlap between orig and paraphrase 24\n",
      "No. unique tokens in paraphrase:  33\n",
      "paraphrase score:  1.375\n"
     ]
    }
   ],
   "source": [
    "import re, random\n",
    "context = elem['context']\n",
    "\n",
    "context = context.split('\\n')\n",
    "random.shuffle(context)\n",
    "context = context[0]\n",
    "context = \"\"\"Rincewind had always been happy to think of himself as a racist.  The One Hundred Metres, the Mile, the Marathon – he'd run them all.\"\"\"\n",
    "context = \"\"\"In Adelaide, Australia, Christos Winter of the MJ Fan Club had organized a petition to bring Jackson to tour there. \"It didn't matter if you were 60, 40 or 20 like I am. Michael Jackson's music just spoke to everyone ... It was always uplifting and happy music,\" Winter told CNN.\"\"\"\n",
    "context = \"\"\"In Glastonbury, southern England, where one of the world's largest music festivals was to kick off Friday morning, initial rumors and then confirmation of Jackson's death added to confusion and then shock among festival goers.\"\"\"\n",
    "context = \"\"\"Another iReporter, Peter Maiyoh, a Kenyan student studying in the U.S. city of Kansas, Missouri, called Jackson \"the voice of change,\" saying \"he was there before Tiger Woods, before Michael Jordan, even before Barack Obama ... I hope people remember him for the work he did.\"\"\"\n",
    "context = \"\"\"Expressing sadness and shock over Jackson's death, Ng recalled being inspired by an interview he once gave to Oprah Winfrey. \"He said if you have power, try to give it back and help the others, and I will try to do that,\" she said.\"\"\"\n",
    "context = \"\"\"Around midnight at London's Leicester Square, as news of Jackson's death spread, Luis Carlos Ameida and his friends were surrounding a car listening to the star's music. Ameida said he'd gotten tickets to see Jackson at his \"This Is It\" concerts beginning on July 13 in London.\"\"\"\n",
    "# context = elem['context']\n",
    "# context = '.'.join(context.split('.')[0:3]) + '.'\n",
    "\n",
    "context = re.sub('(\\n)+', '\\n', context)\n",
    "context = re.sub('( )+', ' ', context)\n",
    "\n",
    "responses = get_response(context, num_return_sequences=100, num_beams=100, max_length=int(1.5*len(context.split(' '))))\n",
    "print('\\n')\n",
    "print(context)\n",
    "print('\\n')\n",
    "responses = [response.replace('  ', ' ') for response in responses]\n",
    "print(responses)\n",
    "print(len(responses))\n",
    "paraphrase_scores = []\n",
    "for response in responses:\n",
    "    response = response.replace('<n>', ' ')\n",
    "    print('='*50)\n",
    "    print(response)\n",
    "    overlap_score = lcs(context.split(' '), response.split(' '))[0]\n",
    "    unique_score = len(set(response.split(' ')))  ## Can change to unique bigrams score\n",
    "    paraphrase_score = unique_score / overlap_score\n",
    "    print('Overlap between orig and paraphrase', overlap_score)\n",
    "    print('No. unique tokens in paraphrase: ', unique_score)\n",
    "    print('paraphrase score: ', paraphrase_score)\n",
    "    paraphrase_scores.append([paraphrase_score, response])\n",
    "\n",
    "# sorted(paraphrase_scores, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(1.4761904761904763, \"Obama picks Lisa Jackson, Nancy Sutley to lead White House Council on Environmental Quality. Jackson is former head of New Jersey's environmental agency. Sutley is Los Angeles deputy mayor for energy and environment.\")\n",
      "(1.4285714285714286, \"Obama names Lisa Jackson, Nancy Sutley to White House Council on Environmental Quality. Jackson is former head of New Jersey's environmental agency. Sutley is Los Angeles deputy mayor for energy and environment.\")\n",
      "(1.1363636363636365, \"Obama taps Lisa Jackson and Nancy Sutley to top environmental posts. Jackson is former head of New Jersey's environmental agency. Sutley is Los Angeles deputy mayor for energy and environment.\")\n",
      "(1.1304347826086956, \"Obama names Lisa Jackson, Nancy Sutley to top environmental posts. Jackson is former head of New Jersey's environmental agency. Sutley is Los Angeles deputy mayor for energy and environment.\")\n",
      "(1.0952380952380953, \"Obama picks Lisa Jackson and Nancy Sutley. Jackson is former head of New Jersey's environmental agency. Sutley is Los Angeles deputy mayor for energy and environment.\")\n",
      "(1.0952380952380953, \"Obama taps Lisa Jackson and Nancy Sutley. Jackson is former head of New Jersey's environmental agency. Sutley is Los Angeles deputy mayor for energy and environment.\")\n",
      "(1.0588235294117647, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, will lead White House Council on Environmental Quality.\")\n",
      "(1.0571428571428572, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. L.A. deputy mayor for energy and environment, Nancy Sutley, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0571428571428572, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, will lead White House Council on Environmental Quality.\")\n",
      "(1.0555555555555556, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0333333333333334, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to lead EPA. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0333333333333334, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to head EPA. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0303030303030303, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as EPA administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0303030303030303, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to serve as EPA administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0303030303030303, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to be Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, to lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Lisa Jackson, former head of New Jersey's environmental agency, will serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to lead Environmental Protection Agency. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, to lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, to lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as EPA administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. L.A. deputy mayor for energy and environment, Nancy Sutley, to lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, a former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. L.A. deputy mayor for energy and environment, Nancy Sutley, to lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, to lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, to lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Los Angeles deputy mayor for energy and environment, Nancy Sutley, to lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Lisa Jackson, former head of New Jersey's environmental agency, will serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Lisa Jackson, former head of New Jersey's environmental agency, named to lead EPA. Nancy Sutley, Los Angeles deputy mayor for energy and environment, named to lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama names Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, will lead White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his EPA administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(1.0, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his EPA administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.975, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality. The White House Council on Environmental\")\n",
      "(0.975, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality. \")\n",
      "(0.975, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality. The White House Council on Environmental Quality\")\n",
      "(0.975, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality. White House Council on Environmental Quality\")\n",
      "(0.9743589743589743, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.9743589743589743, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality. \")\n",
      "(0.9743589743589743, \"Obama also names Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.9736842105263158, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.9736842105263158, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.9736842105263158, \"Obama names Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.972972972972973, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.9714285714285714, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to be Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9705882352941176, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to be Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9705882352941176, \"Lisa Jackson, former head of New Jersey's environmental agency, will serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, will lead the White House Council on Environmental Quality.\")\n",
      "(0.96875, \"Lisa Jackson, former head of New Jersey's environmental agency, to serve as EPA administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.96875, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to be Environmental Protection Agency administrator. Nancy Sutley, deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.967741935483871, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to lead EPA. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9655172413793104, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to lead EPA. Nancy Sutley, deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9487179487179487, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.9487179487179487, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9473684210526315, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9473684210526315, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9473684210526315, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9473684210526315, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.9459459459459459, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9459459459459459, \"Obama names Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9459459459459459, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9459459459459459, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9459459459459459, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9444444444444444, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9444444444444444, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9444444444444444, \"Obama names Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9428571428571428, \"Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9411764705882353, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9411764705882353, \"Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9411764705882353, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.9393939393939394, \"Obama taps Lisa Jackson, former head of New Jersey's environmental agency, to lead Environmental Protection Agency. Nancy Sutley, Los Angeles deputy mayor for energy and environment, to lead White House Council on Environmental Quality.\")\n",
      "(0.926829268292683, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality. The White House Council on Environmental\")\n",
      "(0.926829268292683, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality. White House Council on Environmental Quality\")\n",
      "(0.926829268292683, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality. The White House Council on Environmental Quality\")\n",
      "(0.926829268292683, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality. \")\n",
      "(0.925, \"Obama also names Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.925, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality. \")\n",
      "(0.925, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.9230769230769231, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.9230769230769231, \"Obama names Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.9230769230769231, \"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n",
      "(0.9210526315789473, \"Obama named Lisa Jackson, former head of New Jersey's environmental agency, to serve as Environmental Protection Agency administrator. Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\")\n"
     ]
    }
   ],
   "source": [
    "print_paraphrase(\"\"\"Obama also named Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator, and Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(1.04, 'Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to new post in White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.0384615384615385, 'Obama taps physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner named to new post in White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.0384615384615385, 'Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner named to new post in White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.0384615384615385, 'Obama picks physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner named to new post in White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.037037037037037, 'Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.037037037037037, 'Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy.')\n",
      "(1.037037037037037, 'Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in the White House.')\n",
      "(1.037037037037037, \"Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to new post in White House. Browner will coordinate energy and climate policy in Obama's administration.\")\n",
      "(1.0357142857142858, 'President-elect Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in the White House.')\n",
      "(1.0357142857142858, 'President-elect Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.0344827586206897, \"Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in Obama's administration.\")\n",
      "(1.0344827586206897, 'President-elect Barack Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in White House.')\n",
      "(1.0344827586206897, 'President-elect Barack Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner will coordinate energy and climate policy in the White House.')\n",
      "(1.0, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner named to new post in White House.')\n",
      "(1.0, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner to a new post in the White House.')\n",
      "(1.0, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner is named to new post in the White House.')\n",
      "(1.0, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner named to new post in the White House.')\n",
      "(1.0, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner is named to new post in White House.')\n",
      "(1.0, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner is named to a new post in the White House.')\n",
      "(0.967741935483871, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner to a new post in the White House.')\n",
      "(0.9666666666666667, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner named to new post in the White House.')\n",
      "(0.9666666666666667, 'President-elect Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner to a new post in the White House.')\n",
      "(0.9655172413793104, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner named to new post in White House.')\n",
      "(0.9655172413793104, 'President-elect Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner named to new post in the White House.')\n",
      "(0.9655172413793104, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu is named secretary of energy. Former EPA administrator Carol Browner is named to coordinate energy and climate policy.')\n",
      "(0.9655172413793104, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner to new post in White House.')\n",
      "(0.9642857142857143, 'President-elect Barack Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner will coordinate energy and climate policy.')\n",
      "(0.9642857142857143, 'President-elect Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner named to new post in White House.')\n",
      "(0.9642857142857143, 'Obama names physicist Steven Chu as secretary of energy. Former EPA administrator Carol Browner to a new post in the White House. Browner to coordinate energy and climate policy in White House.')\n",
      "(0.9629629629629629, 'President-elect Obama announces key members of his energy team.  physicist Steven Chu named secretary of energy. Former EPA administrator Carol Browner will coordinate energy and climate policy.')\n"
     ]
    }
   ],
   "source": [
    "print_paraphrase(\"\"\"CHICAGO, Illinois (CNN)  -- U.S. President-elect Barack Obama announced key members of his energy team on Monday, naming physicist Steven Chu as secretary of energy, and former EPA administrator Carol Browner to a new post in the White House to coordinate energy and climate policy.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(1.5555555555555556, 'Plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared.')\n",
      "(1.5555555555555556, 'Plane disappeared in storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared.')\n",
      "(1.5555555555555556, 'Plane disappeared in storm-prone area along equator known as the Intertropical Convergence zone (ITCZ) Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared.')\n",
      "(1.2857142857142858, 'Plane disappeared in storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone')\n",
      "(0.9393939393939394, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is home to')\n",
      "(0.9393939393939394, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is one of')\n",
      "(0.9393939393939394, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is part of')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is at the')\n",
      "(0.9375, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is part of the')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is an area')\n",
      "(0.9375, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is part of the')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is part of')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is known for')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is where the')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is one of')\n",
      "(0.9375, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is known to')\n",
      "(0.9354838709677419, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is an area')\n",
      "(0.9354838709677419, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is where the')\n",
      "(0.9354838709677419, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is known for')\n",
      "(0.9285714285714286, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator. The Intertropical Convergence zone (ITCZ) is a storm-prone area')\n",
      "(0.9117647058823529, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone ( ITCZ) The ITCZ is a storm')\n",
      "(0.9117647058823529, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone ( ITCZ)  ITCZ is a storm-')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is located in')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a relatively')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is located along')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone ( ITCZ) The ITCZ is in the')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is near the')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)  ITCZ is a storm-')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a part')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a region')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone ( ITCZ) The ITCZ is known as')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a tropical')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a band')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone ( ITCZ) The ITCZ is along the')\n",
      "(0.9090909090909091, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a belt')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is along the')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator. The area, known as the Intertropical Convergence zone (ITCZ), is')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) ITCZ is a storm-')\n",
      "(0.90625, '\"Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a')\n",
      "(0.90625, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm-')\n",
      "(0.90625, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is located along the')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a storm')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)  ITCZ is known as the')\n",
      "(0.90625, 'Some have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm-')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator. The area is known as the Intertropical Convergence zone (ITCZ) ')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a region')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a tropical')\n",
      "(0.90625, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm-')\n",
      "(0.90625, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a region along')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is known as')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)  ITCZ is along the equator')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is located in')\n",
      "(0.90625, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is located along the')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is located along')\n",
      "(0.90625, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a region along')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is in a')\n",
      "(0.90625, 'Some experts say that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm-')\n",
      "(0.90625, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is in the')\n",
      "(0.9032258064516129, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)  ITCZ is a storm-prone')\n",
      "(0.9032258064516129, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is along the equator')\n",
      "(0.9032258064516129, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is along the')\n",
      "(0.9032258064516129, '\"Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a')\n",
      "(0.9032258064516129, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is known as the')\n",
      "(0.9032258064516129, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a storm-')\n",
      "(0.9032258064516129, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) This is a storm-prone')\n",
      "(0.9032258064516129, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) ITCZ is known as the')\n",
      "(0.9032258064516129, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a storm-')\n",
      "(0.9032258064516129, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is along the equator')\n",
      "(0.9032258064516129, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is known as')\n",
      "(0.9032258064516129, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)  ITCZ is a storm-prone')\n",
      "(0.9032258064516129, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is known as the')\n",
      "(0.9032258064516129, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator. The area is known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.9032258064516129, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is in the')\n",
      "(0.9, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) ITCZ is a storm-prone')\n",
      "(0.9, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) ITCZ is a storm-prone')\n",
      "(0.9, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is known as the')\n",
      "(0.9, 'Some experts say a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm-prone')\n",
      "(0.9, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator. The area is known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.9, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) \"Some experts have said that')\n",
      "(0.9, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is along the equator')\n",
      "(0.9, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) Some experts have said that a lightning')\n",
      "(0.9, 'Experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) The ITCZ is a storm-prone')\n",
      "(0.9, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is known as the')\n",
      "(0.9, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is along the equator')\n",
      "(0.896551724137931, 'Some experts say a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) ITCZ is a storm-prone area')\n",
      "(0.896551724137931, 'Some experts say a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a storm-prone')\n",
      "(0.896551724137931, 'Experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) TheITCZ is a storm-prone')\n",
      "(0.8928571428571429, 'Some experts have said that a lightning strike was a possibility. The plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.8787878787878788, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared. The plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) ')\n",
      "(0.875, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared. The plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.875, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator. Some experts have said that a lightning strike was a possibility, particularly since the plane')\n",
      "(0.8709677419354839, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone ( ITCZ)')\n",
      "(0.8666666666666667, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.8666666666666667, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ).')\n",
      "(0.8666666666666667, 'Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ) Some experts have said that a')\n",
      "(0.8666666666666667, '\"Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.8620689655172413, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)')\n",
      "(0.8620689655172413, 'Experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ).')\n",
      "(0.8620689655172413, 'Some experts have said a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ)')\n"
     ]
    }
   ],
   "source": [
    "print_paraphrase(\"\"\"\"Some experts have said that a lightning strike was a possibility, particularly since the plane disappeared in a storm-prone area along the equator known as the Intertropical Convergence zone (ITCZ). \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(1.12, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(1.103448275862069, 'The intense sun and warm water of the equator heats the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(1.103448275862069, 'The intense sun and warm water of the equator heat the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(1.09375, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(1.0555555555555556, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(1.0555555555555556, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(1.027027027027027, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.')\n",
      "(0.9743589743589743, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. This is where the trade winds of the Northern and Southern Hemispheres converge. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.9743589743589743, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. This is where the trade winds of the Northern and Southern Hemispheres converge. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.9347826086956522, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(0.9333333333333333, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(0.9333333333333333, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. This is where the trade winds of the Northern and Southern Hemispheres converge.')\n",
      "(0.8372093023255814, 'Trade winds of the Northern and Southern Hemispheres converge in the ITCZ. The intense sun and warm water of the equator heats the air, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8372093023255814, 'Trade winds of the Northern and Southern Hemispheres converge in the ITCZ. The intense sun and warm water of the equator heat the air, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8333333333333334, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air, raising its humidity. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8333333333333334, 'The intense sun and warm water of the equator heats the air in the ITCZ. This raises its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8333333333333334, 'The intense sun and warm water of the equator heats the air in the ITCZ. This raises its humidity and makes it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8285714285714286, 'Intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8260869565217391, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8260869565217391, 'ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8260869565217391, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8260869565217391, 'ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8125, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8055555555555556, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8055555555555556, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.8, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.')\n",
      "(0.8, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.8, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant.\")\n",
      "(0.7948717948717948, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant.\")\n",
      "(0.7948717948717948, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.\")\n",
      "(0.7948717948717948, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.7948717948717948, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.7948717948717948, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7948717948717948, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7931034482758621, 'The intense sun and warm water of the equator heat the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7931034482758621, 'The intense sun and warm water of the equator heats the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.78125, \"The intense sun and warm water of the equator heat the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.78125, \"The intense sun and warm water of the equator heats the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.78125, \"The intense sun and warm water of the equator heats the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7777777777777778, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7777777777777778, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ. This raises its humidity and makes it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'The ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'The ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7755102040816326, 'It is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7708333333333334, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. The buoyant air releases the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7659574468085106, \"Intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7659574468085106, \"Intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7636363636363637, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7619047619047619, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7619047619047619, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in a series of thunderstorms.')\n",
      "(0.7619047619047619, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in a series of thunderstorms.')\n",
      "(0.7619047619047619, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ. The buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7608695652173914, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7608695652173914, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.76, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant \")\n",
      "(0.7560975609756098, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7555555555555555, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises and releases the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7555555555555555, 'The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7555555555555555, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in a series of thunderstorms. The airliner's route.\")\n",
      "(0.7555555555555555, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7551020408163265, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant \")\n",
      "(0.7551020408163265, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.7551020408163265, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7551020408163265, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant \")\n",
      "(0.7551020408163265, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.7551020408163265, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.75, 'Intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.75, 'Intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.75, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.75, \"The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.75, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.75, \"The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n",
      "(0.7391304347826086, 'The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.')\n",
      "(0.7288135593220338, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7288135593220338, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant.  Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7272727272727273, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in a series of thunderstorms.')\n",
      "(0.7241379310344828, 'ITCZ is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7241379310344828, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heat the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7241379310344828, 'This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.')\n",
      "(0.7213114754098361, \"This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route.\")\n",
      "(0.7213114754098361, \"This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms. The airliner's route\")\n"
     ]
    }
   ],
   "source": [
    "print_paraphrase(\"\"\"This is where the trade winds of the Northern and Southern Hemispheres converge. The intense sun and warm water of the equator heats the air in the ITCZ, raising its humidity and making it buoyant. Aided by the convergence of the trade winds, the buoyant air rises, releasing the accumulated moisture in an almost constant series of thunderstorms.  The airliner's route\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mhello\u001b[0m \u001b[32mworld\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "from bokeh.palettes import *\n",
    "# termcolor_colors = ['red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white']\n",
    "def print_highlighted_span(text_list, span_idxs, color):\n",
    "    from blessings import Terminal\n",
    "    t = Terminal()\n",
    "    assert isinstance(text_list, list) and len(text_list) > 0\n",
    "    if not isinstance(span_idxs, list):\n",
    "        span_idxs = [span_idxs]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All your\u001b[31m base \u001b[4mare\u001b[m belong to us\u001b[m\n"
     ]
    }
   ],
   "source": [
    "print(f'All your{t.red} base {t.underline}are{t.no_underline} belong to us{t.normal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mlol\u001b[m\n"
     ]
    }
   ],
   "source": [
    "print(t.yellow('lol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who formed the universal theory of gravitation?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Isaac Newton',\n",
       "  'char_spans': [[125, 136]],\n",
       "  'token_spans': [[20, 21]]},\n",
       " {'text': 'Isaac Newton',\n",
       "  'char_spans': [[125, 136]],\n",
       "  'token_spans': [[20, 21]]},\n",
       " {'text': 'Isaac Newton',\n",
       "  'char_spans': [[125, 136]],\n",
       "  'token_spans': [[20, 21]]},\n",
       " {'text': 'Isaac Newton',\n",
       "  'char_spans': [[125, 136]],\n",
       "  'token_spans': [[20, 21]]}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_new",
   "language": "python",
   "name": "pytorch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
